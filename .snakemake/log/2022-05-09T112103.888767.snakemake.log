Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job                 count    min threads    max threads
----------------  -------  -------------  -------------
all                     1              1              1
make_peak_counts        1              1              1
total                   2              1              1

Resources before job selection: {'_cores': 4, '_nodes': 9223372036854775807}
Ready jobs (1):
	make_peak_counts
Select jobs to execute...
Using greedy selector because only single job has to be scheduled.
Selected jobs (1):
	make_peak_counts
Resources after job selection: {'_cores': 3, '_nodes': 9223372036854775806}

[Mon May  9 11:21:04 2022]
rule make_peak_counts:
    input: test/bam/atac1_open_tn5.bam, test/bam/atac2_open_tn5.bam, test/bam/atac3_open_tn5.bam, test/bam/atac4_open_tn5.bam
    output: test/dca/background_counts_all_rse.rds, test/dca/counts_all_rse.rds
    log: test/logs/make_peak_counts.log
    jobid: 1
    resources: tmpdir=/tmp


        mkdir -p /home/jeszyman/repos/atac-seq/test/dca
        Rscript workflow/scripts/select_window_size.R         "test/bam/atac1_open_tn5.bam test/bam/atac2_open_tn5.bam test/bam/atac3_open_tn5.bam test/bam/atac4_open_tn5.bam"         4         test/dca/background_counts_all_rse.rds         test/dca/counts_all_rse.rds         >& test/logs/make_peak_counts.log
        
[Mon May  9 11:21:13 2022]
Error in rule make_peak_counts:
    jobid: 1
    output: test/dca/background_counts_all_rse.rds, test/dca/counts_all_rse.rds
    log: test/logs/make_peak_counts.log (check log file(s) for error message)
    shell:
        
        mkdir -p /home/jeszyman/repos/atac-seq/test/dca
        Rscript workflow/scripts/select_window_size.R         "test/bam/atac1_open_tn5.bam test/bam/atac2_open_tn5.bam test/bam/atac3_open_tn5.bam test/bam/atac4_open_tn5.bam"         4         test/dca/background_counts_all_rse.rds         test/dca/counts_all_rse.rds         >& test/logs/make_peak_counts.log
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Full Traceback (most recent call last):
  File "/opt/miniconda3/envs/snakemake/lib/python3.10/site-packages/snakemake/executors/__init__.py", line 593, in _callback
    raise ex
  File "/opt/miniconda3/envs/snakemake/lib/python3.10/concurrent/futures/thread.py", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/miniconda3/envs/snakemake/lib/python3.10/site-packages/snakemake/executors/__init__.py", line 579, in cached_or_run
    run_func(*args)
  File "/opt/miniconda3/envs/snakemake/lib/python3.10/site-packages/snakemake/executors/__init__.py", line 2461, in run_wrapper
    raise ex
  File "/opt/miniconda3/envs/snakemake/lib/python3.10/site-packages/snakemake/executors/__init__.py", line 2418, in run_wrapper
    run(
  File "/home/jeszyman/repos/atac-seq/workflow/peak_call_and_dif.smk", line 48, in __rule_make_peak_counts
  File "/opt/miniconda3/envs/snakemake/lib/python3.10/site-packages/snakemake/shell.py", line 266, in __new__
    raise sp.CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command 'set -euo pipefail;  
        mkdir -p /home/jeszyman/repos/atac-seq/test/dca
        Rscript workflow/scripts/select_window_size.R         "test/bam/atac1_open_tn5.bam test/bam/atac2_open_tn5.bam test/bam/atac3_open_tn5.bam test/bam/atac4_open_tn5.bam"         4         test/dca/background_counts_all_rse.rds         test/dca/counts_all_rse.rds         >& test/logs/make_peak_counts.log' returned non-zero exit status 1.

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/jeszyman/repos/atac-seq/.snakemake/log/2022-05-09T112103.888767.snakemake.log
unlocking
removing lock
removing lock
removed all locks
