* ATAC-seq Snakemake Pipelines :biopipe:
:PROPERTIES:
:header-args: :tangle no :tangle-mode (identity #o555) :mkdirp yes :noweb yes
:logging: nil
:ID:       55813fe4-d3bb-476e-a021-141bf02efadc
:END:
** Repository administration
*** Conda environmental YAMLS
**** ATAC-seq
see also [[id:26f3a21b-714a-44ac-8cff-63b3cacf833e][Cardiac]]
#+begin_src bash :tangle ./config/atac_env.yaml
name: atac
channels:
  - conda-forge
  - bioconda

dependencies:
  - bamscale
  - bedops
  - bedtools
  - bioconductor-GenomicRanges
  - bioconductor-TxDb.Hsapiens.UCSC.hg38.knownGene
  - bioconductor-TxDb.Mmusculus.UCSC.mm10.knownGene
  - bioconductor-atacseqqc
  - bioconductor-chippeakanno
  - bioconductor-chipseeker
  - bioconductor-clusterprofiler
  - bioconductor-complexheatmap
  - bioconductor-csaw
  - bioconductor-fgsea
  - bioconductor-ggbio
  - bioconductor-gviz
  - bioconductor-orthology.eg.db
  - bioconductor-rgreat
  - bioconductor-rsamtools
  - bioconductor-ruvseq
  - bioconductor-soggi
  - bowtie2
  - fastp
  - fastqc
  - homer
  - macs2
  - multiqc
  - openpyxl
  - pandas
  - parallel
  - r-ggextra
  - r-ggpattern
  - r-ggrepel
  - r-ggsci
  - r-magick
  - r-msigdbr
  - r-tidyverse
  - r-tidyverse
  - r-yaml
  - samtools
  - snakemake

#+end_src


*** Emacs
**** T o d o states
#+TODO: TODO TEST(t) INPROCESS(p) DEBUG(d) REFACTOR(r) DOCUMENT(d) BLOCKED(b&) WAITING(w&) | DONE DELEGATED
*** Setup of inputs for integration testing
- Some human fastqs
  #+begin_src bash
cp /mnt/ris/stacey.rentschler/Active/

cp /mnt/ris/jschwarz/Active/cardiac-radiobiology/old/IR-1D.HKHJ7DSX3_TAAGGCGAAT-ACTAGATCGC_L002_R1.fastq.gz /mnt/ris/szymanski/Active/test/inputs/

cp /mnt/ris/jschwarz/Active/cardiac-radiobiology/old/IR-1D.HKHJ7DSX3_TAAGGCGAAT-ACTAGATCGC_L002_R2.fastq.gz /mnt/ris/szymanski/Active/test/inputs/

#+end_src
- [[file:test/inputs/libraries.tsv][Sample sheet]]
  | library | path                                                                                         | group |
  |---------+----------------------------------------------------------------------------------------------+-------|
  | lib001  | /mnt/ris/szymanski/Active/test/inputs/IR-1D.HKHJ7DSX3_TAAGGCGAAT-ACTAGATCGC_L002_R1.fastq.gz | ctrl  |
- Human reference fasta
  #+begin_src bash
source config/bash_src
wget --directory-prefix="${data_dir}/inputs" ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz
#+end_src

*** [[id:57458bd3-005f-4342-ada7-58c55a74d7d0][ATAC-seq docker]]
** [[file:workflow/atac.smk][ATAC-seq]] :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/atac.smk
:END:
*** Preamble
:PROPERTIES:
:ID:       4b86db21-4de4-49f1-83f2-0b5e0a094506
:CUSTOM_ID: 4b86db21-4de4-49f1-83f2-0b5e0a094506
:END:
#+begin_src snakemake
#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
###                       ATAC-seq Snakemake File                            ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src
*** Workflow 1: All library processing
**** Fastq processing with fastp                                   :smk_rule:

- Removes tail 1 nucleotide
- Auto-detects and removes nextera adapter

#+begin_src snakemake
rule fastp:
    conda: "atac",
    input:
        r1 = f"{atac_fastq_dir}/{{library}}_raw_R1.fastq.gz",
        r2 = f"{atac_fastq_dir}/{{library}}_raw_R2.fastq.gz",
    log:
        cmd  = f"{log_dir}/{{library}}_atac_fastp.log",
        json = f"{log_dir}/{{library}}_atac_fastp.json",
        html = f"{log_dir}/{{library}}_atac_fastp.html",
    output:
        r1 = f"{atac_fastq_dir}/{{library}}_proc_R1.fastq.gz",
        r2 = f"{atac_fastq_dir}/{{library}}_proc_R2.fastq.gz",
    params:
        script  = f"{atac_script_dir}/trim.sh",
        threads = threads,
    shell:
        """
        {params.script} \
        {input.r1} \
        {input.r2} \
        {log.json} \
        {log.html} \
        {output.r1} \
        {output.r2} \
        {params.threads} \
        &> {log.cmd} && [[ -s {log.html} ]]
        """

#+end_src

#+begin_src bash :tangle ./scripts/trim.sh
#!/usr/bin/env bash

input_r1="${1}"
input_r2="${2}"
log_html="${3}"
log_json="${4}"
output_r1="${5}"
output_r2="${6}"
threads="${7}"

# Functions
fastp_wrap(){
    #
    fastp --detect_adapter_for_pe \
          --html $log_html \
          --json $log_json \
          --in1 $input_r1 \
          --in2 $input_r2 \
          --out1 $output_r1 \
          --out2 $output_r2 \
          --thread $threads --trim_tail1 1
}

fastp_wrap $input_r1 \
           $input_r2 \
           $log_html \
           $log_json \
           $output_r1 \
           $output_r2 \
           $threads

#+end_src

**** Alignments
***** Make bowtie2 index                                           :smk_rule:
#+begin_src snakemake
rule atac_index:
    conda: "atac",
    input: f"{ref_dir}/{{build}}.fna.gz",
    log:   f"{log_dir}/{{build}}_atac_index.log",
    output:
        f"{ref_dir}/{{build}}_bowtie2/{{build}}.1.bt2",
    params:
        base = f"{ref_dir}/{{build}}_bowtie2/{{build}}",
        dir = f"{ref_dir}/{{build}}_bowtie2",
        script = atac_script_dir + "/index.sh",
        threads = threads
    shell:
        """
        {params.script} \
        {input} \
        {params.base} \
        {params.dir} \
        {params.threads} &> {log}
        """
#+end_src
#+begin_src bash :tangle ./scripts/index.sh
#!/usr/bin/env bash
reference=$1
bt2_index_base=$2
dir="${3}"
threads="${4}"

mkdir -p $dir

bowtie2-build \
    --threads $threads \
    $reference \
    $bt2_index_base

#+end_src
***** Align trimmed reads using bowtie2                            :smk_rule:

Alignment is per cite:corces2018, fragment lengths <= 2000, very sensitive. Alignment threads and align_load limit memory usage and avoid errors.

#+begin_src snakemake
rule align_bt2:
    conda: "atac",
    input:
        r1 = f"{atac_fastq_dir}/{{library}}_proc_R1.fastq.gz",
        r2 = f"{atac_fastq_dir}/{{library}}_proc_R2.fastq.gz",
        index = f"{ref_dir}/{{build}}_bowtie2/{{build}}.1.bt2",
    log: f"{log_dir}/{{library}}_{{build}}_align_bt2.log",
    params:
        prefix = f"{ref_dir}/{{build}}_bowtie2/{{build}}",
        script = atac_script_dir + "/align_bt2.sh",
        threads = 4,
    output:
        f"{atac_dir}/bams/{{library}}_{{build}}_raw.bam",
    resources:
        align_load = 50,
    shell:
        """
        {params.script} \
        {input.r1} \
        {input.r2} \
        {params.prefix} \
        {params.threads} \
        {output}
        """
#+end_src

#+begin_src bash :tangle ./scripts/align_bt2.sh
# Snakemake variables
input_r1="$1"
input_r2="$2"
params_prefix="$3"
params_threads="$4"
output_bam="$5"


# Function
bt2_align(){
    bowtie2 --maxins 2000 --threads $4 --very-sensitive --mm -x $3 -1 $1 -2 $2 |
        samtools view -@ 8 -f 2 -F 524 -q 40 -b -o - - |
        samtools sort -@ 8 -o $5 -
    samtools index -@ 8 $5
}


# Run
bt2_align $input_r1 $input_r2 $params_prefix $params_threads $output_bam

#+end_src

- Notes
  - cite:corces2018
  - Maximum fragment length 2000 per cite:corces2017 and ENCODE1.8
  - Very sensitive per cite:reske2020
  - Initial quality filtering from ENCODE ATAC-seq pipeline version 1
***** Remove PCR duplicates                                        :smk_rule:
#+begin_src snakemake
rule atac_dedup:
    conda: "atac",
    input: f"{atac_dir}/bams/{{library}}_{{build}}_raw.bam",
    log: f"{log_dir}/{{library}}_{{build}}_atac_dedup.log",
    output: f"{atac_dir}/bams/{{library}}_{{build}}_dedup.bam",
    params:
        script = f"{atac_script_dir}/dedup.sh",
        threads = 4,
    shell:
        """
        {params.script} \
        {input} \
        {output} \
        {params.threads} &> {log}
        """
#+end_src
#+begin_src bash :tangle ./scripts/dedup.sh
#!/usr/bin/env bash

# Script variables
raw_bam="${1}"
dedup_bam="${2}"
threads="${3}"

samtools sort -@ $threads -n -o - $raw_bam |
    samtools fixmate -m - - |
    samtools sort -@ $threads -o - - |
    samtools markdup -@ $threads -r - $dedup_bam
samtools index $dedup_bam

#+end_src
***** Make a bedfile of regions to query by ATAC-seq peak calling

Currently this filter just excludes unlocalized contigs. Sex chromosomes and mitochondrial reads are retained at this step.

#+begin_src snakemake
rule make_atac_keep_bed:
    conda: "atac",
    input: f"{ref_dir}/{{build}}_chrome_sizes.txt",
    log: f"{log_dir}/{{build}}_make_atac_keep_bed.log",
    output: f"{ref_dir}/{{build}}_atac_keep.bed",
    params:
        script = f"{atac_script_dir}/make_atac_keep_bed.sh"
    shell:
        """
        {params.script} \
        {input} \
        {output} &> {log}
        """
#+end_src
#+begin_src bash :tangle ./scripts/make_atac_keep_bed.sh
#!/usr/bin/env bash

hg38_chrome_sizes="${1}"
hg38_atac_keep_bed="${2}"

cat $hg38_chrome_sizes |
    # Grep out all the non-canonical contigs and the mitochondrial reads
    grep -vE 'chrM|_|\*' |
    # Convert to bedfile format
    awk -v FS='\t' -v OFS='\t' '$2 = "1" FS $2' > $hg38_atac_keep_bed
#+end_src

***** Filter de-duplicated bams for ATAC-seq peak calling
#+begin_src snakemake
rule filter_atac_bams:
    conda: "atac",
    input:
        bam = f"{atac_dir}/bams/{{library}}_{{build}}_dedup.bam",
        keep = f"{ref_dir}/{{build}}_atac_keep.bed",
    log: f"{log_dir}/{{library}}_{{build}}_filter_atac_bams.log",
    output:
        f"{atac_dir}/bams/{{library}}_{{build}}_filt.bam",
        f"{atac_dir}/bams/{{library}}_{{build}}_filt.bam.bai",
    params:
        script = f"{atac_script_dir}/filter_atac_bams.sh",
        threads = 4,
    shell:
        """
        {params.script} \
        {input.bam} \
        {input.keep} \
        {output} {params.threads} &> {log}
        """
#+end_src
#+begin_src bash :tangle ./scripts/filter_atac_bams.sh
#!/usr/bin/env bash

in_bam="${1}"
in_keep="${2}"
out_bam="${3}"
threads="${4}"

samtools view --bam --with-header -o $out_bam -L $in_keep --use-index --threads $threads $in_bam
samtools index -@ $threads $out_bam
#+end_src
  #+begin_src bash :tangle no
#!/usr/bin/env bash

# For unit testing
#in_bam="test/analysis/atac/bams/lib003_dedup.bam"
#out_bam="test/analysis/atac/bams/lib003_filt.bam"

inbam="${1}"
outbam="${2}"
threads="${4}"

samtools view -@ $threads -b -f 1 -h -q 20 -o $outbam $inbam
samtools index $outbam

#+end_src
**** Quality control
***** FastQC
- Snakemake
  #+begin_src snakemake
rule atac_fastqc:
    conda: "atac"
    input: f"{atac_fastq_dir}/{{library}}_{{processing}}_{{read}}.fastq.gz",
    log: f"{log_dir}/{{library}}_{{processing}}_{{read}}_fastqc.log",
    output: f"{qc_dir}/{{library}}_{{processing}}_{{read}}_fastqc.zip",
    params:
        outdir = qc_dir,
        script = f"{atac_script_dir}/fastqc_wrapper.sh",
	threads = threads,
    shell:
        """
        {params.script} \
        {input} \
        {params.outdir} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:workflow/scripts/fastqc_wrapper.sh][Shell script]]
  #+begin_src bash :tangle ./scripts/fastqc_wrapper.sh
#!/usr/bin/env bash

# Script variables
input="${1}"
outdir="${2}"
threads="${3}"

# Functions
fastqc  --outdir $outdir \
        --quiet \
        --threads $threads $input

#+end_src
***** IDX stats
- Snakemake
  #+begin_src snakemake
rule atac_idx:
    input: f"{atac_dir}/{{species}}/bams/{{library}}_{{build}}_filt.bam"
    output: f"{qc_dir}/{{library}}_{{build}}_{{species}}_idxstat.txt"
    shell: "samtools idxstats {input} > {output}"
#+end_src
***** Samtools stats
- Snakemake
  #+begin_src snakemake
#input: f"{atac_dir}/{{species}}/bams/{{library}}_{{processing}}.bam",
rule samtools_stats:
    input:
        f"{atac_dir}/{{species}}/bams/{{library}}_{{build}}_{{processing}}.bam",
    log: f"{log_dir}/{{library}}_{{build}}_{{processing}}_{{species}}_samtool_stats.log",
    output:
        stat = f"{atac_dir}/{{species}}/qc/{{library}}_{{build}}_{{processing}}_samstats.txt",
        flagstat = f"{atac_dir}/{{species}}/qc/{{library}}_{{build}}_{{processing}}_flagstat.txt",
    params:
        script = f"{atac_script_dir}/samtools_stats.sh",
        threads = threads,
    shell:
        """
        {params.script} \
        {input} \
        {output.stat} \
        {output.flagstat} \
        {params.threads} 2>&1 >> {log}
        """
#+end_src
- [[file:scripts/samstools_sats.sh][Base script]]
  #+begin_src bash :tangle ./scripts/samtools_stats.sh
#!/usr/bin/env bash

in_bam="${1}"
out_stat="${2}"
out_flag="${3}"
threads="${4}"

samtools stats -@ $threads $in_bam > $out_stat
samtools flagstat -@ $threads $in_bam > $out_flag
#+end_src
***** ATAC-seq QC
- Snakemake
  #+begin_src snakemake
rule atacseq_qc:
    input:
        dup_bams = lambda wildcards: expand(f"{atac_bam_dir}/{{library}}_{{build}}_raw.bam",
                                 library = atac_map[wildcards.atac_set]['libs'],
                                 build = atac_map[wildcards.atac_set]['build']),
        proc_bams = lambda wildcards: expand(f"{atac_bam_dir}/{{library}}_{{build}}_dedup.bam",
                                 library = atac_map[wildcards.atac_set]['libs'],
                                 build = atac_map[wildcards.atac_set]['build']),
        txdb = f"{{build}}_ensembl_txdb",
    log: f"{log_dir}/{{build}}_atacseq_qc.log",
    output: f"{qc_dir}/{{build}}_atac_qc.rdata",
    params:
        script = f"{atac_script_dir}/atacseq_qc.R",
    shell:
        """
        Rscript {params.script} \
        "{input.dup_bams}" \
        "{input.proc_bams}" \
        {input.txdb} \
        {output} > {log} 2>&1
        """
#+end_src
- [[file:workflow/scripts/atac-seq_qc.R][Rscript]]
  #+begin_src R :tangle ./scripts/atacseqqc.R
# RUNS BUT DOES NOT SAVE frag.len <- fragSizeDist(proc_bam, "label")
#!/usr/bin/env Rscript

#############################
###   Atacseqqc Wrapper   ###
#############################


# Load required packages
args = commandArgs(trailingOnly = TRUE)
in_bam_dup = args[1]
in_bam_dedup = args[2]
out_rda = args[3]

# Load necessary packages
library(ATACseqQC)
library(tidyverse)
library(AnnotationDbi)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)

# Load data
txdb = TxDb.Hsapiens.UCSC.hg38.knownGene

# estimateLibComplexity uses preseqR to generate "a data frame of
# 3 columns: relative sequence depth, number of distinct
# fragments, number of putative sequenced reads"
freq = readsDupFreq(in_bam_dup)
libcomp = estimateLibComplexity(freq)

# tsse_df returns the plot values of TSSEscore with the score itself being
# https://www.encodeproject.org/data-standards/terms/#enrichment
txs = transcripts(txdb)
gal = readBamFile(proc_bam, bigFile=TRUE)
tsse_list = TSSEscore(gal, txs)
tsse_df = data.frame(
  tsse = tsse_list[1],
  distance = 100*(-9:10-.5)
)
tsse = tsse_list[2]

atacqc = function(dup_bam, proc_bam, txdb){
  freq = readsDupFreq(dup_bam)
  libcomp = estimateLibComplexity(freq)
  txs = transcripts(txdb)
  gal = readBamFile(proc_bam)
  tsse_list = TSSEscore(gal, txs)
  tsse_df = data.frame(
    tsse = tsse_list[1],
    distance = 100*(-9:10-.5)
  )
  tsse = tsse_list[2]
  atac = list(libcomp, tsse, tsse_df)
  names(atac) = c("libcomp_df", "tsse", "tsse_df")
  return(atac)
}

atac_qc_out = mapply(atacqc, dup_bam_vect, proc_bam_vect, MoreArgs = list(txdb = txdb))

save(atac_qc_out, file = atac_qc_file)
#+end_src

***** MultiQC
- Snakemake
  #+begin_src snakemake
rule atac_multiqc:
    input:
        lambda wildcards: expand(f"{qc_dir}/{{library}}_{{processing}}_{{read}}_fastqc.html",
                                 library = atac_map[wildcards.atac_set]['libs'],
                                 processing = ["raw", "proc"],
                                 read = ["R1","R2"]),
        lambda wildcards: expand(f"{qc_dir}/{{library}}_{{processing}}_samstats.txt",
                                 library = atac_map[wildcards.atac_set]['libs'],
                                 processing = ["raw", "dedup", "filt"]),
        lambda wildcards: expand(f"{qc_dir}/{{library}}_{{processing}}_flagstat.txt",
                                 library = atac_map[wildcards.atac_set]['libs'],
                                 processing = ["raw", "dedup", "filt"]),
    log: f"{log_dir}/atac_multiqc.log",
    output: f"{atac_dir}/mouse/qc/mouse_atac_multiqc.html",
    params:
        out_dir = f"{atac_dir}/mouse/qc",
        script = f"{atac_script_dir}/multiqc.sh",
    shell:
        """
        {params.script} \
        {input} {params.out_dir} &> {log}
        """
#+end_src
- [[file:scripts/multiqc.sh][Shell script]]
  #+begin_src bash :tangle ./scripts/multiqc.sh
#!/usr/bin/env bash

# Command line arguements
input="${1}"
out_name="${2}"
out_dir="${3}"

multiqc $input \
        --force \
        --outdir $out_dir \
        --filename $out_name

#+end_src
**** [[id:96efb30b-67c7-4df9-8c85-e2bd2fc6707f][Peak calling]]
*** Workflow 2: Per-DCA model processing
- parse the peak file by annotation and run the open genome script
- ideas- use [[https://genome.ucsc.edu/cgi-bin/hgTrackUi?db=mm10&g=encode3RenChromHmm][hmm]]
**** Downsample
#+begin_src snakemake
rule downsample_bam:
    input:
        f"{atac_dir}/bams/{{library}}_{{build}}_filt.bam",
    log:
        f"{log_dir}/{{library}}_{{build}}_ds{{milreads}}_bam.log",
    output:
        ds = f"{atac_dir}/bams/{{library}}_{{build}}_ds{{milreads}}.bam",
        index = f"{atac_dir}/bams/{{library}}_{{build}}_ds{{milreads}}.bam.bai",
    params:
        script = f"{atac_script_dir}/downsample_bam.sh",
        threads = threads,
        milreads = 9,
    shell:
        """
        {params.script} \
        {input} {params.milreads} {params.threads} {output.ds} &> {log}
        """
#+end_src

#+begin_src bash :tangle ./scripts/downsample_bam.sh
#!/bin/bash

in_bam="${1}"
milreads="${2}"
threads="${3}"
out_bam="${4}"

reads=$(echo |awk -v var1=$milreads '{ print 1000000*var1 }')

## Calculate the sampling factor based on the intended number of reads:

FACTOR=$(samtools idxstats $in_bam | cut -f3 |awk -v COUNT=$reads 'BEGIN {total=0} {total += $1} END {print COUNT/total}')

samtools view -s $FACTOR -b -@ $threads $in_bam > $out_bam

samtools index -@ threads $out_bam

#+end_src
**** Open genome by chromosome and chromatin state
#+begin_src snakemake
rule chr_state_open_genome:
    input:
        lambda wildcards: expand(f"{atac_dir}/peaks/{{library}}_{{build}}_{{bam_set}}_peaks.{{peaktype}}_anno.bed",
                                 library=atac_map[wildcards.atac_set]['libs'],
                                 build=atac_map[wildcards.atac_set]['build'],
                                 bam_set=atac_map[wildcards.atac_set]['bam_set'],
                                 peaktype=atac_map[wildcards.atac_set]['peaktype']),
    log:
        f"{log_dir}/{{atac_set}}_{{state}}_{{qval}}_chr_state_open_genome.log",
    output:
        f"{atac_dir}/models/{{atac_set}}/open/{{state}}_q{{qval}}_open_chrom.txt"
    params:
        genome_bed=lambda wildcards: f"{ref_dir}/{atac_map[wildcards.atac_set]['build']}_sorted_autosomes.bed",
        script = f"{atac_script_dir}/chr_state_open_genome.sh",
        threads = 4
    shell:
        """
        {params.script} \
        "{input}" \
        {params.genome_bed} \
        {wildcards.state} \
        {wildcards.qval} \
        {params.threads} \
        {output} > {log} 2>&1
        """
#+end_src

#+begin_src bash :tangle ./scripts/chr_state_open_genome.sh
#!/usr/bin/env bash
peaks_str="${1}"
ref_bed="${2}"
state="${3}"
qval_cut="${4}"
threads="${5}"
out_tsv="${6}"

process_file() {
    file="$1"
    base=$(basename $file)
    state="${2}"
    ref_bed="${3}"
    qval_cut="${4}"

    # Check if the state is "all"; if not, apply state filtering
    if [ "$state" = "all" ]; then
        cat "$file" |
            awk -v cut="$qval_cut" '$8 > cut' |
            sort-bed - |
            bedmap --echo --bases-uniq --delim '\t' $ref_bed - |
            awk -v base="$base" '{print $0 "\t" base}'
    else
        cat "$file" |
            awk -v state="$state" '$10 == state' |
            awk -v cut="$qval_cut" '$8 > cut' |
            sort-bed - |
            bedmap --echo --bases-uniq --delim '\t' $ref_bed - |
            awk -v base="$base" '{print $0 "\t" base}'
    fi
}

export -f process_file

parallel -j "$threads" process_file {} "$state" "$ref_bed" "$qval_cut" ::: $peaks_str > "$out_tsv"

#+end_src

**** Create an experimental design
#+begin_src snakemake
rule make_dca_design:
    input: libraries_full_rds,
    log: f"{log_dir}/{{atac_set}}_make_dca_design.log",
    output: f"{atac_dir}/models/{{atac_set}}/design.rds",
    params:
        formula = lambda wildcards: atac_map[wildcards.atac_set]['formula'],
        libs = lambda wildcards: atac_map[wildcards.atac_set]['libs'],
        script = f"{atac_script_dir}/make_dca_design.R",
    shell:
        """
        Rscript {params.script} {input} "{params.formula}" "{params.libs}" \
        {output} \
        > {log} 2>&1
        """

#+end_src
#+begin_src R :tangle ./scripts/make_dca_design.R
#!/usr/bin/env Rscript

###############################
###   Make Rna-Seq Design   ###
###############################

# ---   Command Line Arguements   --- #
# ----------------------------------- #

args = commandArgs(trailingOnly = TRUE)
libraries_full_rds = args[1]
formula = args[2]
libs_str = args[3]
design_rds = args[4]

# ---   Load   --- #
# ---------------- #

library(tidyverse)
libraries_full = readRDS(libraries_full_rds)
libs_vect = strsplit(libs_str, " ")[[1]]

# ---   Run   --- #
# --------------- #

libs =
  data.frame(library = libs_vect) %>%
  left_join(libraries_full) %>%
  mutate(across(where(is.factor), droplevels))

design = model.matrix(as.formula(formula), data = libs)


# Splitting the formula to isolate the relevant part ("cohort")
split_formula <- strsplit(formula, " ")[[1]]
for (part in split_formula) {
  # Skipping over "+" as it is an operator
  if (part != "+") {
    colnames(design) <- gsub(part, "", colnames(design))
  }
}

rownames(design) = libs$library


saveRDS(object = design,
        file = design_rds)
#+end_src
**** Peak filtering
#+begin_src snakemake
rule peak_filtering:
    input:
        chrs = lambda wildcards: f"{ref_dir}/{atac_map[wildcards.atac_set]['species']}_peak_chrs.txt",
        libs = f"{datamodel_dir}/lists/libraries_full.rds",
        peaks = lambda wildcards: expand(f"{atac_dir}/peaks/{{library}}_{{build}}_{{bam_set}}_peaks.narrowPeak",
                                         library = atac_map[wildcards.atac_set]['libs'],
                                         build = atac_map[wildcards.atac_set]['build'],
                                         bam_set = atac_map[wildcards.atac_set]['bam_set']),
    log: f"{log_dir}/{{atac_set}}_peak_filtering.log",
    output:
        all = f"{atac_dir}/models/{{atac_set}}/corces_peaks_all.bed",
        clust = f"{atac_dir}/models/{{atac_set}}/corces_peaks_clust.bed",
        keep = f"{atac_dir}/models/{{atac_set}}/corces_peaks_keep.bed",
    params:
        corces_min = lambda wildcards: atac_map[wildcards.atac_set]['corces_min'],
        lib_peaks_min = lambda wildcards: atac_map[wildcards.atac_set]['lib_peaks_min'],
        out_dir = f"{atac_dir}/models/{{atac_set}}/",
        script = f"{atac_script_dir}/peak_filtering.R",
    shell:
        """
        mkdir -p {params.out_dir} &&
        Rscript {params.script} \
        {input.chrs} \
        {input.libs} \
        "{input.peaks}" \
        {params.corces_min} \
        {output.all} \
        {output.clust} \
        {params.lib_peaks_min} \
        {output.keep} > {log} 2>&1
        """
#+end_src

#+begin_src R :tangle ./scripts/peak_filtering.R
#!/usr/bin/env Rscript

################################
###   Macs2 Peak Filtering   ###
################################

args = commandArgs(trailingOnly = TRUE)
chrs_tsv = args[1]
libraries_full_rds = args[2]
peak_file_str = args[3]
corces_min = args[4]
all_peaks_bed = args[5]
cluster_bed = args[6]
lib_peaks_min = args[7]
keep_bed = args[8]

# Load required packages and data
library(tidyverse)

chrs = read_tsv(chrs_tsv, col_names = c("chr")) %>% pull(chr)
libraries_full = readRDS(libraries_full_rds)
libraries_full = libraries_full %>% select(!end)
peak_files = unlist(strsplit(peak_file_str, " "))
corces_min = as.numeric(corces_min)

# Create single peak file by library

ingest_macs2 = function(peak){
  macs2peak = read_tsv(peak,
                        col_names = c("chr","start","end","peak","score","strand","signal","neg_l10_pval","neg_l10_qval", "dsummit"))
}

ingest_macs2 <- function(peak) {
  col_names <- c("chr", "start", "end", "peak", "score", "strand", "signal", "neg_l10_pval", "neg_l10_qval", "dsummit")
  macs2peak <- read_tsv(peak, col_names = col_names)
  return(macs2peak)
}

peak_list = lapply(peak_files, ingest_macs2)
names(peak_list) = substr(gsub("^.*lib", "lib", peak_files), 1, 6)
peaks = bind_rows(peak_list, .id = "library")
peaks = peaks %>% left_join(libraries_full, by = "library")


corces_peaks =
  peaks %>%
  mutate(summit = start + dsummit) %>%
  mutate(start = summit - 250) %>%
  mutate(end = summit + 250) %>%
  # Remove sex chromosome and mitochondrial peaks here
  filter(chr %in% chrs) %>%
  group_by(library) %>%
  mutate(corces = neg_l10_pval/sum(neg_l10_pval/1000000)) %>% ungroup() %>%
  filter(corces > corces_min) %>% select(chr, start, end, library, corces, peak)


write_tsv(corces_peaks, file = all_peaks_bed, col_names = F)

system(paste0("bedtools sort -i ", all_peaks_bed, " | bedtools cluster -i - > ", cluster_bed))

clust = read_tsv(cluster_bed, col_names = c("chr","start","end","library","corces","peak","clust"))


max =
  clust %>%
  group_by(clust) %>%
  filter(n() > 2) %>%
  slice_max(corces)

keep_libs =
  max %>%
  group_by(library) %>%
  summarize(sum = n()) %>%
  filter(sum > lib_peaks_min) %>%
  pull(library)

keep = max %>% filter(library %in% keep_libs) %>% write_tsv(keep_bed, col_names = F)

write_tsv(keep, file = keep_bed, col_names = FALSE)

#+end_src

**** Make per-peak counts in BAMscale
#+begin_src snakemake

#bed = lambda wildcards: f"{atac_dir}/{{atac_set}}/{{atac_set}}_union.bed",

rule bamscale:
    input:
        bams = lambda wildcards: expand(f"{atac_dir}/bams/{{library}}_{{build}}_filt.bam",
                                        build = atac_map[wildcards.atac_set]['build'],
                                        library = atac_map[wildcards.atac_set]['libs']),
        bais = lambda wildcards: expand(f"{atac_dir}/bams/{{library}}_{{build}}_filt.bam.bai",
                                        build = atac_map[wildcards.atac_set]['build'],
                                        library = atac_map[wildcards.atac_set]['libs']),
        bed= f"{atac_dir}/models/{{atac_set}}/corces_peaks_keep.bed",
    log: f"{log_dir}/{{atac_set}}_bamscale.log",
    params:
        out_dir = f"{atac_dir}/models/{{atac_set}}/bamscale",
        tmp_dir = f"/tmp/{{atac_set}}",
        script = f"{atac_script_dir}/bamscale.sh",
    output:
        f"{atac_dir}/models/{{atac_set}}/bamscale/FPKM_normalized_coverages.tsv",
        f"{atac_dir}/models/{{atac_set}}/bamscale/raw_coverages.tsv",
    shell:
        """
        {params.script} \
        "{input.bams}" \
        "{input.bais}" \
        {input.bed} \
        {params.tmp_dir} \
        {wildcards.atac_set} \
        {params.out_dir} > {log} 2>&1
        """
#+end_src

#+begin_src bash :tangle ./scripts/bamscale.sh
#!/usr/bin/env bash

bams="${1}"
bais="${2}"
bed="${3}"
tmp_dir="${4}"
atac_set="${5}"
out_dir="${6}"

rm -rf $tmp_dir
mkdir -p $tmp_dir

echo $bams $bais | tr ' ' '\n' | parallel --max-args 1 cp {} $tmp_dir

# set the directory containing the input BAM files
bam_dir=$tmp_dir
# get a list of BAM files in the directory
bam_files=($(ls "$bam_dir"/*.bam))
# build the BAMscale command with the --bam flags
bams=""
for bam in "${bam_files[@]}"
do
bams+="--bam $bam "
done

BAMscale cov --bed $bed --outdir $out_dir --threads 16 $bams
rm -rf $tmp_dir


#+end_src

**** Fit

#+begin_src snakemake
rule atac_edger_fit:
    input:
        counts = f"{atac_dir}/models/{{atac_set}}/bamscale/raw_coverages.tsv",
        design = f"{atac_dir}/models/{{atac_set}}/design.rds",
        libs = f"{datamodel_dir}/lists/libraries_full.rds",
    log:
        f"{log_dir}/{{atac_set}}_atac_edger_fit.log",
    output:
        dge = f"{atac_dir}/models/{{atac_set}}/dge.rds",
        fit = f"{atac_dir}/models/{{atac_set}}/fit.rds",
    params:
        script = f"{atac_script_dir}/atac_edger_fit.R",
    shell:
        """
        Rscript {params.script} {input} {output} > {log} 2>&1
        """
#+end_src

#+begin_src R :tangle ./scripts/atac_edger_fit.R
#!/usr/bin/env Rscript

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
counts_tsv = args[1]
design_rds = args[2]
libs_rds = args[3]
dge_rds = args[4]
fit_rds = args[5]

library(tidyverse)
library(edgeR)

counts = read_tsv(counts_tsv)
design = readRDS(design_rds)

mat = as.matrix(counts[,-1])
row.names(mat) = counts$coordinate
colnames(mat) = substr(colnames(mat),1,6)

dge = DGEList(counts = mat)
keep = filterByExpr(dge, design)
dge = dge[keep,]
dge = calcNormFactors(dge)
dge = estimateGLMCommonDisp(dge, design)
dge = estimateGLMTrendedDisp(dge, design)
dge = estimateGLMTagwiseDisp(dge, design)
fit = glmFit(dge, design)

saveRDS(dge, dge_rds)
saveRDS(fit, fit_rds)
#+end_src

**** Make RUV-adjusted ATAC-seq counts

BAMscale counts are adjusted with RUVseq per [[cite:&gontarz2020]]

#+begin_src snakemake
rule atac_ruv:
    input:
        counts = f"{atac_dir}/models/{{atac_set}}/bamscale/raw_coverages.tsv",
        datmod = f"{datamodel_dir}/lists/libraries_full.rds",
        design = f"{atac_dir}/models/{{atac_set}}/design.rds",
    log: f"{log_dir}/{{atac_set}}_ruvk{{ruv_k}}.log",
    output:
        counts = f"{atac_dir}/models/{{atac_set}}/ruv/{{atac_set}}_ruv{{ruv_k}}_counts.rds",
        fit = f"{atac_dir}/models/{{atac_set}}/ruv/ruv_{{ruv_k}}_fit.rds",
    params:
        ruv_k = lambda wildcards: wildcards.ruv_k,
        script = f"{atac_script_dir}/atac_ruv.R",
    shell:
        """
        Rscript {params.script} {input} {params.ruv_k} {output} >& {log}
        """
#+end_src

#+begin_src R :tangle ./scripts/atac_ruv.R
#!/usr/bin/env Rscript

##############################
###   Human Dca With Rvu   ###
##############################

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
counts_tsv = args[1]
libraries_full_rds = args[2]
design_rds = args[3]
ruv_k = args[4]
ruv_counts_rds = args[5]
fit_rds = args[6]

# Load required packages, data, and functions
library(RUVSeq)
library(tidyverse)
libraries_full = readRDS(libraries_full_rds)
counts = read_tsv(counts_tsv)
design = readRDS(design_rds)

# Setup data objects
mat = as.matrix(counts[,-1])
row.names(mat) = counts$coordinate
colnames(mat) = substr(colnames(mat),1,6)

model_df = as.data.frame(design)
model_df$'(Intercept)' <- NULL

mat <- mat[, rownames(model_df)]

set = newSeqExpressionSet(mat,
                          phenoData = AnnotatedDataFrame(model_df))

dge <- DGEList(counts = counts(set))
y <- DGEList(counts = counts(set))
y <- calcNormFactors(y, method = "upperquartile")
y <- estimateGLMCommonDisp(y, design)
y <- estimateGLMTagwiseDisp(y, design)
fit <- glmFit(y, design)
dev <- residuals(fit, type="deviance")
peaks = row.names(dev)


adjust <- RUVr(set, peaks, k = as.numeric(ruv_k), dev)
adjust_counts = normCounts(adjust)

saveRDS(adjust_counts, ruv_counts_rds)

adjust_counts = adjust_counts + 1
dge = DGEList(counts = adjust_counts)
dge = calcNormFactors(dge)
dge = estimateGLMCommonDisp(dge, design)
dge = estimateGLMTrendedDisp(dge, design)
dge = estimateGLMTagwiseDisp(dge, design)
fit = glmFit(dge, design)

saveRDS(fit, fit_rds)
#+end_src
**** PCA
#+begin_src R :tangle no
#!/usr/bin/env Rscript

####################
###   Atac Pca   ###
####################

# --- Setup --- #
args = commandArgs(trailingOnly = TRUE)
counts_tsv = args[1]
libraries_full_rds = args[2]
fit_rds  = args[3]
pca_pdf = args[4]


# Load required packages, data, and functions
library(edgeR)
library(cowplot)
library(RUVSeq)
library(tidyverse)
library(ggrepel)
library(patchwork)

libraries_full = readRDS(libraries_full_rds)
counts = read_tsv(counts_tsv)
keep = read_tsv(keep_tsv)

counts_pca <- function(mat, libraries_full) {
  dge <- DGEList(counts = mat)
  dge <- calcNormFactors(dge)
  logcpm <- cpm(dge, log = TRUE, prior.count = 3)
  pca <- prcomp(t(logcpm))
  pve_pc1 = round(100*summary(pca)$importance[2,1])
  pve_pc2 = round(100*summary(pca)$importance[2,2])
  tab = as.data.frame(pca$x) %>%
    rownames_to_column(var = "library") %>%
    left_join(libraries_full, by = "library") %>%
    as_tibble()
  plot =
    ggplot(tab, aes(x = PC1, y = PC2, shape = gy, color = post_ir_d, label = library)) +
    geom_point(size = 4) +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    geom_text_repel()
  return(plot)
}

mat = as.matrix(counts[,-1])
row.names(mat) = counts$coordinate
colnames(mat) = substr(colnames(mat),1,6)

mat2 = mat[, colnames(mat) %in% keep$library]

counts_pca(mat2, libraries_full)

(group =
   data.frame(library = colnames(mat2)) %>%
   left_join(libraries_full) %>%
   pull(cohort) %>%
   droplevels())

set = newSeqExpressionSet(mat2,
                          phenoData = data.frame(group, row.names = colnames(mat2)))

# Perform RUV adjustment by k unwanted factors
design <- model.matrix(~0+group, data = pData(set))
y <- DGEList(counts = counts(set), group = group)
y <- calcNormFactors(y, method = "upperquartile")
#y <- calcNormFactors(y)
y <- estimateGLMCommonDisp(y, design)
y <- estimateGLMTagwiseDisp(y, design)
fit <- glmFit(y, design)
dev <- residuals(fit, type="deviance")
peaks = row.names(dev)

adjust1 <- normCounts(RUVr(set, peaks, k = 1, dev))
adjust2 <- normCounts(RUVr(set, peaks, k = 2, dev))
adjust3 <- normCounts(RUVr(set, peaks, k = 3, dev))
adjust4 <- normCounts(RUVr(set, peaks, k = 4, dev))

# --- Basic Plot --- #

pca = counts_pca(mat, libraries_full)
pca_trim = counts_pca(mat2, libraries_full)
pca_k1 = counts_pca(adjust1, libraries_full)
pca_k2 = counts_pca(adjust2, libraries_full)
pca_k3 = counts_pca(adjust3, libraries_full)
pca_k4 = counts_pca(adjust4, libraries_full)

(plot = (pca +
         pca_trim +
         pca_k1 +
         pca_k2 +
         pca_k3 +
         pca_k4 +
         plot_layout(guides = "collect", nrow = 3) +
         plot_annotation(tag_levels = "A")
))

# --- Styled Plot --- #

styled = plot & theme(plot.margin = margin(.25, .25, .25, .25, "cm"),
                      plot.background = element_rect(fill = "white", color = NA),
                      axis.line = element_blank(),
                      axis.text = element_text(size = 8),
                      axis.title = element_text(size = 10),
                      legend.position = "bottom",
                      legend.box = "horizontal",
                      legend.margin = margin(10, 0, 0, 0))

# --- Save --- #

styled2 <- ggdraw(styled) +
  draw_label("PRELIMINARY", color = "gray", angle = 45, alpha = 0.5, size = 100)

if (!is.null(commandArgs(trailingOnly = TRUE))) {
  if ("--prelim" %in% commandArgs(trailingOnly = TRUE)) {
    saved_plot = styled2
  } else {
    saved_plot = styled
  }
} else {
  saved_plot = styled
}

ggsave(file = pdf, plot = saved_plot, width = 8.5, height = 11, units = "in", dpi = 300)

save(pca, pca_trim, pca_k1, pca_k2, pca_k3, pca_k4, plot, styled, file = rda)

#+end_src
library(cowplot)
library(ggrepel)

#+begin_src R :tangle no
#!/usr/bin/env Rscript

####################
###   Atac Pca   ###
####################

# --- Setup --- #
args = commandArgs(trailingOnly = TRUE)
counts_tsv = args[1]
libraries_full_rds = args[2]
keep_tsv = args[3]
pdf = args[4]
rda = args[5]

# Load required packages, data, and functions
library(edgeR)
library(cowplot)
library(RUVSeq)
library(tidyverse)
library(ggrepel)
library(patchwork)

libraries_full = readRDS(libraries_full_rds)
counts = read_tsv(counts_tsv)
keep = read_tsv(keep_tsv)

counts_pca <- function(mat, libraries_full) {
  dge <- DGEList(counts = mat)
  dge <- calcNormFactors(dge)
  logcpm <- cpm(dge, log = TRUE, prior.count = 3)
  pca <- prcomp(t(logcpm))
  pve_pc1 = round(100*summary(pca)$importance[2,1])
  pve_pc2 = round(100*summary(pca)$importance[2,2])
  tab = as.data.frame(pca$x) %>%
    rownames_to_column(var = "library") %>%
    left_join(libraries_full, by = "library") %>%
    as_tibble()
  plot =
    ggplot(tab, aes(x = PC1, y = PC2, shape = gy, color = post_ir_d, label = library)) +
    geom_point(size = 4) +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    geom_text_repel()
  return(plot)
}

mat = as.matrix(counts[,-1])
row.names(mat) = counts$coordinate
colnames(mat) = substr(colnames(mat),1,6)

mat2 = mat[, colnames(mat) %in% keep$library]

counts_pca(mat2, libraries_full)

(group =
   data.frame(library = colnames(mat2)) %>%
   left_join(libraries_full) %>%
   pull(cohort) %>%
   droplevels())

set = newSeqExpressionSet(mat2,
                          phenoData = data.frame(group, row.names = colnames(mat2)))

# Perform RUV adjustment by k unwanted factors
design <- model.matrix(~0+group, data = pData(set))
y <- DGEList(counts = counts(set), group = group)
y <- calcNormFactors(y, method = "upperquartile")
#y <- calcNormFactors(y)
y <- estimateGLMCommonDisp(y, design)
y <- estimateGLMTagwiseDisp(y, design)
fit <- glmFit(y, design)
dev <- residuals(fit, type="deviance")
peaks = row.names(dev)

adjust1 <- normCounts(RUVr(set, peaks, k = 1, dev))
adjust2 <- normCounts(RUVr(set, peaks, k = 2, dev))
adjust3 <- normCounts(RUVr(set, peaks, k = 3, dev))
adjust4 <- normCounts(RUVr(set, peaks, k = 4, dev))

# --- Basic Plot --- #

pca = counts_pca(mat, libraries_full)
pca_trim = counts_pca(mat2, libraries_full)
pca_k1 = counts_pca(adjust1, libraries_full)
pca_k2 = counts_pca(adjust2, libraries_full)
pca_k3 = counts_pca(adjust3, libraries_full)
pca_k4 = counts_pca(adjust4, libraries_full)

(plot = (pca +
         pca_trim +
         pca_k1 +
         pca_k2 +
         pca_k3 +
         pca_k4 +
         plot_layout(guides = "collect", nrow = 3) +
         plot_annotation(tag_levels = "A")
))

# --- Styled Plot --- #

styled = plot & theme(plot.margin = margin(.25, .25, .25, .25, "cm"),
                      plot.background = element_rect(fill = "white", color = NA),
                      axis.line = element_blank(),
                      axis.text = element_text(size = 8),
                      axis.title = element_text(size = 10),
                      legend.position = "bottom",
                      legend.box = "horizontal",
                      legend.margin = margin(10, 0, 0, 0))

# --- Save --- #

styled2 <- ggdraw(styled) +
  draw_label("PRELIMINARY", color = "gray", angle = 45, alpha = 0.5, size = 100)

if (!is.null(commandArgs(trailingOnly = TRUE))) {
  if ("--prelim" %in% commandArgs(trailingOnly = TRUE)) {
    saved_plot = styled2
  } else {
    saved_plot = styled
  }
} else {
  saved_plot = styled
}

ggsave(file = pdf, plot = saved_plot, width = 8.5, height = 11, units = "in", dpi = 300)

save(pca, pca_trim, pca_k1, pca_k2, pca_k3, pca_k4, plot, styled, file = rda)

#+end_src
#+begin_src R
#!/usr/bin/env Rscript
libraries_full_rds="~/cards/data-model/lists/libraries_full.rds"
counts_tsv =  "~/cards/analysis/atac/human/dca/human_hg38.raw_coverages.tsv"
keep_tsv = "~/cards/data-model/lists/human_atac_simple.tsv"

# Load required packages, data, and functions
library(edgeR)
library(RUVSeq)
library(tidyverse)
library(ggrepel)
library(patchwork)
libraries_full = readRDS(libraries_full_rds)
counts = read_tsv(counts_tsv)
keep = read_tsv(keep_tsv)

counts_pca <- function(mat, libraries_full) {
  dge <- DGEList(counts = mat)
  dge <- calcNormFactors(dge)
  logcpm <- cpm(dge, log = TRUE, prior.count = 3)
  pca <- prcomp(t(logcpm))
  pve_pc1 = round(100*summary(pca)$importance[2,1])
  pve_pc2 = round(100*summary(pca)$importance[2,2])
  tab = as.data.frame(pca$x) %>%
    rownames_to_column(var = "library") %>%
    left_join(libraries_full, by = "library") %>%
    as_tibble()
  plot =
    ggplot(tab, aes(x = PC1, y = PC2, shape = gy, color = post_ir_d, label = library)) +
    geom_point(size = 4) +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    geom_text_repel()
  return(plot)
}

mat = as.matrix(counts[,-1])
row.names(mat) = counts$coordinate
colnames(mat) = substr(colnames(mat),1,6)

mat2 = mat[, colnames(mat) %in% keep$library]

counts_pca(mat2, libraries_full)

(group =
   data.frame(library = colnames(mat2)) %>%
   left_join(libraries_full) %>%
   pull(cohort) %>%
   droplevels())

set = newSeqExpressionSet(mat2,
                          phenoData = data.frame(group, row.names = colnames(mat2)))

# Perform RUV adjustment by k unwanted factors
design <- model.matrix(~0+group, data = pData(set))
y <- DGEList(counts = counts(set), group = group)
y <- calcNormFactors(y, method = "upperquartile")
y <- estimateGLMCommonDisp(y, design)
y <- estimateGLMTagwiseDisp(y, design)
fit <- glmFit(y, design)
dev <- residuals(fit, type="deviance")
peaks = row.names(dev)


adjust1 <- normCounts(RUVr(set, peaks, k = 1, dev))
adjust2 <- normCounts(RUVr(set, peaks, k = 2, dev))
adjust3 <- normCounts(RUVr(set, peaks, k = 3, dev))
adjust4 <- normCounts(RUVr(set, peaks, k = 4, dev))

pca = counts_pca(mat, libraries_full)
pca_trim = counts_pca(mat2, libraries_full)
pca_k1 = counts_pca(adjust1, libraries_full)
pca_k2 = counts_pca(adjust2, libraries_full)
pca_k3 = counts_pca(adjust3, libraries_full)
pca_k4 = counts_pca(adjust4, libraries_full)

# create the combined plot using patchwork
(combined_plot = (pca +
                  pca_trim +
                  pca_k1 +
                  pca_k2 +
                  pca_k3 +
                  pca_k4 +
                  plot_layout(guides = "collect", nrow = 3) +
                  plot_annotation(tag_levels = "A")
))

# set the dimensions of the combined plot
combined_plot <- combined_plot + theme(plot.margin = margin(1, 1, 1, 1, "cm"),
                                        plot.background = element_rect(fill = "white", color = NA),
                                        axis.line = element_blank(),
                                        axis.text = element_text(size = 8),
                                        axis.title = element_text(size = 10))
# set the dimensions of the combined plot
combined_plot <- combined_plot & theme(plot.margin = margin(.25, .25, .25, .25, "cm"),
                                        plot.background = element_rect(fill = "white", color = NA),
                                        axis.line = element_blank(),
                                        axis.text = element_text(size = 8),
                                        axis.title = element_text(size = 10),
                                        legend.position = "bottom",
                                        legend.box = "horizontal",
                                        legend.margin = margin(10, 0, 0, 0))
ggsave(file = "~/cards/analysis/atac/human/dca/human_ruv_pca.pdf", plot = combined_plot, width = 8.5, height = 11, units = "in", dpi = 300)

#########1#########2#########3#########4#########5#########6#########7#########8
counts_tsv =  "~/cards/analysis/atac/mouse/dca/mouse_mm10.raw_coverages.tsv"
keep_tsv = "~/cards/data-model/lists/mouse_atac_simple.tsv"

counts = read_tsv(counts_tsv)
keep = read_tsv(keep_tsv)

mat = as.matrix(counts[,-1])
row.names(mat) = counts$coordinate
colnames(mat) = substr(colnames(mat),1,6)

mat2 = mat[, colnames(mat) %in% keep$library]

counts_pca(mat2, libraries_full)

(group =
   data.frame(library = colnames(mat2)) %>%
   left_join(libraries_full) %>%
   pull(cohort) %>%
   droplevels())

set = newSeqExpressionSet(mat2,
                          phenoData = data.frame(group, row.names = colnames(mat2)))

# Perform RUV adjustment by k unwanted factors
design <- model.matrix(~0+group, data = pData(set))
y <- DGEList(counts = counts(set), group = group)
y <- calcNormFactors(y, method = "upperquartile")
y <- estimateGLMCommonDisp(y, design)
y <- estimateGLMTagwiseDisp(y, design)
fit <- glmFit(y, design)
dev <- residuals(fit, type="deviance")
peaks = row.names(dev)

adjust1 <- normCounts(RUVr(set, peaks, k = 1, dev))
adjust2 <- normCounts(RUVr(set, peaks, k = 2, dev))
adjust3 <- normCounts(RUVr(set, peaks, k = 3, dev))
adjust4 <- normCounts(RUVr(set, peaks, k = 4, dev))

pca = counts_pca(mat, libraries_full)
pca_k1 = counts_pca(adjust1, libraries_full)
pca_k2 = counts_pca(adjust2, libraries_full)
pca_k3 = counts_pca(adjust3, libraries_full)
pca_k4 = counts_pca(adjust4, libraries_full)

# create the combined plot using patchwork
(combined_plot = (pca +
                  pca_k1 +
                  pca_k2 +
                  pca_k3 +
                  pca_k4 +
                  plot_layout(guides = "collect", nrow = 3) +
                  plot_annotation(tag_levels = "A")
))

# set the dimensions of the combined plot
combined_plot <- combined_plot + theme(plot.margin = margin(1, 1, 1, 1, "cm"),
                                        plot.background = element_rect(fill = "white", color = NA),
                                        axis.line = element_blank(),
                                        axis.text = element_text(size = 8),
                                        axis.title = element_text(size = 10))
# set the dimensions of the combined plot
combined_plot <- combined_plot & theme(plot.margin = margin(.25, .25, .25, .25, "cm"),
                                        plot.background = element_rect(fill = "white", color = NA),
                                        axis.line = element_blank(),
                                        axis.text = element_text(size = 8),
                                        axis.title = element_text(size = 10),
                                        legend.position = "bottom",
                                        legend.box = "horizontal",
                                        legend.margin = margin(10, 0, 0, 0))
ggsave(file = "~/cards/analysis/atac/mouse/dca/mouse_ruv_pca.pdf", plot = combined_plot, width = 8.5, height = 11, units = "in", dpi = 300)


(watermark_size = max(ggplot_build(combined_plot)$data[[1]]$xmax) *max(ggplot_build(plot)$data[[1]]$ymax_final))



styled2 <- ggdraw(combined_plot) +
  draw_label("PRELIMINARY", color = "gray", angle = 45, alpha = 0.5, size = 50)

styled2
# Check if there are any command-line arguments
if (!is.null(commandArgs(trailingOnly = TRUE))) {
  # Check if "--prelim" is present in the command-line arguments
  if ("--prelim" %in% commandArgs(trailingOnly = TRUE)) {
    saved_plot = styled2
  } else {
    saved_plot = styled
  }
} else {
  # Default behavior when there are no command-line arguments
  saved_plot = styled
}
#+end_src
#+begin_src R

library(tidyverse)
library(edgeR)

counts = read_tsv(counts_tsv)
design = readRDS(design_rds)

mat = as.matrix(counts[,-1])
row.names(mat) = counts$coordinate
colnames(mat) = substr(colnames(mat),1,6)

dge = DGEList(counts = mat)
keep = filterByExpr(dge, design)
dge = dge[keep,]
dge = calcNormFactors(dge)



logcpm = edgeR::cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
head(logcpm)

pca = prcomp(t(as.matrix(logcpm[,-1])))

(pve_pc1=round(100*summary(pca)$importance[2,1]))

(pve_pc2=round(100*summary(pca)$importance[2,2]))

plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library") %>%
  ggplot(., aes(x = PC1, y = PC2)) +
  geom_point(size = 4) +
  xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
  ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
  coord_fixed(ratio = 1)
plot


library(cowplot)
library(ggrepel)
library(tidyverse)

libraries_full_rds="~/cards/data-model/lists/libraries_full.rds"
libraries_full = readRDS(libraries_full_rds)

plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library") %>%
  left_join(libraries_full, by = "library") %>%
  ggplot(., aes(x = PC1, y = PC2, color = get(factor_vec[[1]]), label = library)) +
  geom_point(size = 4) +
  geom_text_repel() +
  scale_color_discrete(name = factor_vec[[1]]) +
  xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
  ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
  coord_fixed(ratio = 1)

if (length(factor_vec) >= 2 && !is.null(factor_vec[[2]])) {
  plot = plot +
    aes(shape = get(factor_vec[[2]])) +
    scale_shape_discrete(name = factor_vec[[2]])
}
plot

plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library") %>%
  left_join(libraries_full, by = "library") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort, shape = strain, label = library)) +
  geom_point(size = 4) +
  geom_text_repel() +
  xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
  ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
  coord_fixed(ratio = 1)
plot
#+end_src
*** Workflow 3: Differential chromatin accessibility
**** Make edgeR DCA contrast

From RUVseq-adjusted BAMscale peak counts, differential chromatin accessibility is quantified with edgeR

#+begin_src snakemake
rule atac_edger_dca:
    input:
        design = lambda wildcards: dca_map[wildcards.contrast]['design'],
        fit = lambda wildcards: dca_map[wildcards.contrast]['fit'],
    log: f"{log_dir}/{{contrast}}_atac_edger_dca.log",
    output: f"{atac_dir}/contrasts/{{contrast}}/{{contrast}}.tsv",
    params:
        contrast_str = lambda wildcards: dca_map[wildcards.contrast]['contrast_str'],
        script = f"{atac_script_dir}/atac_edger_dca.R",
    shell:
        """
        Rscript {params.script} \
        {input.design} \
        {input.fit} \
        "{params.contrast_str}" \
        {output} > {log} 2>&1
        """
#+end_src

#+begin_src R :tangle ./scripts/atac_edger_dca.R
#!/usr/bin/env Rscript

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
design_rds = args[1]
fit_rds = args[2]
contrast_string = args[3]
res_tsv = args[4]

# Load required packages, data, and functions
library(edgeR)
library(tidyverse)

design = readRDS(design_rds)
fit = readRDS(fit_rds)

contrast <- makeContrasts(eval(parse(text = contrast_string)), levels=design)
lrt = glmLRT(fit, contrast = contrast)

res =
  as.data.frame(topTags(lrt, n = Inf)) %>%
  rownames_to_column(var = "coordinate") %>%
  as_tibble()

write_tsv(res, file = res_tsv)
#+end_src

*** Shared
**** Peak calling
:PROPERTIES:
:ID:       96efb30b-67c7-4df9-8c85-e2bd2fc6707f
:END:
Broad peak calling per [[cite:&reske2020]]
Reference Narrow peak as in cite:corces2018 and cite:hendrickson2017

#+begin_src snakemake
rule macs2:
    input:
        f"{atac_dir}/bams/{{library}}_{{build}}_{{bam_set}}.bam",
    log:
        f"{log_dir}/{{library}}_{{build}}_{{bam_set}}_macs2.log",
    output:
        broad = f"{atac_dir}/peaks/{{library}}_{{build}}_{{bam_set}}_peaks.broadPeak",
        narrow = f"{atac_dir}/peaks/{{library}}_{{build}}_{{bam_set}}_peaks.narrowPeak",
    params:
        gsize = lambda wildcards: build_map[wildcards.build]['gsize'],
        outdir = f"{atac_dir}/peaks",
        script = f"{atac_script_dir}/macs2.sh",
    shell:
        """
        name=$(basename -s .bam {input})
        {params.script} \
        {input} \
        $name \
        {params.gsize} \
        {params.outdir} &> {log}
        """
#+end_src

#+begin_src bash :tangle ./scripts/macs2.sh

inbam=$1
name=$2
gsize=$3
outdir=$4

macs2 callpeak --treatment $inbam \
      --format BAMPE \
      --name $name \
      --gsize $gsize \
      --broad \
      --broad-cutoff 0.05 \
      --keep-dup all \
      --outdir $outdir

macs2 callpeak --treatment $inbam \
      --bdg \
      --call-summits \
      --extsize 150 \
      --format BAMPE \
      --gsize $gsize \
      --keep-dup all \
      --name ${name} \
      --nolambda \
      --outdir $outdir \
      -p 0.01 \
      --shift -75 \
      --SPMR \
      --nomodel

#+end_src

**** TEST Peak annotation
:PROPERTIES:
:ID:       f0124001-2d9f-47a3-a55a-7004bc5db0ee
:END:

#+begin_src snakemake
rule peak_annotation:
    input:
        f"{atac_dir}/peaks/{{library}}_{{build}}_{{bam_set}}_peaks.{{peaktype}}Peak",
    log:
        f"{log_dir}/{{library}}_{{build}}_{{bam_set}}_{{peaktype}}_peak_annotation.log",
    output:
        f"{atac_dir}/peaks/{{library}}_{{build}}_{{bam_set}}_peaks.{{peaktype}}_anno.bed",
    params:
        script = f"{atac_script_dir}/peak_annotation.R",
        txdb = lambda wildcards: build_map[wildcards.build]['txdb'],
    shell:
        """
        Rscript {params.script} {input} "{params.txdb}" {output} > {log} 2>&1
        """
#+end_src

#+begin_src R :tangle ./scripts/peak_annotation.R
#!/usr/bin/env Rscript

#################################
###   Macs2 Peak Annotation   ###
#################################

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
in_peak_bed = args[1]
txdb = args[2]
out_peak_bed = args[3]

# Load required packages, data, and functions
library(tidyverse)
library(ChIPpeakAnno)
library(rtracklayer)
library(ChIPseeker)
library(txdb, character.only = T)

peaks = rtracklayer::import(in_peak_bed)
anno = annotatePeak(peaks, TxDb = get(txdb))
anno = as_tibble(anno)
anno =
  anno %>% mutate(simple = case_when(
                    grepl("Promoter", annotation) ~ "promoter",
                    grepl("Exon", annotation) ~ "exon",
                    grepl("Intron", annotation) ~ "intron",
                    grepl("3' UTR", annotation) ~ "utr3",
                    grepl("5' UTR", annotation) ~ "utr5",
                    grepl("Distal Intergenic", annotation) ~ "intergenic",
                    grepl("Downstream", annotation) ~ "downstream",
                    TRUE ~ annotation
                  )) %>%
  dplyr::select(seqnames, start, end, name, score, strand, pValue, qValue, width, simple, everything())

write_tsv(anno, out_peak_bed, col_names = F)

#+end_src

*** Development
:PROPERTIES:
:header-args:snakemake: :tangle no
:header-args:r: :tangle no
:END:
**** Peak counting
***** MACS2 broad peak calling
#+begin_src snakemake
rule macs2_broad:
    input: f"{atac_dir}/{{species}}/bams/{{library}}_{{build}}_{{proc}}.bam",
    log: f"{log_dir}/{{library}}_{{species}}_{{build}}_{{proc}}_peaks.broadPeak",
    output: f"{atac_dir}/{{species}}/peaks/{{library}}_{{build}}_{{proc}}_peaks.broadPeak",
    params:
        gsize = lambda wildcards: human_gsize if wildcards.species == "human" else mouse_gsize,
        outdir = f"{atac_dir}/{{species}}/peaks",
        script = f"{atac_script_dir}/macs2_broad.sh",
    shell:
        """
        name=$(basename -s .bam {input})
        {params.script} \
        {input} \
        $name \
        {params.gsize} \
        {params.outdir} &> {log}
        """
#+end_src
#+begin_src bash :tangle ./scripts/macs2_broad.sh

inbam=$1
name=$2
gsize=$3
outdir=$4

macs2 callpeak -t $inbam -f BAMPE -n $name -g $gsize --broad --broad-cutoff 0.05 --keep-dup all --outdir $outdir

#+end_src

***** MACS2 narrow peak calling
- Snakemake
  #+begin_src snakemake
rule macs2_narrow:
    input: f"{atac_dir}/{{species}}/bams/{{library}}_{{build}}_{{proc}}.bam",
    log: f"{log_dir}/{{library}}_{{build}}_{{species}}_{{proc}}_macs2_narrow.log",
    output: f"{atac_dir}/{{species}}/peaks/{{library}}_{{build}}_{{proc}}_multi_peaks.narrowPeak",
    params:
        gsize = lambda wildcards: human_gsize if wildcards.species == "human" else mouse_gsize,
        outdir = f"{atac_dir}/{{species}}/peaks",
        script = f"{atac_script_dir}/macs2_narrow.sh",
    shell:
        """
        name=$(basename -s .bam {input})
        {params.script} \
        {input} \
        $name \
        {params.gsize} \
        {params.outdir} &> {log}
        """
#+end_src
- Script
  #+begin_src bash :tangle ./scripts/macs2_narrow.sh
#!/usr/bin/env bash
set -o errexit   # abort on nonzero exitstatus
set -o nounset   # abort on unbound variable
set -o pipefail  # don't hide errors within pipes

inbam=$1
name=$2
gsize=$3
outdir=$4

macs2 callpeak --treatment $inbam \
      --bdg \
      --call-summits \
      --extsize 150 \
      --format BAMPE \
      --gsize $gsize \
      --keep-dup all \
      --name ${name}_multi \
      --nolambda \
      --outdir $outdir \
      -p 0.01 \
      --shift -75 \
      --SPMR \
      --nomodel
#+end_src
- Reference Narrow peak as in cite:corces2018 and cite:hendrickson2017

**** Motif enrichment with Homer
***** Prepare DCA bed files

Takes differentially accessible regions from a specific contrast and returns bedfiles formatted for homer.

#+begin_src snakemake
rule homer_bed_from_dca:
    input:
        dca = f"{atac_dir}/{{species}}/dca/{{species}}_atac_k{{rvu_k}}_{{contrast}}.tsv",
        anno = f"{atac_dir}/{{species}}/dca/{{species}}_annotation.tsv",
    log: f"{log_dir}/homer_bed_from_dca_{{species}}_k{{rvu_k}}_{{contrast}}.log",
    output:
        f"{atac_dir}/{{species}}/homer/bed/homer_{{species}}_k{{rvu_k}}_{{contrast}}_up_all.bed",
        f"{atac_dir}/{{species}}/homer/bed/homer_{{species}}_k{{rvu_k}}_{{contrast}}_down_all.bed",
        f"{atac_dir}/{{species}}/homer/bed/homer_{{species}}_k{{rvu_k}}_{{contrast}}_up_promoter.bed",
        f"{atac_dir}/{{species}}/homer/bed/homer_{{species}}_k{{rvu_k}}_{{contrast}}_down_promoter.bed",
        f"{atac_dir}/{{species}}/homer/bed/homer_{{species}}_k{{rvu_k}}_{{contrast}}_up_enhancer.bed",
        f"{atac_dir}/{{species}}/homer/bed/homer_{{species}}_k{{rvu_k}}_{{contrast}}_down_enhancer.bed",
    params:
        qval = 0.05,
        script = f"{atac_script_dir}/homer_bed_from_dca.R",
    shell:
        """
        Rscript {params.script} {input} {params.qval} {output} > log 2>&1
        """
#+end_src
#+begin_src R :tangle ./scripts/homer_bed_from_dca.R
#!/usr/bin/env Rscript

################################
###   Make Homer Bed Files   ###
################################

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
dca_tsv = args[1]
anno_tsv = args[2]
qval_cut = args[3]
upbed_out = args[4]
downbed_out = args[5]
upbed_p_out = args[6]
downbed_p_out = args[7]
upbed_e_out = args[8]
downbed_e_out = args[9]

# Load required packages, data, and functions
library(tidyverse)
dca = read_tsv(dca_tsv)
anno = read_tsv(anno_tsv)

anno = anno %>% select(!c("start", "end","strand"))

# Main
up_tib =
  dca %>% filter(qval < qval_cut &
               logfc >0)

down_tib =
  dca %>% filter(qval < qval_cut &
               logfc < 0)

make_homer_bed = function(tibble){
  bed =
    tibble %>% mutate(chr = gsub(":.*$","",coordinate)) %>%
    mutate(start = gsub("^chr\\d+:(\\d+)-\\d+$", "\\1", coordinate)) %>%
    mutate(end = gsub("^chr\\d+:\\d+-(\\d+)$", "\\1", coordinate)) %>%
    mutate(col5 = "") %>%
    mutate(strand = "+") %>%
    select(chr, start, end, coordinate, col5, strand)
}

up_bed = make_homer_bed(up_tib)
up_bed %>% write_tsv(upbed_out, col_names = FALSE)
down_bed = make_homer_bed(down_tib)
down_bed %>% write_tsv(downbed_out, col_names = FALSE)


subset <- function(peaks_tibble, anno_tibble, annotation_string){
  result <- peaks_tibble %>%
    left_join(anno_tibble, "coordinate") %>%
    filter(grepl(annotation_string, annotation)) %>%
    select(chr, start, end, coordinate, col5, strand)

  return(result)
}

subset(up_bed, anno, "Promoter") %>% write_tsv(upbed_p_out, col_names = FALSE)
subset(down_bed, anno, "Promoter") %>% write_tsv(downbed_p_out, col_names = FALSE)
subset(up_bed, anno, "Distal") %>% write_tsv(upbed_e_out, col_names = FALSE)
subset(down_bed, anno, "Distal") %>% write_tsv(downbed_e_out, col_names = FALSE)
#+end_src

***** Find genome-wide enrichment
#+begin_src snakemake
rule homer_genome_enrich:
    input:
        bed = f"{atac_dir}/{{species}}/homer/bed/homer_{{species}}_k{{rvu_k}}_{{contrast}}_{{direction}}_{{set}}.bed",
        fasta = lambda wildcards: get_genome_fasta(wildcards.species),
    log: f"{log_dir}/homer_genome_enrich_{{species}}_{{rvu_k}}_{{contrast}}_{{direction}}_{{set}}.log",
    output:
        dir = directory(f"{atac_dir}/{{species}}/homer/genome/{{species}}_k{{rvu_k}}_{{contrast}}_{{direction}}_{{set}}"),
        known_tsv = f"{atac_dir}/{{species}}/homer/genome/{{species}}_k{{rvu_k}}_{{contrast}}_{{direction}}_{{set}}/knownResults.txt",
        denovo_html = f"{atac_dir}/{{species}}/homer/genome/{{species}}_k{{rvu_k}}_{{contrast}}_{{direction}}_{{set}}/homerResults.html",
    params:
        script = f"{atac_script_dir}/homer_genome_enrich.sh",
        threads = 4,
    shell:
       """
       {params.script} {input.bed} {input.fasta} {output.dir} {params.threads} &> {log}
       cp {output.known_tsv} $(dirname {output.known_tsv})_knownResults.txt
       """
#+end_src
#+begin_src bash :tangle ./scripts/homer_genome_enrich.sh
bed="${1}"
fasta="${2}"
outdir="${3}"
threads="${4}"

findMotifsGenome.pl $bed $fasta $outdir -p $threads

#+end_src
- Reference
  - [[id:33a4b4a6-f22f-4e12-8c27-7170bb1e1a9e][homer in biotools.org]]
  - old code
    - homer
      #+begin_src R
    library(tidyverse)

    ir48h_sham = as_tibble(read.csv("/mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir48h_sham.csv", header=T))
    ir6w_sham = as_tibble(read.csv("/mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir6w_sham.csv", header=T))
    ir6w_ir48h = as_tibble(read.csv("/mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir6w_ir48h.csv", header=T))

    down_ensembl = function(res_tbl, fdr, lfc){
    motifs_down_ensembl = res_tbl %>%
    filter(grepl("promoter", annotation, ignore.case = T)) %>%
    filter(FDR < fdr) %>%
    filter(rep.logFC < lfc) %>%
    pull(geneId)
    return(motifs_down_ensembl)
    }

    ir48h_sham_down = down_ensembl(ir48h_sham, .000005, -1.5)
    ir6w_sham_down = down_ensembl(ir6w_sham, .2, 0)
    ir6w_ir48h_down = down_ensembl(ir6w_ir48h, .2, 0)

    up_ensembl = function(res_tbl, fdr, lfc){
    motifs_down_ensembl = res_tbl %>%
    filter(grepl("promoter", annotation, ignore.case = T)) %>%
    filter(FDR < fdr) %>%
    filter(rep.logFC > lfc) %>%
    pull(geneId)
    return(motifs_down_ensembl)
    }

    ir48h_sham_up = up_ensembl(ir48h_sham, .2, 0)
    ir6w_sham_up = up_ensembl(ir6w_sham, .0000000000000000000000000000000000000005, 4)
    ir6w_ir48h_up = up_ensembl(ir6w_ir48h, .000000000000000000000000000000000000000005, 5)

    writeLines(as.character(ir48h_sham_down), "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir48h_sham_down.txt")
    writeLines(as.character(ir6w_sham_down), "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir6w_sham_down.txt")
    writeLines(as.character(ir6w_ir48h_down), "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir6w_ir48h_down.txt")
    writeLines(as.character(ir48h_sham_up), "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir48h_sham_up.txt")
    writeLines(as.character(ir6w_sham_up), "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir6w_sham_up.txt")
    writeLines(as.character(ir6w_ir48h_up), "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir6w_ir48h_up.txt")

    #+end_src
      #+begin_src bash
    mkdir -p /mnt/ris/jschwarz/cardiac-radiobiology/tmp/homer/ir6w_sham_up

    nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir6w_sham_up.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/tmp/homer/ir6w_sham_up -fdr 10 -p 12

    nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/tmp/ir6w_ir48h_up.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/tmp/homer/ir6w_48hr_up -fdr 10 -p 12

    #+end_src
***** Extract homer denovo motifs from html
#+begin_src snakemake
rule homer_denovo_tsv:
    input: f"{atac_dir}/{{species}}/homer/genome/{{species}}_k{{rvu_k}}_{{contrast}}_{{direction}}_{{set}}/homerResults.html",
    log: f"{log_dir}/{{species}}_k{{rvu_k}}_{{contrast}}_{{direction}}_{{set}}_homer_denovo.log",
    output: f"{atac_dir}/{{species}}/homer/genome/{{species}}_k{{rvu_k}}_{{contrast}}_{{direction}}_{{set}}_homer_denovo.tsv",
    run:
        import os
        from bs4 import BeautifulSoup
        import csv

        # Define the file path
        file_path = input[0]

        # Expand the tilde to the user home directory
        file_path = os.path.expanduser(file_path)

        # Read the HTML file
        with open(file_path, 'r') as f:
            contents = f.read()

        # Parse the HTML
        soup = BeautifulSoup(contents, 'html.parser')

        # Find the table
        table = soup.find('table')

        # Find all rows
        rows = table.find_all('tr')

        # Prepare to write to TSV
        with open(output[0], 'w') as f:
            writer = csv.writer(f, delimiter='\t')

            for row in rows:
                # Find all columns
                cols = row.find_all('td')

                # Write columns to the TSV, excluding the SVG column (the second one, index 1)
                writer.writerow([col.text for i, col in enumerate(cols) if i != 1])
#+end_src
**** Reference
:PROPERTIES:
:header-args: :tangle no
:END:
- subset DESeq2 object https://support.bioconductor.org/p/79746/
- deseq2 model design
  - https://support.bioconductor.org/p/101002/
  - for interactions https://support.bioconductor.org/p/65676/#66860)
- time course DE in DESeq2 https://master.bioconductor.org/packages/release/workflows/vignettes/rnaseqGene/inst/doc/rnaseqGene.html#time-course-experiments

**** Make ensembl txdb
- Snakemake
  #+begin_src snakemake

rule make_ensembl_txdb:
    input: f"{ref_dir}/{{build}}.gtf.gz",
    output: f"{ref_dir}/{{build}}_ensembl_txdb",
    params: script = f"{atac_script_dir}/make_ensembl_txdb.R",
    shell:
        """
        Rscript {params.script} {input}
        cp /tmp/db {output}
        """
#+end_src
- Rscript
  #+begin_src R :tangle ./scripts/make_ensembl_txdb.R
#!/usr/bin/env Rscript

#######################################
###   Make A Txdb From A Gtf File   ###
#######################################

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
ensembl_gtf = args[1]

library(GenomicFeatures)

txdb = makeTxDbFromGFF(ensembl_gtf)

saveDb(txdb, file = "/tmp/db")

#+end_src
**** Make summary peaks file of union of all peaks
#+begin_src snakemake
rule atac_peak_union:
    input:
        lambda wildcards: expand(f"{atac_dir}/peaks/{{library}}_{{build}}_peaks.{{peak_type}}",
                                 library = atac_map[wildcards.atac_set]['libs'],
                                 build = atac_map[wildcards.atac_set]['build'],
                                 peak_type = atac_map[wildcards.atac_set]['peak_type']),
    log: f"{log_dir}/{{atac_set}}_peak_union.bed",
    output: f"{atac_dir}/{{atac_set}}/{{atac_set}}_union.bed",
    params:
        script = f"{atac_script_dir}/peak_union.R",
    shell:
        """
        Rscript {params.script} "{input}" {output} >& {log}
        """
#+end_src
- [[file:./scripts/peak_union.R][Rscript]]
  #+begin_src R :tangle ./scripts/peak_union.R
#!/usr/bin/env Rscript

########################################
###   Make Atac Peak Union Bedfile   ###
########################################

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
macs2_str = args[1]
union_bed = args[2]

# Load required packages
library(BiocGenerics)
library(ChIPpeakAnno)
library(rtracklayer)

macs2 = unlist(strsplit(macs2_str, " "))
names(macs2) = substr(gsub("^.*lib","lib",macs2),1,6)

granges = lapply(macs2, toGRanges, format = "MACS2.broad")

all.peaks = Reduce(union, granges)

# export as a BED file
rtracklayer::export.bed(all.peaks, con = union_bed)

#+end_src
- Peak joins
  #+begin_src R
library(csaw)
library(rtracklayer)


macs2 = list.files("~/cards/analysis/atac/macs2/", pattern = "broad", full.names = T)

names = substr(
  gsub("^.*lib","lib",list.files("~/cards/analysis/atac/macs2/", pattern = "broad", full.names = F)),1,6)

names(bams) = names

make_grange = function(in_bam){
  tbl <- read.table(in_bam)
  colnames(tbl) = c("chrom", "start", "end")
  peaks = GRanges(tbl)
  return(peaks)
}

granges = lapply(macs2, make_grange)

all.peaks = Reduce(union, granges)

# export as a BED file
export.bed(all.peaks, "~/cards/analysis/atac/peaks/human_union.bed")
#+end_src
**** Filter to open chrom                                          :smk_rule:
- Snakemake
  #+begin_src snakemake
rule get_open_chrom:
    input:
        regfilt_bam = config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam",
    output:
        unsort_open_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_unsort_open.bam"),
        open_bam = config["data_dir"] + "/atac/bam/{library_id}_open.bam",
    shell:
        """
        workflow/scripts/get_open_chrom.sh {input.regfilt_bam} \
                                           {config[threads]} \
                                           {output.unsort_open_bam} \
                                           {output.open_bam}
        """
#+end_src
- [[file:./scripts/get_open_chrom.sh][Base script]]
  #+begin_src bash :tangle ./scripts/get_open_chrom.sh
#########1#########2#########3#########4#########5#########6#########7#########8
alignmentSieve --bam $1 \
               --maxFragmentLength 150 \
               --numberOfProcessors $2 \
               --outFile $3
samtools sort -@ $2 -o $4 $3
samtools index -@ $2 $4
#+end_src
**** Peak annotation
#+begin_src snakemake
rule peak_annotation:
    input: f"{atac_dir}/models/{{atac_set}}/{{atac_set}}_corces_peaks_keep.bed",
    log: f"{log_dir}/{{atac_set}}_peak_annotation.log",
    output: f"{atac_dir}/models/{{atac_set}}/{{atac_set}}_annotation.tsv",
    params:
        txdb = lambda wildcards: atac_map[wildcards.atac_set]['txdb'],
        bmart_dataset = lambda wildcards: atac_map[wildcards.atac_set]['bmart_dataset'],
        script = f"{atac_script_dir}/peak_annotation.R",
    shell:
        """
        Rscript {params.script} \
        {input} \
        {params.bmart_dataset} {params.txdb} \
        {output} > {log} 2>&1
        """
#+end_src

#+begin_src R :tangle no
#!/usr/bin/env Rscript

####################################
###   Bamscale Peak Annotation   ###
####################################

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
cov_bed = args[1]
bmart_dataset = args[2]
txdb = args[3]
out_tsv = args[4]

# Load required packages, data, and functions

library(ChIPseeker)
library(txdb,character.only = TRUE)
library(biomaRt)
library(GenomicRanges)
library(tidyverse)

peaks = read_tsv(cov_bed, col_names = c("chr",
                                        "start",
                                        "end",
                                        "library")) %>%
  dplyr::select(chr, start, end, library)

# Create a GRanges object from the data frame
gr <- makeGRangesFromDataFrame(peaks, start.field = "start", end.field = "end",
                               seqnames.field = "chr")

anno = annotatePeak(gr, TxDb = eval(parse(text=txdb)))
anno = as_tibble(anno)

anno = anno %>% mutate(entrezgene_id = as.numeric(geneId))

geneIds = anno %>% pull(geneId) %>% unique()

mart <- useMart("ensembl")
mart <- useDataset(bmart_dataset, mart)

names = getBM(
  filters = "entrezgene_id",
  attributes=c("ensembl_gene_id",
               "entrezgene_id",
               "description",
               "external_gene_name",
               "gene_biotype"),
  values = geneIds,
  mart = mart)
names = as_tibble(names)

final = anno %>% left_join(names, by = c("entrezgene_id")) %>%
  mutate(coordinate = paste0(seqnames, ":",start,"-",end))

final <- distinct(final, coordinate, .keep_all = TRUE)
write_tsv(final, file = out_tsv)
#+end_src
*** Reference
- [[id:22e31d06-f5df-427e-bd70-3a2ccd3f47ec][ATAC-seq]]
- [[id:f600cd95-723e-4893-8b3f-0634d8905920][Chromatin accessibility profiling methods]]
- cite:knaupp2017


** Development
*** RUV outputs
***** Make RUV-adjusted counts

#+begin_src snakemake
rule atac_ruv:
    input:
#+end_src
***** RUV-adjusted ATAC-seq counts
#+begin_src snakemake
rule atac_ruv:
    input:
        libs = f"{datamodel_dir}/lists/libraries_full.rds",
        counts = lambda wildcards: f"{atac_dir}/{{[wildcards.experiment]['species']}}/dca/{{[wildcards.experiment]['species']}}_{{[wildcards.experiment]['build']}}.raw_coverages.tsv",
        keep = lambda wildcards: f"{datamodel_dir}/lists/{{[wildcards.experiment]['species']}}_atac_simple.tsv",
    log: f"{log_dir}/{{species}}_{{build}}_{ruv_k}_atac_ruv.log",
    output:
        f"{atac_dir}/{{species}}/dca/{{species}}_atac_k{{ruv_k}}_{{contrast}}.tsv",
    params:
        script = f"{cardiac_script_dir}/atac_ruv.R",
    shell:
        """
        Rscript {params.script} {input} "{wildcards.contrast}" {output} > {log} 2>&1
        """
#+end_src

***** RVU-adjusted ATAC-seq for human
:PROPERTIES:
:ID:       e774161f-4c1c-4640-8ace-f7b48c93f3aa
:END:
#+begin_src snakemake
rule hs_rvu_atac:
    input:
        libs = f"{datamodel_dir}/lists/libraries_full.rds",
        counts = f"{atac_dir}/human/dca/human_hg38.raw_coverages.tsv",
        keep = f"{datamodel_dir}/lists/human_atac_simple.tsv",
    log: f"{log_dir}/hs_rvu_k{{rvu_k}}_atac.log",
    output:
        f"{atac_dir}/human/dca/human_atac_k{{rvu_k}}_ir1w_sham1w.tsv",
        f"{atac_dir}/human/dca/human_atac_k{{rvu_k}}_ir2w_sham2w.tsv",
    params:
        script = f"{cardiac_script_dir}/hs_rvu_atac.R",
        rvu_k = "{rvu_k}"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} {params.rvu_k} > {log} 2>&1
        """
#+end_src
#+begin_src R :tangle ./scripts/hs_rvu_atac.R
#!/usr/bin/env Rscript

##############################
###   Human Dca With Rvu   ###
##############################

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
libraries_full_rds = args[1]
counts_tsv = args[2]
keep_tsv = args[3]
ir1w_sham1w_tsv = args[4]
ir2w_sham2w_tsv = args[5]
rvu_k = args[6]

# Load required packages, data, and functions
library(RUVSeq)
library(tidyverse)
libraries_full = readRDS(libraries_full_rds)
counts = read_tsv(counts_tsv)
keep = read_tsv(keep_tsv)

# Setup data objects
mat = as.matrix(counts[,-1])
row.names(mat) = counts$coordinate
colnames(mat) = substr(colnames(mat),1,6)
mat = mat[, colnames(mat) %in% keep$library]
(group = data.frame(library = colnames(mat)) %>% left_join(libraries_full) %>% pull(cohort) %>% droplevels())
set = newSeqExpressionSet(mat,
                          phenoData = data.frame(group, row.names = colnames(mat)))

# Perform RUV adjustment by k unwanted factors
design <- model.matrix(~0+group, data = pData(set))
y <- DGEList(counts = counts(set), group = group)
y <- calcNormFactors(y, method = "upperquartile")
y <- estimateGLMCommonDisp(y, design)
y <- estimateGLMTagwiseDisp(y, design)
fit <- glmFit(y, design)
dev <- residuals(fit, type="deviance")
peaks = row.names(dev)
adjust <- RUVr(set, peaks, k = as.numeric(rvu_k), dev)

# Perform DCA by EdgeR on adjusted gene expression
if (rvu_k != 0) {
  modcounts = normCounts(adjust)
} else {
  modcounts = mat
}


design = model.matrix(~ 0 + group)
dge = DGEList(counts = modcounts)
dge = calcNormFactors(dge)
dge = estimateGLMCommonDisp(dge, design)
dge = estimateGLMTrendedDisp(dge, design)
dge = estimateGLMTagwiseDisp(dge, design)
fit = glmFit(dge, design)

name_mapping= data.frame(newname = c("logfc", "logcpm", "lr", "pval", "qval"),
                 oldname = c("logFC", "logCPM", "LR", "PValue", "FDR"))

# Generate specific comparisons
ir1w_sham1w_cont = makeContrasts(groupir1w - groupsham1w, levels = colnames(design))
ir1w_sham1w_lrt = glmLRT(fit, contrast = ir1w_sham1w_cont)
ir1w_sham1w = data.frame(topTags(ir1w_sham1w_lrt, n = nrow(dge))$table) %>% rownames_to_column(var = "coordinate") %>% as_tibble() %>%
  rename(!!!setNames(as.list(name_mapping$oldname), name_mapping$newname)) %>%
  write_tsv(ir1w_sham1w_tsv)

ir2w_sham2w_cont = makeContrasts(groupir2w - groupsham2w, levels = colnames(design))
ir2w_sham2w_lrt = glmLRT(fit, contrast = ir2w_sham2w_cont)
ir2w_sham2w = data.frame(topTags(ir2w_sham2w_lrt, n = nrow(dge))$table) %>% rownames_to_column(var = "coordinate") %>% as_tibble() %>%
  rename(!!!setNames(as.list(name_mapping$oldname), name_mapping$newname)) %>%
  write_tsv(ir2w_sham2w_tsv)
#+end_src

#+caption: label:fig_human_ruv_cor_ir1w_sham1w
[[file:/mnt/ris/jschwarz/Active/cardiac-radiobiology/results/human/atac/qc/rvu_spearman/human_ir1w_sham1w.pdf]]

#+caption: label:fig_human_ruv_cor_ir2w_sham2w
[[file:/mnt/ris/jschwarz/Active/cardiac-radiobiology/results/human/atac/qc/rvu_spearman/human_ir2w_sham2w.pdf]]

***** RVU-adjusted ATAC-seq for mouse

Performs RUVseq adjustment of open chromatin region raw counts. Factor k defines
#+begin_src snakemake
rule ms_rvu_atac:
    input:
        libs = f"{datamodel_dir}/lists/libraries_full.rds",
        counts = f"{atac_dir}/mouse/dca/mouse_mm10.raw_coverages.tsv",
        keep = f"{atac_dir}/mouse/qc/filtered_mouse_atac_simple.tsv",
    log: f"{log_dir}/ms_rvu_k{{rvu_k}}_atac.log",
    output:
        f"{atac_dir}/mouse/dca/mouse_atac_k{{rvu_k}}_ir2d_sham.tsv",
        f"{atac_dir}/mouse/dca/mouse_atac_k{{rvu_k}}_ir6w_sham.tsv",
        f"{atac_dir}/mouse/dca/mouse_atac_k{{rvu_k}}_ir6w_ir2d.tsv",
    params:
        script = f"{cardiac_script_dir}/ms_rvu_atac.R",
        rvu_k = "{rvu_k}"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} {params.rvu_k} > {log} 2>&1
        """
#+end_src
#+begin_src R :tangle ./scripts/ms_rvu_atac.R
#!/usr/bin/env Rscript

##############################
###   Mouse Dca With Rvu   ###
##############################

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
libraries_full_rds = args[1]
counts_tsv = args[2]
keep_tsv = args[3]
ir2d_sham_tsv = args[4]
ir6w_sham_tsv = args[5]
ir6w_ir2d_tsv = args[6]
rvu_k = args[7]

# Load required packages, data, and functions
library(RUVSeq)
library(tidyverse)
libraries_full = readRDS(libraries_full_rds)
counts = read_tsv(counts_tsv)
keep = read_tsv(keep_tsv)

# Setup data objects
mat = as.matrix(counts[,-1])
row.names(mat) = counts$coordinate
colnames(mat) = substr(colnames(mat),1,6)
mat = mat[, colnames(mat) %in% keep$library]
(group = data.frame(library = colnames(mat)) %>% left_join(libraries_full) %>% pull(cohort) %>% droplevels())
set = newSeqExpressionSet(mat,
                          phenoData = data.frame(group, row.names = colnames(mat)))

print("Setup complete")

# Perform RUV adjustment by k unwanted factors
design <- model.matrix(~0+group, data = pData(set))
y <- DGEList(counts = counts(set), group = group)
y <- calcNormFactors(y, method = "upperquartile")
#y <- calcNormFactors(y)
y <- estimateGLMCommonDisp(y, design)
y <- estimateGLMTagwiseDisp(y, design)
fit <- glmFit(y, design)
dev <- residuals(fit, type="deviance")
peaks = row.names(dev)
adjust <- RUVr(set, peaks, k = as.numeric(rvu_k), dev)

print("\nModified counts created\n")

# Perform DCA by EdgeR on adjusted gene expression
if (rvu_k != 0) {
  modcounts = normCounts(adjust)
} else {
  modcounts = mat
}

design = model.matrix(~ 0 + group)
dge = DGEList(counts = modcounts)
dge = calcNormFactors(dge)
dge = estimateGLMCommonDisp(dge, design)
dge = estimateGLMTrendedDisp(dge, design)
dge = estimateGLMTagwiseDisp(dge, design)
fit = glmFit(dge, design)

name_mapping= data.frame(newname = c("logfc", "logcpm", "lr", "pval", "qval"),
                 oldname = c("logFC", "logCPM", "LR", "PValue", "FDR"))

print("\nDGE performed with modified counts\n")

# Generate specific comparisons
ir2d_sham_cont = makeContrasts(groupir2d - groupsham, levels = colnames(design))
ir2d_sham_lrt = glmLRT(fit, contrast = ir2d_sham_cont)
ir2d_sham = data.frame(topTags(ir2d_sham_lrt, n = nrow(dge))$table) %>% rownames_to_column(var = "coordinate") %>% as_tibble() %>%
  rename(!!!setNames(as.list(name_mapping$oldname), name_mapping$newname)) %>%
  write_tsv(ir2d_sham_tsv)

ir6w_sham_cont = makeContrasts(groupir6w - groupsham, levels = colnames(design))
ir6w_sham_lrt = glmLRT(fit, contrast = ir6w_sham_cont)
ir6w_sham = data.frame(topTags(ir6w_sham_lrt, n = nrow(dge))$table) %>% rownames_to_column(var = "coordinate") %>% as_tibble() %>%
  rename(!!!setNames(as.list(name_mapping$oldname), name_mapping$newname)) %>%
  write_tsv(ir6w_sham_tsv)

ir6w_ir2d_cont = makeContrasts(groupir6w - groupir2d, levels = colnames(design))
ir6w_ir2d_lrt = glmLRT(fit, contrast = ir6w_ir2d_cont)
ir6w_ir2d = data.frame(topTags(ir6w_ir2d_lrt, n = nrow(dge))$table) %>% rownames_to_column(var = "coordinate") %>% as_tibble() %>%
  rename(!!!setNames(as.list(name_mapping$oldname), name_mapping$newname)) %>%
  write_tsv(ir6w_ir2d_tsv)
#+end_src
***** RVU k selection Spearman
#+begin_src snakemake
rule atac_rvu_spearmans:
    input:
        dca=lambda wildcards: expand(f"{atac_dir}/{{species}}/dca/{{species}}_atac_k{{rvu_k}}_{wildcards.contrast}.tsv",
                                     species=wildcards.species,
                                     rvu_k=[0, 1, 2, 3, 4]),
        libs=f"{datamodel_dir}/lists/libraries_full.rds",
    log: f"{log_dir}/{{species}}_atac_rvu_{{contrast}}_spearmans.log",
    output:
        f"{results_dir}/{{species}}/atac/qc/rvu_spearman/{{species}}_{{contrast}}.rda",
        f"{results_dir}/{{species}}/atac/qc/rvu_spearman/{{species}}_{{contrast}}.pdf"
    params:
        script=f"{cardiac_script_dir}/atac_rvu_spearman.R"
    shell:
        """
        Rscript {params.script} \
        "{input.dca}" {input.libs} \
        {output} > {log} 2>&1
        """

#+end_src
#+begin_src R :tangle ./scripts/atac_rvu_spearman.R
dca_str="~/cards/analysis/atac/mouse/dca/ms_atac_k0_ir2d_sham.tsv ~/cards/analysis/atac/mouse/dca/ms_atac_k1_ir2d_sham.tsv ~/cards/analysis/atac/mouse/dca/ms_atac_k2_ir2d_sham.tsv ~/cards/analysis/atac/mouse/dca/ms_atac_k3_ir2d_sham.tsv ~/cards/analysis/atac/mouse/dca/ms_atac_k4_ir2d_sham.tsv"
libraries_full_rds="~/cards/data-model/lists/libraries_full.rds"

#!/usr/bin/env Rscript

#############################
###   Atac Rvu Spearman   ###
#############################

# Command line arguements
args = commandArgs(trailingOnly = TRUE)
dca_str = args[1]
libraries_full_rds = args[2]
out_rda = args[3]
out_pdf = args[4]

# Load required packages, data, and functions
library(tidyverse)

# Setup data
libraries_full = readRDS(libraries_full_rds)
(dca_char = strsplit(dca_str, " ")[[1]])
tibble_list = lapply(dca_char, read_tsv)
(names(tibble_list) = substr(gsub("^.*atac_", "", dca_char), 1, 2))


# Rename columns and merge tibbles
merged <- reduce(names(tibble_list), function(result, suffix) {
  tibble_i <- tibble_list[[suffix]]
  colnames(tibble_i) <- ifelse(colnames(tibble_i) == "coordinate", "coordinate", paste0(suffix, "_", colnames(tibble_i)))

  if (is.null(result)) {
    return(tibble_i)
  } else {
    return(left_join(result, tibble_i, by = "coordinate"))
  }
}, .init = NULL)

plot_merged <- function(merged) {
  # Create a data frame to store the R values and p-values
  stats_values <- merged %>%
    select(coordinate, ends_with("logfc")) %>%
    pivot_longer(cols = !c("coordinate", "k0_logfc"), names_to = "rvu_k", values_to = "logfc") %>%
    mutate(dif = abs(k0_logfc - logfc)) %>% group_by(rvu_k) %>%
    summarize(r2 = cor(k0_logfc, logfc)^2, p_value_diff = wilcox.test(k0_logfc, logfc)$p.value)
  stats_values

  exceeds <- merged %>% select(coordinate, ends_with("qval")) %>%
    pivot_longer(cols = !coordinate, names_to = "rvu_k", values_to = "qval")  %>%
    mutate(qsig = ifelse(qval < 0.05, "yes", "no")) %>%
    group_by(rvu_k) %>%
    summarize(qsum = sum(qsig == "yes")) %>%
    mutate(rvu_k = paste0(substr(rvu_k, 1, 2), "_logfc")) %>%
    full_join(stats_values) %>%
    filter(rvu_k != "k0_logfc")

  plot <- merged %>%
    select(coordinate, ends_with("logfc")) %>%
    pivot_longer(cols = !c("coordinate", "k0_logfc"), names_to = "rvu_k", values_to = "logfc") %>%
    mutate(dif = abs(k0_logfc - logfc)) %>% group_by(rvu_k) %>%
    mutate(sd2 = abs(mean(dif, na.rm = T)) + 3 * abs(sd(dif, na.rm = T))) %>%
    filter(dif > sd2) %>%
    ggplot(., aes(x = k0_logfc, y = logfc)) + geom_point() +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "blue") +
    geom_text(data = exceeds, aes(x = -Inf, y = Inf, label = paste0("R = ", round(r2, 3))),
              hjust = 0, nudge_x = -1, vjust = 2, size = 4) +
    geom_text(data = exceeds, aes(x = -Inf, y = Inf, label = paste0("p(diff) = ", format.pval(p_value_diff, digits = 3))),
              hjust = 0, nudge_x = -1, vjust = 4, size = 4) +
    geom_text(data = exceeds, aes(x = -Inf, y = Inf, label = paste0(qsum, " regions with FDR < 0.05")),
              hjust = 0, nudge_x = -1, vjust = 6, size = 4) +
    facet_wrap(~rvu_k) +     theme(text = element_text(size = 14), plot.margin = margin(1, 1, 1, 1, "cm"))


  return(plot)
}

plot = plot_merged(merged)

save(merged, plot, file = out_rda)

ggsave(plot, file = out_pdf)

#+end_src


*** Track visualization
#+begin_src R
library(rtracklayer)
library(Gviz)
library(GenomicRanges)
data(cpgIslands)

atrack <- AnnotationTrack(cpgIslands, name = "CpG")

plotTracks(atrack)

gtrack = GenomeAxisTrack()

plotTracks(list(gtrack, atrack))

(gen<-genome(cpgIslands))

(chr <- as.character(unique(seqnames(cpgIslands))))

itrack <- IdeogramTrack(genome = gen, chromosome = chr)

plotTracks(list(itrack, gtrack, atrack))

data(geneModels)

grtrack = GeneRegionTrack(geneModels, genome = gen, chromosome = chr, name = "Gene Model")

plotTracks(list(itrack, gtrack, grtrack))

#Use from and to arguments to zoom
plotTracks(list(itrack, gtrack, atrack, grtrack),
           from = 26700000, to = 26750000)
# Use extend.left and extend.right to zoom
#those arguments are relative to the currently displayed ranges,
#and can be used to quickly extend the view on one or both ends of the plot.
plotTracks(list(itrack, gtrack, atrack, grtrack),
           extend.left = 0.5, extend.right = 1000000)
# to drop the bounding borders of the exons and
# to have a nice plot
plotTracks(list(itrack, gtrack, atrack, grtrack),
           extend.left = 0.5, extend.right = 1000000, col = NULL)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("BSgenome.Hsapiens.UCSC.hg19")

library(BSgenome.Hsapiens.UCSC.hg19)

strack <- SequenceTrack(Hsapiens, chromosome = chr)
plotTracks(list(itrack, gtrack, atrack, grtrack,
                strack), from = 26591822, to = 26591852, cex = 0.8)

#For demonstration purposes we can create a simple DataTrack object from
#randomly sampled data.
set.seed(255)
lim <- c(26700000, 26750000)
coords <- sort(c(lim[1], sample(seq(from = lim[1],
                                    to = lim[2]), 99), lim[2]))
dat <- runif(100, min = -10, max = 10)
head(dat)

dtrack <- DataTrack(data = dat, start = coords[-length(coords)],
                    end = coords[-1], chromosome = chr, genome = gen,
                    name = "Uniform")
##Plot data track
plotTracks(list(itrack, gtrack, atrack, grtrack,
                dtrack), from = lim[1], to = lim[2])

#Change plot type to histogram
plotTracks(list(itrack, gtrack, atrack, grtrack,dtrack),
           from = lim[1], to = lim[2], type = "histogram")

data(twoGroups)
head(twoGroups)

dTrack <- DataTrack(twoGroups, name = "asdf")
plotTracks(dTrack)

plotTracks(DataTrack(twoGroups, name = "p"), type="p")
#lines plot
plotTracks(DataTrack(twoGroups, name = "l"), type="l")
#line and dot plot
test =plotTracks(DataTrack(twoGroups, name = "b"), type="b")
#lines plot of average

class(test)

plotTracks(DataTrack(twoGroups, name = "a"), type="a", groups = rep(c("control","treated"),each = 3))

#histogram lines
plotTracks(DataTrack(twoGroups, name = "h"), type="h")
#histogram histogram (bar width equal to range with)
plotTracks(DataTrack(twoGroups, name = "histogram"), type="histogram")
#'polygon-type' plot relative to a baseline
plotTracks(DataTrack(twoGroups, name = "polygon"), type="polygon")
#box and whisker plot
plotTracks(DataTrack(twoGroups, name = "boxplot"), type="boxplot")
#false color image of the individual values

alTrack <- AlignmentsTrack(system.file(package = "Gviz", "extdata",
                                       "gapped.bam"), isPaired = TRUE)

alTrack

class(alTrack)

afrom=2960000
ato=3160000

plotTracks(alTrack, from = afrom, to = ato, chromosome = "chr12")

# Load necessary packages
library(rtracklayer)
library(GenomicRanges)

# Import the bed file with rtracklayer
bed_data <- import.bed("~/cards/analysis/atac/mouse/peaks/lib116_mm10_ds9_peaks.broadPeak")

testbam = "~/cards/analysis/atac/mouse/bams/lib116_mm10_ds9.bam"
mappedReads <- idxstatsBam(testbam)
(TotalMapped <- sum(mappedReads[, "mapped"]))

#forBigWig <- coverage(testbam, weight = (10^6)/TotalMapped)
forBigWig <- coverage(testbam)

export.bw(forBigWig, con = "/tmp/test.bw")


bw_data <- import(con = "/tmp/test.bw")

dt <- DataTrack(range = bw_data, name = "My Data")

# Plot the track
plotTracks(dt)


# Print the GRanges object
print(bw_data)



plotTracks(DataTrack(forBigWig, name = "p"), type="l")


# Load necessary packages

library(Gviz)
library(GenomicRanges)

# Import the bigWig file with rtracklayer
bw_data <- import(con = "/tmp/test.bw")

# Create a GRanges object for the desired region
region <- GRanges("chr2", IRanges(start = 137081456, end = 137116644))

# Subset the data
subset_data <- subsetByOverlaps(bw_data, region)

# Create a DataTrack
plotTracks(DataTrack(range = subset_data, name = "My Data", type = "hist", genome = "mm10", window = -1, fill.histogram = "darkblue", col.histogram = "darkblue"))

library(grid)
library(ggplotify)
library(Gviz)

set.seed(123)
gr <- GRanges("chr1", IRanges(1:100, width=1),
              score=rnorm(100))
dTrack <- DataTrack(gr, type=c("a", "p"))
aTrack <- GenomeAxisTrack(add35=TRUE, add53=TRUE, littleTicks=TRUE)
# plotTracks(list(aTrack,dTrack),from=1,to=100)


p1 <- as.grob(~plotTracks(list(aTrack,dTrack),from=1,to=100))
p1 # gTree

p2 <- as.grob(~plotTracks(DataTrack(range = subset_data, name = "My Data", type = "hist", genome = "mm10", window = -1, fill.histogram = "darkblue", col.histogram = "darkblue")))

library(cowplot)
plot_grid(p1, p2)

grid.newpage()
grid.draw(p1, p2)

# Import the bed file with rtracklayer
bed_data <- import.bed("~/cards/analysis/atac/mouse/peaks/lib117_mm10_ds9_peaks.broadPeak")

testbam = "~/cards/analysis/atac/mouse/bams/lib119_mm10_ds9.bam"
mappedReads <- idxstatsBam(testbam)
(TotalMapped <- sum(mappedReads[, "mapped"]))


ir_data <- import(con = "/tmp/test.bw")
sham_data= import(con = "/tmp/test_sham.bw")

# Create a GRanges object for the desired region
region <- GRanges("chr3", IRanges(start = from, end = to))

# Subset the data
subset_ir <- subsetByOverlaps(ir_data, region)
subset_sham <- subsetByOverlaps(sham_data, region)

# Create a DataTrack
sham = DataTrack(range = subset_sham, name = "My Data", type = "hist", genome = "mm10", window = -1, fill.histogram = "darkblue", col.histogram = "darkblue")

# Create a DataTrack
ir = DataTrack(range = subset_ir, name = "My Data", type = "hist", genome = "mm10", window = -1, fill.histogram = "darkblue", col.histogram = "darkblue")


plotTracks(list(sham, ir, knownGenes))

test = AlignmentsTrack("~/cards/analysis/atac/mouse/bams/lib051_mm10_ds9.bam", isPaired = T)

library(biomaRt)
options(ucscChromosomeNames=FALSE)

library(biomaRt)

mart <- useMart("ensembl", dataset = "mmusculus_gene_ensembl")  # Mouse genes
gene <- "Jag1"

# Fetch the gene start and end
gene_info <- getBM(attributes = c('chromosome_name', 'start_position', 'end_position'),
                   filters = 'external_gene_name',
                   values = gene,
                   mart = mart)

# Use the gene start and end to plot
knownGene <- UcscTrack(
  genome = "mm10",
  chromosome = paste0("chr", gene_info$chromosome_name[1]),  # assuming it is located on the first chromosome listed
  track = "knownGene",
  from = gene_info$start_position[1],  # assuming the gene is located at the first start_position listed
  to = gene_info$end_position[1],  # assuming the gene is located at the first end_position listed
  trackType = "GeneRegionTrack",
  rstarts = "exonStarts",
  rends = "exonEnds",
  gene = "name",
  symbol = "name"
)

plotTracks(knownGene)

from <-137046267
to <- 137151833
knownGenes <- UcscTrack(genome = "mm9", chromosome = "chr2",
                        track = "knownGene", from = from, to = to,
                        trackType = "GeneRegionTrack",
                        rstarts = "exonStarts", rends = "exonEnds",
                        gene = "name", symbol = "name")
plotTracks(knownGenes)


from <- 137046267
to <- 137151833
knownGenes <- UcscTrack(genome = "mm10", chromosome = "chr3",
                        table = "knownGene", from = from, to = to,
                        trackType = "GeneRegionTrack",
                        rstarts = "exonStarts", rends = "exonEnds",
                        gene = "name", symbol = "name",
                        transcript = "name", strand = "strand",
                        fill = "#8282d2", name = "UCSC Genes")
#+end_src
*** Region and locus-based enrichment
- [[id:12393aa3-d318-4ba6-8183-6e3a175d3ba4][Region or locus-based enrichment analysis]]
*** Fraction of reads in peaks (FRiP)
:PROPERTIES:
:ID:       6f4cf12b-bc4c-4063-823f-7d4fcf9b0579
:END:
#+begin_src snakemake
rule frip_mouse:
    input:
        bam = expand(f"{atac_dir}/mouse/bams/{{library}}_mm10_filt.bam", library = MOUSE_ATAC_LIBS),
        peak = expand(f"{atac_dir}/mouse/peaks/{{library}}_mm10_filt_multi_peaks.narrowPeak", library = MOUSE_ATAC_LIBS),
    log: f"{log_dir}/mouse_frip.log",
    output: tsv = f"{atac_dir}/mouse/qc/mouse_frip.tsv",
    params:
        script = f"{atac_script_dir}/frip.sh",
    shell:
        """
        {params.script} '{input.bam}' {output.tsv} &> {log}
        """
#+end_src
#+begin_src bash :tangle ./scripts/frip.sh
#!/usr/bin/env bash

input_str="${1}"
output="${2}"

#echo "library	reads	frip" > $output

IFS=' ' read -r -a array <<< "$input_str"

# Define a function to process each file
process_file() {
    file="$1"
    library=$(echo $(basename $file) | sed 's/_.*$//g')
    peaks=sed 's|/bams/lib[0-9]\{3\}_mm10_ds9.bam|/peaks/&_multi_peaks.narrowPeak|' filename
    col1=$(bedtools intersect -a $file -b /mnt/ris/jschwarz/Active/cardiac-radiobiology/analysis/atac/${species}/peaks/${library}_${build}_ds9_multi_peaks.narrowPeak -wa -f 0.2 -r | wc -l)
    col2=$(cat $file | wc -l)
    frip=$(awk 'BEGIN {print '${col1}'/'${col2}' }')
    echo "$library	$col2	$frip"
}

# Export the function to make it available to parallel
export -f process_file

# Run the loop in parallel using parallel command
parallel -j 4 process_file ::: "${array[@]}" > "$output"

sed -i '1i\library\tpeaks\tfrip' $output

#+end_src
- Reference
  - [[https://docs.google.com/document/d/1f0Cm4vRyDQDu0bMehHD7P7KOMxTOP-HiNoIvL1VcBt8/edit][ENCODE]]
  - [[id:a55b6586-9f45-4f0c-9280-15b996a689f4][ATAC-seq FRiP results]]
*** MACS2 narrow peak calling



#+begin_src snakemake
rule macs2_narrow:
    input:
        f"{atac_dir}/bams/{{library}}_{{build}}_filt.bam",
    log:
        f"{log_dir}/{{library}}_{{build}}_macs2_narrow.log",
    output:
        f"{atac_dir}/peaks/{{library}}_{{build}}_peaks.narrowPeak",
    params:
        gsize = lambda wildcards: build_map[wildcards.build]['gsize'],
        txdb = lambda wildcards: build_map[wildcards.build]['txdb'],
        outdir = f"{atac_dir}/peaks",
        script = f"{atac_script_dir}/macs2_narrow.sh",
    shell:
        """
        name=$(basename -s _filt.bam {input})
        {params.script} \
        {input} \
        $name \
        {params.gsize} \
        {params.outdir} &> {log}
        """
#+end_src

#+begin_src bash :tangle ./scripts/macs2_narrow.sh
#!/usr/bin/env bash
set -o errexit   # abort on nonzero exitstatus
set -o nounset   # abort on unbound variable
set -o pipefail  # don't hide errors within pipes

inbam=$1
name=$2
gsize=$3
outdir=$4

macs2 callpeak --treatment $inbam \
      --bdg \
      --call-summits \
      --extsize 150 \
      --format BAMPE \
      --gsize $gsize \
      --keep-dup all \
      --name ${name} \
      --nolambda \
      --outdir $outdir \
      -p 0.01 \
      --shift -75 \
      --SPMR \
      --nomodel
#+end_src
*** Aggregate
**** INPROCESS Aggregate samstats
#+begin_src snakemake
rule agg_samstat:
    input:
        lambda wildcards: expand(f"{atac_dir}/{wildcards.species}/qc/{{library}}_filt_samstats.txt", library=get_libraries(wildcards.species)),
    output:
        f"{atac_dir}/{{species}}/qc/{{species}}_atac_samstats.tsv",
    run:
        import os
        import re

        data = []

        # Loop over the input files
        for filename in input:
            # Extract the library ID from the filename
            library_id = os.path.basename(filename).split("_")[0]

            # Open the log file
            with open(filename, "r") as f:
                lines = f.readlines()

                # Find the required lines using regular expressions
                reads = duplicated = total = mapped = error = None
                for line in lines:
                    if re.match(r"SN\traw total sequences:", line):
                        reads = int(re.search(r"\d+", line).group())
                    elif re.match(r"SN\treads duplicated:", line):
                        duplicated = int(re.search(r"\d+", line).group())
                    elif re.match(r"SN\ttotal length:", line):
                        total = int(re.search(r"\d+", line).group())
                    elif re.match(r"SN\tbases mapped \(cigar\):", line):
                        mapped = int(re.search(r"\d+", line).group())
                    elif re.match(r"SN\terror rate:", line):
                        error = float(re.search(r"\d+\.\d+[eE][+-]\d+", line).group())

                # Append the data to the list
                data.append({
                    "reads": reads,
                    "duplicated": duplicated,
                    "total": total,
                    "mapped": mapped,
                    "error": error,
                    "library": library_id
                })

        # Write the data to a file
        header = "total_reads\tduplicated_reads\ttotal_bases\tmapped_bases\terror_rate\tlibrary\n"
        with open(output[0], "w") as f:
            f.write(header)
            for d in data:
                f.write("{}\t{}\t{}\t{}\t{}\t{}\n".format(d["reads"], d["duplicated"], d["total"], d["mapped"], d["error"], d["library"]))

#+end_src

**** WAITING Tabular summary

NEXT ADD SAMSTATS

Per-species ATAC-seq library QC tabular results
#+begin_src snakemake
rule atac_qc_table:
    input:
        f"{atac_dir}/{{species}}/qc/{{species}}_corces_qc.tsv",
        f"{atac_dir}/{{species}}/qc/{{species}}_frip.tsv",
        f"{atac_dir}/{{species}}/qc/{{species}}_atac_samstats.tsv",
    log: f"{log_dir}/{{species}}_atac_qc_table.log",
    output: f"{atac_dir}/{{species}}/qc/{{species}}_atac_qc.tsv",
    params:
        script = f"{atac_script_dir}/atac_qc_table.R",
#+end_src
#+begin_src R
frip_tsv = "~/cards/analysis/atac/mouse/qc/mouse_mm10_frip.tsv"
corces_tsv = "~/cards/analysis/atac/mouse/qc/mouse_corces_qc.tsv"
samstats_tsv = "~/cards/analysis/atac/mouse/qc/mouse_atac_samstats.tsv"
libs_tsv = "~/cards/data-model/lists/atac_logic.tsv"
species_var = "mouse"

library(tidyverse)
frip = read_tsv(frip_tsv)
libs = read_tsv(libs_tsv)
samstast = read_tsv(samstat_tsv)
corces = read_tsv(corces_tsv)

libs %>% filter(species == species_var) %>% left_join(frip, by = "library") %>% left_join(corces, by = "library")

#+end_src
**** Development
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
- https://genome.cshlp.org/content/22/9/1813.full
***** Insert-size distribution
- Snakemake
  #+begin_src snakemake
checkpoint insert_size:
    input: expand(f"{atac_dir}/{{species}}/bams/{{library}}_{{build}}_filt.bam", library = raw_atac_libs),
    log: f"{log_dir}/{{species}}_{{build}}_insert_size.log",
    output:
        tsv = f"{qc_dir}/{{species}}_{{build}}_insert_sizes.tsv",
        plot = f"{qc_dir}/{{species}}_{{build}}_insert_sizes.pdf",
    params:
        peak_cut = atac_peak_cut,
        script = f"{atac_script_dir}/insert_size.R",
    shell:
        """
        Rscript {params.script} \
        "{input}" \
        {output.tsv} \
        {output.plot} \
        {params.peak_cut} > {log} 2>&1
        """
#+end_src
- Rscript
  #+begin_src R :tangle ./scripts/insert_size.R
args = commandArgs(trailingOnly = TRUE)
bam_list_str = args[1]
peak_ratio_tsv = args[2]
peak_ratio_plot = args[3]
peak_cut = args[4]

library(GenomicAlignments)
library(tidyverse)

bam_list = unlist(strsplit(bam_list_str, " "))
names(bam_list) = substr(gsub("^.*lib","lib", bam_list), 1, 6)

tally_lengths = function(in_bam){
  # Make a tibble with counts of fragment lengths
  gal = readGAlignments(in_bam,
                        param=ScanBamParam(what=c("isize")))
  tib = mcols(gal) %>%
    as_tibble() %>%
    mutate(frag_len = abs(isize)) %>%
    group_by(frag_len) %>%
    tally()
  return(tib)
}

change_column_name <- function(x, aList) {
  # For each per-library tibble, change column to library ID
  dat <- aList[[x]]
  names(dat)[2] <- x
  return(dat)
}

pre_frag_len_list = lapply(bam_list, tally_lengths)
frag_len_list = lapply(names(pre_frag_len_list), change_column_name, pre_frag_len_list)

frags =
  # Make a complete list of fragment sizes, 1-1000
  data.frame(frag_len = 1:1000) %>%
  as_tibble()
frags

frag_len_tib =
  frag_len_list %>% purrr::reduce(full_join, by = "frag_len") %>%
  full_join(frags, by = "frag_len") %>%
  arrange(frag_len) %>%
   replace(is.na(.), 0) %>%
   mutate(frag_len_fct = ifelse(frag_len > 1000, "other", frag_len)) %>%
  select(!frag_len) %>%
  pivot_longer(!frag_len_fct, names_to = "library", values_to = "count") %>%
  group_by(frag_len_fct, library) %>%
  summarize(count = sum(count)) %>%
  mutate(frag_len_fct = as.numeric(frag_len_fct)) %>%
  arrange(frag_len_fct)

cut = frag_len_tib %>%
  mutate(mono_cut = ifelse(frag_len_fct < 146, "open", "mono")) %>%
  group_by(library,mono_cut) %>%
  summarize(high = max(count)) %>%
  pivot_wider(names_from = mono_cut, values_from = high) %>%
  mutate(peak_ratio = open / mono) %>%
  select(library, open, mono, peak_ratio)

cut %>% write_tsv(file = peak_ratio_tsv)

plot = frag_len_tib %>%
  left_join(cut, by = "library") %>%
  mutate(peak_ratio_mod = ifelse(peak_ratio < peak_cut, NA, peak_ratio)) %>%
  ggplot(., aes(x=frag_len_fct, y = count)) +
  geom_line(aes(color = peak_ratio_mod)) +
  facet_wrap(vars(library)) +
  xlab("Fragment Length") + ylab("Count") +
  geom_hline(aes(yintercept = mono)) +
  scale_color_continuous(name = "Ratio of open to mononucleosomal peaks", na.value = "red") +
  theme(legend.position = "bottom")

ggsave(plot, file = peak_ratio_plot)


#+end_src
**** [[id:f0124001-2d9f-47a3-a55a-7004bc5db0ee][Peak annotation]]
*** Open genome by chromosome
#+begin_src snakemake

rule chr_open_genome:
    input:
        lambda wildcards: expand(f"{atac_dir}/peaks/{{library}}_{{build}}_{{bam_set}}_peaks.{{peaktype}}Peak",
                                 library=atac_map[wildcards.atac_set]['libs'],
                                 build=atac_map[wildcards.atac_set]['build'],
                                 bam_set=atac_map[wildcards.atac_set]['bam_set'],
                                 peaktype=atac_map[wildcards.atac_set]['peaktype'])
    log: f"{log_dir}/{{atac_set}}_open_genome.log",
    output:
        f"{atac_dir}/models/{{atac_set}}/open_chrom.txt"
    params:
        genome_bed=lambda wildcards: f"{ref_dir}/{atac_map[wildcards.atac_set]['build']}_sorted_autosomes.bed",
        qval_cut=5,
        threads=4,
        script=f"{atac_script_dir}/chr_open_genome.sh",
    shell:
        """
        {params.script} \
        "{input}" \
        {params.genome_bed} \
        {params.qval_cut} \
        {params.threads} \
        {output}
        """
#+end_src

#+begin_src bash :tangle ./scripts/chr_open_genome.sh
#!/usr/bin/env bash

peaks_str="${1}"
ref_bed="${2}"
qval_cut="${3}"
threads="${4}"
out_tsv="${5}"


process_file() {
    file="$1"
    base=$(basename $file)
    ref_bed="${2}"
    qval_cut="${3}"
    cat "$file" |
        awk -v cut="$qval_cut" '$9 > cut' |
        sort-bed - |
        bedmap --echo --bases-uniq --delim '\t' $ref_bed - |
        awk -v base="$base" '{print $0 "\t" base}'

}

export -f process_file

parallel -j "$threads" process_file {} "$ref_bed" "$qval_cut" ::: $peaks_str > "$out_tsv"

#+end_src

- https://www.biostars.org/p/219099/
** Ideas
- chromatin information enrichment - narrowpeak is used as for https://www.nature.com/articles/s41467-021-21534-4
# naive consensus peaks by markov chain
library(BSgenome.Hsapiens.UCSC.hg19)
seq = getAllPeakSequence(overlaps,
                         upstream = 20,
                         downstream = 20,
                         genome=Hsapiens)

*** Template                                                       :smk_rule:
#+begin_src snakemake
#
rule :
    container: atac_container,
    input:
    log:       log_dir + "/
    output:
    params:
        script  = atac_script_dir + "/
	threads = threads,
    shell:
        """
        {params.script} \
        {input} \
        {params.threads} \
        {output} &> {log}
        """
#+end_src

*** Make backgroud bins                                            :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_backgroud_bins:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/make_backgroud_bins.R"
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
    output:
    log:
        config["data_dir"] + "/logs/make_backgroud_bins.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./scripts/make_backgroud_bins.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to make background bins for csaw TMM normalization   ###
###

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
window_file =  args[1]
bam_dir = args[2]
bam_pattern = args[3]
filt_libs_str = args[4]
rse = args[4]
bk = args[5]

filt_libs = unlist(strsplit(filt_libs_str, " "))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

#+end_src
*** d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src

**** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./scripts/edger.R][Base script]]
#+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src
*** Nearest feature of ensembl genes with bedops
https://bedops.readthedocs.io/en/latest/content/reference/set-operations/closest-features.html
- Convert DESeq2 results to bedfile
  #+begin_src bash
cat /tmp/rt_up.tsv | sed 's/\t.*//g' | sed 's/\./\t/g' | sed 's\chr\\g'> /tmp/rt_up.bed
cat /tmp/ctrl_up.tsv | sed 's/\t.*//g' | sed 's/\./\t/g' | sed 's\chr\\g' > /tmp/ctrl_up.bed
#+end_src
- annotate nearest protein coding genes and return lists for sham and post-RT state
  #+begin_src bash
sort-bed $data_dir/ref/mm10_ens_gene.bed > /tmp/mm10_sort.bed
#########1#########2#########3#########4#########5#########6#########7#########8

sort-bed /tmp/ctrl_up.bed > /tmp/ctrl_up_sort.bed
sort-bed /tmp/rt_up.bed > /tmp/rt_up_sort.bed


#########1#########2#########3#########4#########5#########6#########7#########8

closest-features --closest /tmp/ctrl_up_sort.bed /tmp/mm10_sort.bed | sed 's/^.*gene_name..//g' | sed 's/".*$//g' | sort -u > /tmp/ctrl_up_genes

closest-features --closest /tmp/rt_up_sort.bed /tmp/mm10_sort.bed | sed 's/^.*gene_name..//g' | sed 's/".*$//g' | sort -u > /tmp/rt_up_genes

diff /tmp/rt_up_genes /tmp/ctrl_up_genes | grep '^<' | cut -c 3- > /tmp/diff
wc -l /tmp/diff

#+end_src






*** Differential accessibility                                     :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes

#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to generate differential accessibility model with EdgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
load(data_model)
background = readRDS(background_rds)

counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design <- model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src
- Reference
  -   https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt

*** Motif analysis
- Get gene list- Takes annotated edger results as table
  #+begin_src R
library(tidyverse)
test = as_tibble(read.csv("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_de.csv", header = T))

motifs_down_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC < 0) %>%
  pull(geneId)

motifs_up_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC > 0) %>%
  pull(geneId)

writeLines(as.character(motifs_down_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt")
writeLines(as.character(motifs_up_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_up.txt")

#+end_src

- Find motifs
  #+begin_src bash
mkdir -p /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/

nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/ -fdr 10 -p 12

# try



Number of CPUs to use ("-p <#>", default 1)
HOMER is now multicore compliant.  It's not perfectly parallelized, however, certain types of analysis can benefit.  In general, the longer the length of the motif, the better the speed-up you'll see.

Number of motifs to find ("-S <#>", default 25)
Specifies the number of motifs of each length to find.  25 is already quite a bit.  If anything, I'd recommend reducing this number, particularly for long motifs to reduce the total execution time.
perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src

- Extract gene names
  #+begin_src bash

#+end_src


**** Snakefile                                                 :smk:noexport:
:PROPERTIES:
:header-args:snakemake:
:END:
***** Smk preamble
#+begin_src snakemake :noweb yes

#+end_src
***** All rule
#+begin_src snakemake
rule all:
    input:
#+end_src
***** Extract gene list                                            :smk_rule:

extract ensembl ID lists from csaw-EdgeR DCA workflow

- Snakemake
  #+begin_src snakemake
rule extract_gene_list:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/extract_gene_list.R"
    output:
    log:
        config["data_dir"] + "/logs/extract_gene_list.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./scripts/extract_gene_list.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###    SCRIPT TITLE   ###
###

args = commandArgs(trailingOnly = TRUE)
dca_tbl = args[1]

#+end_src
***** Find motifs for gene list promoters
- Find motifs by gene list
  #+begin_src bash
# TODO install homer w/ mouse-p promoter set

source ~/repos/cardradbio-atac/config/${HOSTNAME}.sh

# Fake gene list from peak annotation output, is ensembl IDs
#

# Install mouse homer promotor set
perl /home/jeszyman/homer/.//configureHomer.pl -install mouse-p

mkdir -p /tmp/out

findMotifs.pl /tmp/test.txt mouse /tmp/out

perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src
**** Description                                                     :ignore:

*** Normalize filtered csaw peaks                                  :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
*** [[file:workflow/chrom_access_opto.smk][Chromatin Accessibility Optimization]]                                :smk:
:PROPERTIES:
:header-args:snakemake:
:END:
**** Smk preamble
#+begin_src snakemake
CHROM_FILT =  ["regfilt", "open"]
COHORT = ["sham", "ir48h", "ir6w"]
CONTRAST = ["all", "ir6w_sham", "ir48h_sham"]
JOIN = ["union", "intersect", "naive"]
IR48H_LIBS = ["lib008", "lib009", "lib010", "lib012"]
IR6W_LIBS = ["lib003", "lib004", "lib005", "lib006", "lib017", "lib019", "lib021", "lib023", "lib025"]
RUNSAMPLES =  ["lib001", "lib002", "lib003", "lib004", "lib005", "lib006", "lib007", "lib008", "lib009", "lib010", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib025"]
SHAM_LIBS = ["lib001", "lib002", "lib007", "lib013", "lib014", "lib015", "lib016", "lib018", "lib020", "lib022"]
SHAM_LIBS_FILT = ["lib013", "lib014", "lib015", "lib016", "lib018", "lib020", "lib022"]
IR6W_LIBS_FILT = ["lib017", "lib019", "lib021", "lib023", "lib025"]
WIDTH = ["broad", "narrow"]
FILTSAMPLES =  ["lib008", "lib009", "lib010", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib025"]
CALLER = ["csaw", "macs2"]
#+end_src
**** Smk rules
***** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5.bam", cohort = COHORT, chrom_filt = CHROM_FILT),
        expand(config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5_filt.bam", chrom_filt = CHROM_FILT),
        expand(config["data_dir"] + "/atac/bam/ir6w_{chrom_filt}_merged_tn5_filt.bam", chrom_filt = CHROM_FILT),
        expand(config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_filt_peaks.xls", cohort = ["sham", "ir6w"], chrom_filt = CHROM_FILT, width = WIDTH)
        expand(config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}_filt.bed", join=JOIN, chrom_filt=CHROM_FILT, width=WIDTH),
        expand(config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}_filt.bed", join=JOIN, chrom_filt=CHROM_FILT, width=WIDTH),
        expand(config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}_filt.bed",  join=JOIN, chrom_filt=CHROM_FILT, width=WIDTH),
        expand(config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}_filt.rds", contrast = CONTRAST, join=JOIN, chrom_filt=CHROM_FILT, width=WIDTH),
#+end_src
***** Make merged bams                                             :smk_rule:
CLOSED: [2022-02-16 Wed 12:14]
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:14]
:END:
- Snakemake
#+begin_src snakemake
rule make_merged_bams:
    input:
        ir48h =     expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR48H_LIBS),
        ir6w =      expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR6W_LIBS),
        ir6w_filt = expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR6W_LIBS_FILT),
        sham =      expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = SHAM_LIBS),
        sham_filt = expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = SHAM_LIBS_FILT),
    output:
        ir48h = config["data_dir"] + "/atac/bam/ir48h_{chrom_filt}_merged_tn5.bam",
        ir6w = config["data_dir"] + "/atac/bam/ir6w_{chrom_filt}_merged_tn5.bam",
        ir6w_filt = config["data_dir"] + "/atac/bam/ir6w_{chrom_filt}_merged_tn5_filt.bam",
        sham = config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5.bam",
        sham_filt = config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5_filt.bam",
    shell:
        """
        samtools merge -@ {config[threads]} {output.sham} {input.sham}
        samtools merge -@ {config[threads]} {output.ir6w} {input.ir6w}
        samtools merge -@ {config[threads]} {output.ir48h} {input.ir48h}
        samtools merge -@ {config[threads]} {output.sham_filt} {input.sham_filt}
        samtools merge -@ {config[threads]} {output.ir6w_filt} {input.ir6w_filt}
        """
#+end_src

***** MACS2 workflow
CLOSED: [2022-03-01 Tue 12:09]
:LOGBOOK:
- State "DONE"       from              [2022-03-01 Tue 12:09]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
*** more macs2
**** DONE Call MACS2 merged                                        :smk_rule:
CLOSED: [2022-02-25 Fri 15:20]
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:20]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
**** DONE Make MACS2 union consensus peaks                         :smk_rule:
CLOSED: [2022-02-16 Wed 12:49]
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
	ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}.bed",
	ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir48h_{chrom_filt}_{width}.bed",
	ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir6w_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir48h} > {output.ir48h}
        bedops -m {input.ir6w} > {output.ir6w}
        """
#+end_src
**** DONE Make MACS2 intersect consensus peaks                     :smk_rule:
CLOSED: [2022-02-16 Wed 12:52]
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir6w_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir48h} > {output.ir48h}
        bedops --intersect {input.ir6w} > {output.ir6w}
        """
#+end_src

**** DONE Make MACS2 naive peaks                                   :smk_rule:
CLOSED: [2022-02-25 Fri 16:01]
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_peaks.{width}Peak",
	ir6w_merge = config["data_dir"] + "/atac/macs2/ir6w_{chrom_filt}_{width}_peaks.{width}Peak",
	ir48h_merge = config["data_dir"] + "/atac/macs2/ir48h_{chrom_filt}_{width}_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir6w_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir48h_merge} {input.ir48h} > {output.ir48h}
        bedops --element-of 50% {input.ir6w_merge} {input.ir6w} > {output.ir6w}
        """
#+end_src

**** DONE Make cross cohort consenus
CLOSED: [2022-02-25 Fri 16:02]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir6w_{chrom_filt}_{width}.bed",
    output:
        all = config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}.bed",
	ir6w_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}.bed",
	ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} {input.ir6w} > {output.all}
	bedops --merge {input.sham} {input.ir6w} > {output.ir6w_sham}
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
**** DONE BED to GRanges                                           :smk_rule:
CLOSED: [2022-02-25 Fri 16:02]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/{contrast}_{join}_{chrom_filt}_{width}.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src
**** Filtered bam workflow
***** DONE Call MACS2 merged filtered                              :smk_rule:
CLOSED: [2022-03-01 Tue 12:10]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:10]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged_filtered:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5_filt.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow_filt \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad_filt \
              --outdir {params.outdir}
        """
#+end_src
***** DONE Make MACS2 union filtered consensus peaks               :smk_rule:
CLOSED: [2022-03-01 Tue 12:12]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
	ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}_filt.bed",
	ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir6w} > {output.ir6w}
        """
#+end_src
***** DONE Make MACS2 intersect filtered consensus peaks           :smk_rule:
CLOSED: [2022-03-01 Tue 12:12]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir6w} > {output.ir6w}
        """
#+end_src

***** DONE Make MACS2 naive filtered peaks                         :smk_rule:
CLOSED: [2022-03-01 Tue 12:13]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:13]
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_filt_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_filt_peaks.{width}Peak",
	ir6w_merge = config["data_dir"] + "/atac/macs2/ir6w_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir6w_merge} {input.ir6w} > {output.ir6w}
        """
#+end_src

***** DONE Make cross cohort consenus
CLOSED: [2022-03-01 Tue 12:16]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:16]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_filt_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}_filt.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir6w_{chrom_filt}_{width}_filt.bed",
    output:
        all = config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}_filt.bed",
	ir6w_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}_filt.bed",
	ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}_filt.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} {input.ir6w} > {output.all}
	bedops --merge {input.sham} {input.ir6w} > {output.ir6w_sham}
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
***** DONE BED to GRanges:smk_rule:
CLOSED: [2022-03-01 Tue 12:45]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:45]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges_filt:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/{contrast}_{join}_{chrom_filt}_{width}_filt.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}_filt.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src

***** Count from filtered MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_filtered_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}_filt.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src

***** Call csaw filtered local peaks                               :smk_rule:
- Library normalization is performed here, so need to re-run on subset
- Snakemake
  #+begin_src snakemake
rule call_csaw_filtered_local_peaks:
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
        filt_libs = "lib008,lib009,lib010,lib012,lib013,lib014,lib015,lib016,lib017,lib018,lib019,lib020,lib021,lib022,lib023,lib025"
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_filt_peaks_rse.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {params.filt_libs} \
        {output.rse} \
        >& {log}
        """
#+end_src
- [[file:./scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
rse = args[4]

filt_libs = unlist(strsplit(filt_libs_str, ","))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
#+end_src
***** DONE Make filtered background bins
CLOSED: [2022-03-01 Tue 09:00]
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-01 Tue 09:00]
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- just need to filter to filt libs
#+begin_src R
library(SummarizedExperiment)

bkbin_open = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_rse.rds")

bkbin_regfilt = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_regfilt_rse.rds")

filt_libs = c("lib008", "lib009", "lib010", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib025")

bkbin_open_filt = bkbin_open[,colnames(bkbin_open) %in% filt_libs]

bkbin_regfilt_filt = bkbin_regfilt[,colnames(bkbin_regfilt) %in% filt_libs]

saveRDS(object = bkbin_open_filt,
        file = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

saveRDS(object = bkbin_regfilt_filt,
        file = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_regfilt_filt_rse.rds")
#+end_src

***** Normalize filtered csaw peaks                                :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
***** Normalize filtered macs2 peaks                               :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src

**** d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src
**** Count, normalize, and DE
***** Count from MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
***** Call csaw local peaks                                        :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_csaw_local_peaks:
    input:
        expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = RUNSAMPLES)
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse = args[3]
dge = args[4]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

edger_input <- asDGEList(filtered_counts)

colnames(edger_input$counts) = colnames(filtered_counts)
rownames(edger_input$samples) = colnames(filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
***** DONE Make background bins:smk_rule:
CLOSED: [2022-02-16 Wed 13:22]
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- Snakemake
#+begin_src snakemake
rule make_background_bins:
    params:
        script = config["repo"] + "/workflow/scripts/make_background_bins.R",
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds"
    log:
        config["data_dir"] + "/logs/make_background_bins_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/make_background_bins.R][Base script]]
#+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make background bins for TMM normalization   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse_file = args[3]

library(csaw)

standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)


bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))


binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

saveRDS(object = binned,
        file = rse_file)
#+end_src
***** Normalize                                                    :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-02-16 Wed 13:25] \\
  waiting for counts to finish
:END:
  #+begin_src R
#!/usr/bin/env Rscript
library(csaw)
library(edgeR)

peaks_rse = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds")

bk = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

tmm = normFactors(bk, se.out = peaks_rse)

loess = normOffsets(peaks_rse, se.out = TRUE)

#########1#########2#########3#########4#########5#########6#########7#########8

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

norm_tmm_logcpm = make_logcpm(tmm)
norm_loess_logcpm = make_logcpm(loess)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

make_pca = function(in_cpm){
  pca_out = prcomp(t(in_cpm))
}

pca_list = lapply(cpm_list, make_pca)

make_pca_plots = function(in_pca, full_libs){
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(full_libs, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")
  return(pca_plot)
}

pca_plot_list = lapply(pca_list, make_pca_plots, libraries_full)

legend = get_legend(pca_plot_list[[1]]+
                        guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom")
)

pre_pca_plot_grid = plot_grid(plotlist = pca_plots, labels = names(pca_list))
pre_pca_plot_grid

pca_plot_grid = plot_grid(pre_pca_plot_grid, legend, ncol = 1, rel_heights = c(1,.1))

save_plot("./results/imgs/cpm_pca.pdf", pca_plot_grid,
          base_height = 20, base_width = 20)

#+end_src

- Snakemake
  #+begin_src snakemake
rule normalize:
    input:
        counts = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        bk = config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_tmm_rse.rds",
        loess = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_loess_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_macs2_{join}_{chrom_filt}_{width}_norm.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- [[file:./scripts/normalize.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Normalize peak counts   ###
###

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

in_counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/macs2_all_intersect_open_broad_peaks_rse.rds")

test =make_logcpm(in_counts)

in_norm = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_intersect_open_broad_tmm_rse.rds")

dge = asDGEList(in_norm)

in_norm

head(assays(in_norm)$counts)

colnames(dge) = colnames(in_norm)

# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)



tmm_logcpm = make_logcpm(tmm)



loess_logcpm = make_logcpm(loess)

head(tmm_logcpm)

colnames(tmm)
colnames(test2) = colnames(norm)

pca = prcomp(t(test2))

summary(pca)


saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
**** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./scripts/edger.R][Base script]]
#+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src
**** Reference
- https://mail.google.com/mail/u/0/#inbox/FMfcgzGlkPSkLCSSZzbsHgHQJfDzVHhN
- [[https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt][reske2020 scripts]]

**** Carry forward csaw and do sensitivity analysis with rna
For open vs total x loess vs tmm

Annotate, do sense vs rna
#+begin_src R
library(csaw)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

library(csaw)

standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)


bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))


binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)


library(GenomicRanges)

peaks = read.table("/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2_consensus_beds/all_intersect_open_broad.bed", sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)
granges


all.peaks = granges

pe.bams=c("/mnt/ris/jschwarz/cardiac-radiobiology/atac/bam/lib001_open_tn5.bam","/mnt/ris/jschwarz/cardiac-radiobiology/atac/bam/lib002_open_tn5.bam")

pe.bams =
  list.files("/mnt/ris/jschwarz/cardiac-radiobiology/atac/bam",
           pattern = "_open_tn5.bam$",
           full.names = T)

names(pe.bams) = gsub("_.*$","",  list.files("/mnt/ris/jschwarz/cardiac-radiobiology/atac/bam",
           pattern = "_open_tn5.bam$",
           full.names = F))

peak.counts <- regionCounts(pe.bams, all.peaks, param=param)

save(peak.counts, file = "/tmp/peak.counts.RData")
load("/tmp/peak.counts.RData")
peak.counts

colData(peak.counts)

library(DESeq2)

group =
  data.frame(library_id = colnames(peak.counts)) %>%
  left_join(libraries_full, by = "library_id") %>%
  pull(cohort_id)
group = as.character(group)

colData(peak.counts)$group = group

peakssub = subset(peak.counts, select = !(colnames(peak.counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))

dds = DESeqDataSet(peakssub, design = ~ group)

dds = DESeq(dds)

resultsNames(dds)

test = as.data.frame(DESeq2::results(dds, name = "group_sham_vs_ir48h"))

head(test)

summary(test$log2FoldChange)

summary(test$padj)

length(test$padj[test$padj < 0.1])

#########1#########2#########3#########4#########5#########6#########7#########8
##############################
# MACS2 peaks only: filter low abundance peaks
library("edgeR")
peak.abundances <- aveLogCPM(asDGEList(peak.counts))
peak.counts.filt <- peak.counts[peak.abundances > -3, ] # only use peaks logCPM > -3
# few or no peaks should be removed; modify as desired

##########################################
# NORMALIZATION

# method 1: MACS2 peaks only, TMM normalization based on binned counts
peak.counts.tmm <- peak.counts.filt
peak.counts.tmm <- normFactors(binned, se.out=peak.counts.tmm)
peak.counts.tmm

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
load("/tmp/working.windows.RData")
colData(working.windows)
colData(working.windows)$group = group

counts = working.windows
# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")
library(tidyverse)
# setup design matrix
# see edgeR manual for more information

colnames(y$counts) = names(counts$bam.files)
rownames(y$samples) = names(counts$bam.files)

groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups

colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 500)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = names(counts$bam.files)
rownames(y$samples) = names(counts$bam.files)

rownames(y$samples)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 100)

plotMDS(y, col = colors, top = 500)

(design <- model.matrix(~group, data=y$samples))

colnames(design) = levels(groups)
groups

groups = factor(groups, levels = c("sham", "ir48h", "ir6w"))
levels(groups)

design = model.matrix(~0 + groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

save(y, design, file = "/tmp/y.RData")

load("/tmp/y.RData")

library(edgeR)

if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("DEFormats")

library(DEFormats)
library(DESeq2)

dds = as.DESeqDataSet(y)

dds = DESeq(dds)

resultsNames(dds)

test = as.data.frame(DESeq2::results(dds))

head(test)

summary(test$log2FoldChange)

summary(test$padj)

length(test$padj[test$padj < 0.1])

res = as.data.frame(DESeq2::results(dds, contrast = c("group", "ir6wk", "sham")))

y
fit <- glmQLFit(y, design, robust=TRUE)

fit$design
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(groupir6w-(Intercept), levels=design))

# head(results$table)

library(GenomicRanges)
library(csaw)

head(results$table)
summary(results$table$logFC)
summary(results$table$PValue)
ggplot(results$table, aes(x = PValue)) + geom_density()
# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
summary(tab.best$logFC)
ggplot(tab.best
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)
#+end_src

**** [[file:workflow/peak_call_and_norm.smk][Peak calling and normalization]] :smk:
:PROPERTIES:
:header-args:snakemake:
:END:
***** DONE Call MACS2 narrow                                       :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_macs2_narrow:
    input:
        config["data_dir"] + "/bam/{library_id}_{bam_process}_tn5.bam",
    output:
        expand(config["data_dir"] + "/macs2/{{library_id}}_{{bam_process}}_{ext}", ext = MACS_NARROW_EXT)
    shell:
        """
        base=$(echo $(basename {input}) | sed 's/_tn5.*$//g')
        workflow/scripts/call_macs2_narrow.sh {input} ${{base}} "{config[data_dir]}/macs2"
        """
#+end_src
- Script
  #+begin_src bash
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8
# Check for parameters, return usage if empty
if [[ "$#" -ne 3 ]];
then
    printf "\n usage: call_macs2_broad <BAM FILE> <OUTPUT BASENAME> <OUTPUT DIRECTORY>
    \n Wrapper function for calling broad beaks from ATAC-seq data with MACS2
    \n "
elif
    [[ ! -f "${1}.bai" ]]; then echo "No index for $1"
else
    macs2 callpeak \
          --bdg \
          --call-summits \
          --extsize 150 \
          --format BAMPE \
          --gsize mm \
          --keep-dup all \
          --name $2 \
          --nolambda \
          --nomodel \
          --outdir $3 \
          --SPMR \
          --treatment $1
fi
#+end_src
***** DONE Peak calling, all samples                               :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    input:
        expand(config["bam_dir"] + "/{library_id}_{{bam_process}}_tn5.bam", library_id = LIBRARY_IDS)
    params:
        script = config["atac_script_dir_dir"] + "/select_window_size.R",
	groups_str = "ir48h ir48h sham sham"
    output:
        norm_counts_rse = config["data_dir"] + "/csaw/norm_counts_rse_{bam_process}.rds",
        dge = config["data_dir"] + "/csaw/dge_{bam_process}.rds",
    log:
        config["log_dir"] + "/make_peak_counts_{bam_process}.log",
    shell:
        """
        Rscript {params.script} \
        "{input}" \
        {config[threads]} \
        {output.norm_counts_rse} \
        {output.dge} \
        {params.groups_str} \
        >& {log}
        """
#+end_src
- [[file:./scripts/select_window_size.R][Base script]]
  #+begin_src R :noweb yes

#############################################################################
###            Script for csaw ATAC-seq local peak calling                ###
#############################################################################

# Setup

## Test arguements
## groups_str = "ir48h ir48h sham sham"
## library_ids_str = "/home/jeszyman/repos/atac-seq/test/bam/atac1_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac2_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac3_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac4_open_tn5.bam"
## out_rse_rds = "/home/jeszyman/repos/atac-seq/test/csaw/norm_counts_rse.rds"
## out_dge_rds = "/home/jeszyman/repos/atac-seq/test/csaw/dge.rds"
## threads = 4

## Command line arguements
args = commandArgs(trailingOnly = TRUE)
library_ids_str = args[1]
threads = args[2]
out_rse_rds = args[3]
out_dge_rds = args[4]
groups_str = args[5]

## Load packages
library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

# Specify csaw window parameters
surrounds = 2000
autosomes <- paste0("chr", c(1:19)) # only use autosomes
param = readParam(max.frag=1000, pe="both", restrict=autosomes)

# Make bam file list
bam_list = unlist(strsplit(library_ids_str, " "))
names(bam_list) = gsub("^.*/","",bam_list)

# Filter per Reske JJ, et al. 2021. https://doi.org/10.1186/s13072-020-00342-y

## Choose window width by fragment size distribution
csaw_choose_window = function(bam_list){
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

# Remove dimnames to avoid SummarizedExperiment error in window filtering
dimnames(wider) = NULL
dimnames(counts) = NULL

filter_stat = filterWindowsLocal(counts, wider, assay.data = "counts")

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

# Return library names
colnames(filtered_counts) = names(bam_list)
colnames(background) = names(bam_list)

filtered_counts = normFactors(background, se.out = filtered_counts)

y = asDGEList(filtered_counts)
colnames(y$counts) = colnames(filtered_counts)
rownames(y$samples) = colnames(filtered_counts)

groups = as.factor(unlist(strsplit(groups_str, " ")))
y$samples$group = groups

# Save outputs
saveRDS(object = filtered_counts,
        file = out_rse_rds)
saveRDS(object = y,
        file = out_dge_rds)
#+end_src
**** Filtered bam workflow
***** Call MACS2 merged filtered                                   :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:10]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged_filtered:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5_filt.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow_filt \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad_filt \
              --outdir {params.outdir}
        """
#+end_src
***** Make MACS2 union filtered consensus peaks                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
	ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}_filt.bed",
	ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir6w} > {output.ir6w}
        """
#+end_src
***** Make MACS2 intersect filtered consensus peaks                :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir6w} > {output.ir6w}
        """
#+end_src

***** Make MACS2 naive filtered peaks                              :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:13]
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_filt_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_filt_peaks.{width}Peak",
	ir6w_merge = config["data_dir"] + "/atac/macs2/ir6w_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir6w_merge} {input.ir6w} > {output.ir6w}
        """
#+end_src

***** Make cross cohort consenus
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:16]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_filt_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}_filt.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir6w_{chrom_filt}_{width}_filt.bed",
    output:
        all = config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}_filt.bed",
	ir6w_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}_filt.bed",
	ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}_filt.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} {input.ir6w} > {output.all}
	bedops --merge {input.sham} {input.ir6w} > {output.ir6w_sham}
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
***** BED to GRanges:smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:45]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges_filt:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/{contrast}_{join}_{chrom_filt}_{width}_filt.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}_filt.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src

***** Count from filtered MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_filtered_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}_filt.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src

***** Call csaw filtered local peaks                               :smk_rule:
- Library normalization is performed here, so need to re-run on subset
- Snakemake
  #+begin_src snakemake
rule call_csaw_filtered_local_peaks:
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
        filt_libs = "lib008,lib009,lib010,lib012,lib013,lib014,lib015,lib016,lib017,lib018,lib019,lib020,lib021,lib022,lib023,lib025"
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_filt_peaks_rse.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {params.filt_libs} \
        {output.rse} \
        >& {log}
        """
#+end_src
- [[file:./scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
rse = args[4]

filt_libs = unlist(strsplit(filt_libs_str, ","))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
#+end_src
***** Normalize filtered macs2 peaks                               :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src

**** Normalize                                                     :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-02-16 Wed 13:25] \\
  waiting for counts to finish
:END:
  #+begin_src R
#!/usr/bin/env Rscript
library(csaw)
library(edgeR)

peaks_rse = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds")

bk = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

tmm = normFactors(bk, se.out = peaks_rse)

loess = normOffsets(peaks_rse, se.out = TRUE)

#########1#########2#########3#########4#########5#########6#########7#########8

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

norm_tmm_logcpm = make_logcpm(tmm)
norm_loess_logcpm = make_logcpm(loess)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

make_pca = function(in_cpm){
  pca_out = prcomp(t(in_cpm))
}

pca_list = lapply(cpm_list, make_pca)

make_pca_plots = function(in_pca, full_libs){
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(full_libs, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")
  return(pca_plot)
}

pca_plot_list = lapply(pca_list, make_pca_plots, libraries_full)

legend = get_legend(pca_plot_list[[1]]+
                        guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom")
)

pre_pca_plot_grid = plot_grid(plotlist = pca_plots, labels = names(pca_list))
pre_pca_plot_grid

pca_plot_grid = plot_grid(pre_pca_plot_grid, legend, ncol = 1, rel_heights = c(1,.1))

save_plot("./results/imgs/cpm_pca.pdf", pca_plot_grid,
          base_height = 20, base_width = 20)

#+end_src

- Snakemake
  #+begin_src snakemake
rule normalize:
    input:
        counts = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        bk = config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_tmm_rse.rds",
        loess = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_loess_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_macs2_{join}_{chrom_filt}_{width}_norm.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- [[file:./scripts/normalize.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Normalize peak counts   ###
###

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

in_counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/macs2_all_intersect_open_broad_peaks_rse.rds")

test =make_logcpm(in_counts)

in_norm = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_intersect_open_broad_tmm_rse.rds")

dge = asDGEList(in_norm)

in_norm

head(assays(in_norm)$counts)

colnames(dge) = colnames(in_norm)

# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)



tmm_logcpm = make_logcpm(tmm)



loess_logcpm = make_logcpm(loess)

head(tmm_logcpm)

colnames(tmm)
colnames(test2) = colnames(norm)

pca = prcomp(t(test2))

summary(pca)


saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
**** Make background bins:smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- Snakemake
#+begin_src snakemake
rule make_background_bins:
    params:
        script = config["repo"] + "/workflow/scripts/make_background_bins.R",
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds"
    log:
        config["data_dir"] + "/logs/make_background_bins_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/make_background_bins.R][Base script]]
#+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make background bins for TMM normalization   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse_file = args[3]

library(csaw)

standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)


bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))


binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

saveRDS(object = binned,
        file = rse_file)
#+end_src
**** Count from MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
**** Call csaw local peaks                                         :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_csaw_local_peaks:
    input:
        expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = RUNSAMPLES)
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse = args[3]
dge = args[4]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

edger_input <- asDGEList(filtered_counts)

colnames(edger_input$counts) = colnames(filtered_counts)
rownames(edger_input$samples) = colnames(filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
**** Make merged bams                                              :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:18]
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:16]
- State "DONE"       from              [2022-02-16 Wed 12:14]
:END:
- Snakemake
#+begin_src snakemake
rule make_merged_bams:
    input:
        ir48h =     expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR48H_LIBS),
        sham =      expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = SHAM_LIBS),
    output:
        ir48h = config["data_dir"] + "/atac/bam/ir48h_{chrom_filt}_merged_tn5.bam",
        sham = config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5.bam",
    shell:
        """
        samtools merge -@ {config[threads]} {output.sham} {input.sham}
        samtools merge -@ {config[threads]} {output.ir48h} {input.ir48h}
        """
#+end_src

**** Call MACS2                                                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:31]
- State "DONE"       from              [2022-02-16 Wed 12:18]
:END:
- [[file:/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2]]
- Snakemake
  #+begin_src snakemake
rule call_macs2:
    input:
        config["data_dir"] + "/atac/bam/{library_id}_{chrom_filt}_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{library_id}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
- Reference
  - Function- Narrowpeak as in  cite:corces2018 and cite:hendrickson2017
**** Call MACS2 merged                                             :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:20]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
**** Make MACS2 union consensus peaks                              :smk_rule:
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}.bed",
	ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir48h} > {output.ir48h}
        """
#+end_src
**** Make MACS2 intersect consensus peaks                          :smk_rule:
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir48h} > {output.ir48h}
        """
#+end_src

**** Make MACS2 naive peaks                                        :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_peaks.{width}Peak",
	ir48h_merge = config["data_dir"] + "/atac/macs2/ir48h_{chrom_filt}_{width}_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir48h_merge} {input.ir48h} > {output.ir48h}
        """
#+end_src

**** [#Y] Make cross cohort consenus
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
    output:
        ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
**** BED to GRanges                                                :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/ir48h_sham_{join}_{chrom_filt}_{width}.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src



**** Pass config list test                                         :smk_rule:
- Snakemake
  #+begin_src snakemake
rule pass_config_list_test:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/pass_config_list_test.R",
        #thelist = expand("{sample}", sample = config["IR48H_V_SHAM"]),
        thelist = config["IR48H_V_SHAM"],
    output:
        config["data_dir"] + "/tmp/test.RData"
    log:
        config["data_dir"] + "/logs/pass_config_list_test.log"
    shell:
        """
        thevar="{params.thelist}"
        #echo "{params.thelist}" > {output}
        Rscript {params.script} \
        "${{thevar}}" \
        {output}
        >& {log}
        """
#+end_src
- [[file:./scripts/pass_config_list_test.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###    SCRIPT TITLE   ###
###

args = commandArgs(trailingOnly = TRUE)
passed_list = args[1]
saveloc = args[2]


filt_libs_raw = passed_list
filt_libs = unlist(strsplit(filt_libs_raw, " "))
saveloc = "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/test.RData"

save(filt_libs_raw,
     file = saveloc)
#+end_src
**** Make MACS2 intersect consensus peaks                          :smk_rule:
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir48h} > {output.ir48h}
        """
#+end_src
**** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./scripts/edger.R][Base script]]
#+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src

**** d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)
<<<<<<< HEAD
#+end_src

*** [[file:workflow/peak_call_and_norm.smk][Peak calling and normalization]]                                      :smk:
:PROPERTIES:
:header-args:snakemake:
:END:
**** DONE Call MACS2 narrow                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_macs2_narrow:
    input:
        config["data_dir"] + "/bam/{library_id}_{bam_process}_tn5.bam",
    output:
        expand(config["data_dir"] + "/macs2/{{library_id}}_{{bam_process}}_{ext}", ext = MACS_NARROW_EXT)
    shell:
        """
        base=$(echo $(basename {input}) | sed 's/_tn5.*$//g')
        workflow/scripts/call_macs2_narrow.sh {input} ${{base}} "{config[data_dir]}/macs2"
        """
#+end_src
- Script
  #+begin_src bash
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8
# Check for parameters, return usage if empty
if [[ "$#" -ne 3 ]];
then
    printf "\n usage: call_macs2_broad <BAM FILE> <OUTPUT BASENAME> <OUTPUT DIRECTORY>
    \n Wrapper function for calling broad beaks from ATAC-seq data with MACS2
    \n "
elif
    [[ ! -f "${1}.bai" ]]; then echo "No index for $1"
else
    macs2 callpeak \
          --bdg \
          --call-summits \
          --extsize 150 \
          --format BAMPE \
          --gsize mm \
          --keep-dup all \
          --name $2 \
          --nolambda \
          --nomodel \
          --outdir $3 \
          --SPMR \
          --treatment $1
fi
#+end_src
**** DONE Call MACS2 broad                                            :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_macs2_broad:
    input:
        config["data_dir"] + "/bam/{library_id}_{bam_process}_tn5.bam",
    output:
        expand(config["data_dir"] + "/macs2/{{library_id}}_{{bam_process}}_{ext}", ext = MACS_BROAD_EXT)
    shell:
        """
        base=$(echo $(basename {input}) | sed 's/_tn5.*$//g')
        workflow/scripts/call_macs2_broad.sh {input} ${{base}} "{config[data_dir]}/macs2"
        """
#+end_src
- from cite:corces2018
  #+begin_src bash
#!/usr/bin/env bash
set -o errexit   # abort on nonzero exitstatus
set -o nounset   # abort on unbound variable
set -o pipefail  # don't hide errors within pipes

# Script variables
inbam=$1
outdir=$2

main(){
    macs2_wrapper \
        $inbam \
        $outdir
}

# Functions
macs2_wrapper(){
    local inbam="${1}"
    local outdir="${2}"
    #
    base=$(basename -s .bam $inbam)
    #
    macs2 callpeak \
           --extsize 150 \
          --format BAMPE \
          --gsize mm \
          --keep-dup all \
          --name $base \
          --nolambda \
          --nomodel \
          --outdir $outdir \
          -p 0.01 \
          --shift -75 \
          --treatment $inbam
}

# Run
main "$@"
#+end_src

  #+begin_src bash
#!/usr/bin/env bash
set -o errexit   # abort on nonzero exitstatus
set -o nounset   # abort on unbound variable
set -o pipefail  # don't hide errors within pipes

# Script variables
inbam=$1
outdir=$2

main(){
    macs2_wrapper \
        $inbam \
        $outdir
}

# Functions
macs2_wrapper(){
    local inbam="${1}"
    local outdir="${2}"
    #
    base=$(basename -s .bam $inbam)
    #
    macs2 callpeak \
          --broad \
          --extsize 150 \
          --format BAMPE \
          --gsize mm \
          --keep-dup all \
          --name $base \
          --nolambda \
          --nomodel \
          --outdir $outdir \
          -p 0.01 \
          --shift -75 \
          --treatment $inbam
}

# Run
main "$@"
#+end_src
- Function- Broadpeak as in  cite:corces2018 and cite:hendrickson2017
**** DONE Peak calling, all samples                                   :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    input:
        expand(config["bam_dir"] + "/{library_id}_{{bam_process}}_tn5.bam", library_id = LIBRARY_IDS)
    params:
        script = config["atac_script_dir_dir"] + "/select_window_size.R",
	groups_str = "ir48h ir48h sham sham"
    output:
        norm_counts_rse = config["data_dir"] + "/csaw/norm_counts_rse_{bam_process}.rds",
        dge = config["data_dir"] + "/csaw/dge_{bam_process}.rds",
    log:
        config["log_dir"] + "/make_peak_counts_{bam_process}.log",
    shell:
        """
        Rscript {params.script} \
        "{input}" \
        {config[threads]} \
        {output.norm_counts_rse} \
        {output.dge} \
        {params.groups_str} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/select_window_size.R][Base script]]
  #+begin_src R :noweb yes

#############################################################################
###            Script for csaw ATAC-seq local peak calling                ###
#############################################################################

# Setup

## Test arguements
## groups_str = "ir48h ir48h sham sham"
## library_ids_str = "/home/jeszyman/repos/atac-seq/test/bam/atac1_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac2_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac3_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac4_open_tn5.bam"
## out_rse_rds = "/home/jeszyman/repos/atac-seq/test/csaw/norm_counts_rse.rds"
## out_dge_rds = "/home/jeszyman/repos/atac-seq/test/csaw/dge.rds"
## threads = 4

## Command line arguements
args = commandArgs(trailingOnly = TRUE)
library_ids_str = args[1]
threads = args[2]
out_rse_rds = args[3]
out_dge_rds = args[4]
groups_str = args[5]

## Load packages
library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

# Specify csaw window parameters
surrounds = 2000
autosomes <- paste0("chr", c(1:19)) # only use autosomes
param = readParam(max.frag=1000, pe="both", restrict=autosomes)

# Make bam file list
bam_list = unlist(strsplit(library_ids_str, " "))
names(bam_list) = gsub("^.*/","",bam_list)

# Filter per Reske JJ, et al. 2021. https://doi.org/10.1186/s13072-020-00342-y

## Choose window width by fragment size distribution
csaw_choose_window = function(bam_list){
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

# Remove dimnames to avoid SummarizedExperiment error in window filtering
dimnames(wider) = NULL
dimnames(counts) = NULL

filter_stat = filterWindowsLocal(counts, wider, assay.data = "counts")

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

# Return library names
colnames(filtered_counts) = names(bam_list)
colnames(background) = names(bam_list)

filtered_counts = normFactors(background, se.out = filtered_counts)




#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src
**** Make merged bams                                              :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:18]
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:16]
- State "DONE"       from              [2022-02-16 Wed 12:14]
:END:
- Snakemake
#+begin_src snakemake
rule make_merged_bams:
    input:
        ir48h =     expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR48H_LIBS),
        sham =      expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = SHAM_LIBS),
    output:
        ir48h = config["data_dir"] + "/atac/bam/ir48h_{chrom_filt}_merged_tn5.bam",
        sham = config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5.bam",
    shell:
        """
        samtools merge -@ {config[threads]} {output.sham} {input.sham}
        samtools merge -@ {config[threads]} {output.ir48h} {input.ir48h}
        """
#+end_src

**** Call MACS2                                                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:31]
- State "DONE"       from              [2022-02-16 Wed 12:18]
:END:
- [[file:/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2]]
- Snakemake
  #+begin_src snakemake
rule call_macs2:
    input:
        config["data_dir"] + "/atac/bam/{library_id}_{chrom_filt}_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{library_id}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
- Reference
  - Function- Narrowpeak as in  cite:corces2018 and cite:hendrickson2017
**** Call MACS2 merged                                             :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:20]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
**** Make MACS2 union consensus peaks                              :smk_rule:
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}.bed",
	ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir48h} > {output.ir48h}
        """
#+end_src
**** Make MACS2 naive peaks                                        :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_peaks.{width}Peak",
	ir48h_merge = config["data_dir"] + "/atac/macs2/ir48h_{chrom_filt}_{width}_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir48h_merge} {input.ir48h} > {output.ir48h}
        """
#+end_src

**** Make cross cohort consenus
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
    output:
        ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
**** BED to GRanges                                                :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/ir48h_sham_{join}_{chrom_filt}_{width}.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src


**** Count, normalize, and DE
***** Count from MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/count_from_macs2_consensus.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
***** Call csaw local peaks                                        :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_csaw_local_peaks:
    input:
        expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = RUNSAMPLES)
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/call_csaw_local_peaks.R
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse = args[3]
dge = args[4]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

edger_input <- asDGEList(filtered_counts)

colnames(edger_input$counts) = colnames(filtered_counts)
rownames(edger_input$samples) = colnames(filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
***** Make background bins:smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- Snakemake
#+begin_src snakemake
rule make_background_bins:
    params:
        script = config["repo"] + "/workflow/scripts/make_background_bins.R",
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds"
    log:
        config["data_dir"] + "/logs/make_background_bins_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/make_background_bins.R][Base script]]
#+begin_src R :noweb yes :tangle ./scripts/make_background_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make background bins for TMM normalization   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse_file = args[3]

library(csaw)

standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)


bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))


binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

saveRDS(object = binned,
        file = rse_file)
#+end_src
***** Normalize                                                    :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-02-16 Wed 13:25] \\
  waiting for counts to finish
:END:
  #+begin_src R
#!/usr/bin/env Rscript
library(csaw)
library(edgeR)

peaks_rse = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds")

bk = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

tmm = normFactors(bk, se.out = peaks_rse)

loess = normOffsets(peaks_rse, se.out = TRUE)

#########1#########2#########3#########4#########5#########6#########7#########8

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

norm_tmm_logcpm = make_logcpm(tmm)
norm_loess_logcpm = make_logcpm(loess)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

make_pca = function(in_cpm){
  pca_out = prcomp(t(in_cpm))
}

pca_list = lapply(cpm_list, make_pca)

make_pca_plots = function(in_pca, full_libs){
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(full_libs, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")
  return(pca_plot)
}

pca_plot_list = lapply(pca_list, make_pca_plots, libraries_full)

legend = get_legend(pca_plot_list[[1]]+
                        guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom")
)

pre_pca_plot_grid = plot_grid(plotlist = pca_plots, labels = names(pca_list))
pre_pca_plot_grid

pca_plot_grid = plot_grid(pre_pca_plot_grid, legend, ncol = 1, rel_heights = c(1,.1))

save_plot("./results/imgs/cpm_pca.pdf", pca_plot_grid,
          base_height = 20, base_width = 20)

#+end_src

- Snakemake
  #+begin_src snakemake
rule normalize:
    input:
        counts = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        bk = config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_tmm_rse.rds",
        loess = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_loess_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_macs2_{join}_{chrom_filt}_{width}_norm.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- [[file:./scripts/normalize.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Normalize peak counts   ###
###

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

in_counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/macs2_all_intersect_open_broad_peaks_rse.rds")

test =make_logcpm(in_counts)

in_norm = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_intersect_open_broad_tmm_rse.rds")

dge = asDGEList(in_norm)

in_norm

head(assays(in_norm)$counts)

colnames(dge) = colnames(in_norm)

# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)



tmm_logcpm = make_logcpm(tmm)



loess_logcpm = make_logcpm(loess)

head(tmm_logcpm)

colnames(tmm)
colnames(test2) = colnames(norm)

pca = prcomp(t(test2))

summary(pca)


saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
**** Filtered bam workflow
***** Call MACS2 merged filtered                                   :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:10]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged_filtered:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5_filt.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow_filt \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad_filt \
              --outdir {params.outdir}
        """
#+end_src
***** Make MACS2 union filtered consensus peaks                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
	ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}_filt.bed",
	ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir6w} > {output.ir6w}
        """
#+end_src
***** Make MACS2 intersect filtered consensus peaks                :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir6w} > {output.ir6w}
        """
#+end_src

***** Make MACS2 naive filtered peaks                              :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:13]
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_filt_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_filt_peaks.{width}Peak",
	ir6w_merge = config["data_dir"] + "/atac/macs2/ir6w_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir6w_merge} {input.ir6w} > {output.ir6w}
        """
#+end_src

***** Make cross cohort consenus
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:16]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_filt_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}_filt.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir6w_{chrom_filt}_{width}_filt.bed",
    output:
        all = config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}_filt.bed",
	ir6w_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}_filt.bed",
	ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}_filt.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} {input.ir6w} > {output.all}
	bedops --merge {input.sham} {input.ir6w} > {output.ir6w_sham}
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
***** BED to GRanges:smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:45]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges_filt:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/{contrast}_{join}_{chrom_filt}_{width}_filt.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}_filt.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/bed_to_granges.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src

***** Count from filtered MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_filtered_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}_filt.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/count_from_macs2_consensus.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src

***** Make filtered background bins
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-01 Tue 09:00]
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- just need to filter to filt libs
#+begin_src R
library(SummarizedExperiment)

bkbin_open = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_rse.rds")

bkbin_regfilt = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_regfilt_rse.rds")

filt_libs = c("lib008", "lib009", "lib010", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib025")

bkbin_open_filt = bkbin_open[,colnames(bkbin_open) %in% filt_libs]

bkbin_regfilt_filt = bkbin_regfilt[,colnames(bkbin_regfilt) %in% filt_libs]

saveRDS(object = bkbin_open_filt,
        file = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

saveRDS(object = bkbin_regfilt_filt,
        file = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_regfilt_filt_rse.rds")
#+end_src

***** Normalize filtered csaw peaks                                :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes :tangle ./scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
***** Normalize filtered macs2 peaks                               :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes :tangle ./scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src


**** check pca norms vs 48h using csaw counts
#+begin_src R
library(csaw)
library(edgeR)
library(tidyverse)
library(ggrepel)

peaks_rse = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds")

bk = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

keep_libs = c("lib008", "lib013", "lib009", "lib010", "lib015", "lib011", "lib012", "lib016", "lib018", "lib020", "lib022", "lib024")

peaks_rse = peaks_rse[, colnames(peaks_rse) %in% keep_libs]
bk = bk[,colnames(bk) %in% keep_libs]
bk = bk[,colnames(bk) != "lib022"]

tmm = normFactors(bk, se.out = peaks_rse)

loess = normOffsets(peaks_rse, se.out = TRUE)

#########1#########2#########3#########4#########5#########6#########7#########8

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

norm_tmm_logcpm = make_logcpm(tmm)
norm_loess_logcpm = make_logcpm(loess)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

make_pca = function(in_cpm){
  pca_out = prcomp(t(in_cpm))
}

tmm_pca = make_pca(norm_tmm_logcpm)

make_pca_plots = function(in_pca, full_libs){
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(full_libs, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")
  return(pca_plot)
}

pca_plot = make_pca_plots(tmm_pca, libraries_full)

pca_plot
pca_plot_list = lapply(pca_list, make_pca_plots, libraries_full)

legend = get_legend(pca_plot_list[[1]]+
                        guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom")
)

pre_pca_plot_grid = plot_grid(plotlist = pca_plots, labels = names(pca_list))
pre_pca_plot_grid

pca_plot_grid = plot_grid(pre_pca_plot_grid, legend, ncol = 1, rel_heights = c(1,.1))

save_plot("./results/imgs/cpm_pca.pdf", pca_plot_grid,
          base_height = 20, base_width = 20)

#+end_src

- Snakemake
  #+begin_src snakemake
rule normalize:
    input:
        counts = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        bk = config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_tmm_rse.rds",
        loess = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_loess_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_macs2_{join}_{chrom_filt}_{width}_norm.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- [[file:./scripts/normalize.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Normalize peak counts   ###
###

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

in_counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/macs2_all_intersect_open_broad_peaks_rse.rds")

test =make_logcpm(in_counts)

in_norm = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_intersect_open_broad_tmm_rse.rds")

dge = asDGEList(in_norm)

in_norm

head(assays(in_norm)$counts)

colnames(dge) = colnames(in_norm)

# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)



tmm_logcpm = make_logcpm(tmm)



loess_logcpm = make_logcpm(loess)

head(tmm_logcpm)

colnames(tmm)
colnames(test2) = colnames(norm)

pca = prcomp(t(test2))

summary(pca)


saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src


**** Tn5 shift filtered alignments                                 :smk_rule:
- Snakemake
  #+begin_src snakemake
rule tn5_shift:
    container:
        atac_container,
    input:
        atac_bam_filt + "/{library}_filt.bam",
    log:
        config["log_dir"] + "/{library}_tn5_shift.log",
    output:
        tmp = temp(atac_bam_tn5 + "/{library}_tn5_tmp.bam"),
        tn5 =      atac_bam_tn5 + "/{library}_tn5.bam",
    params:
        script = config["scriptdir"]["atac"] + "/tn5_shift.sh",
        threads = config["threads"],
    shell:
        """
        {params.script} \
        {input} \
        {output.tmp} \
        {output.tn5} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:./scripts/todo_tn5_shift.sh][Base script]]
  #+begin_src bash :tangle ./scripts/tn5_shift.sh
inbam=$1
outtmp=$2
outbam=$3
threads=$4

alignmentSieve --ATACshift --bam "$1" --numberOfProcessors $4 --outFile "$2"

samtools sort -@ $4 -o $3 $2
samtools index -@ $4 $3
#+end_src
**** Get Tn5-shifted alignments to open chromatin                  :smk_rule:
- Snakemake
  #+begin_src snakemake
rule open_chrom:
    container:
        atac_container,
    input:
        atac_bam_tn5 + "/{library}_tn5.bam",
    log:
        config["log_dir"] + "/{library}_open_chrom.log",
    output:
        tmp = temp(atac_bam_open + "/{library}_open_tmp.bam"),
        open = atac_bam_open + "/{library}_open.bam",
    params:
        script = config["scriptdir"]["atac"] + "/open_chrom.sh",
        threads = config["threads"],
    shell:
        """
        {params.script} \
        {input} \
        {output.tmp} \
        {output.open} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:workflow/scripts/open_chrom.sh][Base script]]
  #+begin_src bash :tangle ./scripts/open_chrom.sh
  input=$1
    tmp=$2
   open=$3
threads=$4

alignmentSieve --bam $input \
               --maxFragmentLength 150 \
               --numberOfProcessors $threads \
               --outFile $tmp
samtools sort -@ $threads -o $open $tmp
samtools index -@ $threads $open
#+end_src

**** Ideas
- https://www.biostars.org/p/442760/
- [ ] bowtie to version 2.4.5 for multithreading build
- normailzed read density in frag size distribution
  - https://www.biostars.org/p/220132/
  - https://www.biostars.org/p/219679/#219835
  - https://www.biostars.org/p/442760/
- FRIP
  - https://www.biostars.org/p/337872/
- upgrade to fastp https://workflowhub.eu/workflows/224https://community.brave.com/t/how-to-block-specific-websites/55961/8
- add flexbar files to multiqc
- ? cp /mnt/ris/jschwarz/cardiac-radiobiology/ref/keep.bed resources/keep.bed
***** ideas
- cite:liu2021 https://www.sciencedirect.com/science/article/pii/S1672022921001479
- for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
- lib complexity w/ preseq http://smithlabresearch.org/software/preseq/ https://github.com/smithlabcode/preseq

- common
  #+begin_src bash


CHROM_FILT:
  - "open"
  - "regfilt"

JOIN:
  - "union"
  - "intersect"
  - "naive"

WIDTH:
  - "broad"
  - "narrow"

#+end_src
#+begin_src bash
git add -A
git commit -m "feat: initial dev"
git push origin master

git branch dev_initial
git checkout dev_initial
git push origin dev_initial
#+end_src

#+begin_src bash
git init
git add -A
git commit -am "First commit"
git branch -M master

#
git remote add origin git@github.com:jeszyman/atac-seq.git
git branch -M master
git push -u origin master

cp basecamp/src/pre-commit src/precommit_git_hook
ln -s src/precommit_git_hook .git/hooks/precommit
chmod 777 .git/hooks/precommit
#+end_src

- startup script
  #+begin_src bash
#!/usr/bin/env bash
repo=$1
mntpt=$2
sif_dir=$3

# Check for parameters, return usage if empty
if [ $# -ne 3 ];
then
    printf "\n usage: repo_startup.sh <REPO PATH> <RIS MOUNT PT> <SINGULARITY CONTAINER DIR>
    \n ATAC-seq repo development helper script
    \n "
else

    # Check git file hook is read-able
    if [ -r "${repo}/.git/hooks/precommit" ]; then
        echo "Git size check is read-able"
    else
        echo
        "Git size check is not read-able"
        exit 1
    fi

    # Check mount point
    if grep -qs $mntpt /proc/mounts; then
        echo "RIS storage mounted."
    else
        echo "RIS storage NOT mounted, exiting."
        exit 1
    fi

    # Check singularity container
    if [ -r $sif_dir/atac.sif ]; then
        echo "Local SIF file present"
    else
        echo "No local SIF file found"
        exit 1
    fi

    # Check singularity container up-to-date
    if [ /mnt/ris/jschwarz/cardiac-radiobiology/atac.sif -nt $sif_dir/atac.sif ]; then
        echo "Local SIF is out of date. Updating ..."
        cp /mnt/ris/jschwarz/cardiac-radiobiology/atac.sif $sif_dir/atac.sif
    else
        echo "Local SIF file is up to date"
    fi

    cur_branch=$(git branch | head -n 1)
    echo "Current branch is $cur_branch"
fi
#+end_src




- [ ] https://github.com/snakemake-workflows/rna-seq-star-deseq2/blob/master/workflow/rules/common.smk


#+begin_src python
import pandas as pd
import re

libraries = (
    pd.read_csv("/home/jeszyman/repos/atac-seq/test/inputs/full_libraries.tsv", sep="\t",
		dtype={"library_id": str})
    .set_index("library_id", drop=False)
    .sort_index()
)

read1str=pd.Series(libraries.library_fq_r1_basename, dtype="string")

libraries["library_fq_r2_basename"] = [re.sub("R1.fastq.gz","R2.fastq.gz", x) for x in read1str]

#+end_src

libraries = (
    pd.read_csv("/home/jeszyman/repos/atac-seq/test/inputs/full_libraries.tsv", sep="\t",
		dtype={"library_id": str})
    .set_index("library_id", drop=False)
    .sort_index()
)


- add tablular sample input https://github.com/snakemake-workflows/rna-seq-star-deseq2
:header-args: :tangle no
- transcription factor sites
- homer superenhancers http://homer.ucsd.edu/homer/ngs/peaks.html


****** ATAC-seq peak calling and chromating accessibility on subsets
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-03-31 Thu 14:25]
:END:
  - [-] run 48h
    #+begin_src bash
lib_str="lib008 lib009 lib010 lib011 lib012 lib013 lib014 lib015 lib016"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
      "_open_tn5.bam$" \
      "${lib_str}" \
      16 \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_open_background_counts.rds \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_open_counts.rds

#+end_src
  - [ ] run 6wk
  - [-] run 48h
    #+begin_src bash
lib_str="lib008 lib009 lib010 lib011 lib012 lib013 lib014 lib015 lib016"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
      "_regfilt_tn5.bam$" \
      "${lib_str}" \
      16 \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_regfilt_background_counts.rds \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_regfilt_counts.rds

#+end_src
  - [ ] run 6wk

- run ir48h vs sham
- run ir6w vs sham



******** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
******** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
********* Make backgroud bins                                      :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_backgroud_bins:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/make_backgroud_bins.R"
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
    output:
    log:
        config["data_dir"] + "/logs/make_backgroud_bins.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./scripts/make_backgroud_bins.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/make_backgroud_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to make background bins for csaw TMM normalization   ###
###

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
window_file =  args[1]
bam_dir = args[2]
bam_pattern = args[3]
filt_libs_str = args[4]
rse = args[4]
bk = args[5]

filt_libs = unlist(strsplit(filt_libs_str, " "))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

#+end_src
********* d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src

********** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./scripts/edger.R][Base script]]
#+begin_src R :noweb yes :tangle ./scripts/edger.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src
****** Ideas
  - full log to catch this error
    - - https://www.biostars.org/p/396538/
    - note- log didn't work [[file:/mnt/ris/jschwarz/cardiac-radiobiology/log/fastqc_log.txt]]
    - #TODO how to add log file to find "$data_dir}/atac/atac-fastq" -name "*.fastq.gz" | parallel fastqc --outdir="$data_dir}/qc" }
  - preamble


******* Reference
- [[https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt][reske csaw workflow]]
******* Hold and dev
:PROPERTIES:
header-args:snakemake: :tangle no
:END:
******* Ideas
:PROPERTIES:
header-args:snakemake: :tangle no
:END:
****** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:

******* [#Y] Make nucleosome positioning alignments
:PROPERTIES:
:CREATED:  [2021-09-02 Thu 11:22]
:ID:       5acea857-b98c-473b-9b23-d430665cbb4d
:END:
:LOGBOOK:
- State "RUN"        from "DONE"       [2021-09-22 Wed 10:09]
- State "DONE"       from "CANCELED"   [2021-09-22 Wed 10:09]
CLOCK: [2021-09-15 Wed 09:35]--[2021-09-15 Wed 10:53] =>  1:18
:END:
#+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                              "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                              "TC", "UQ"),
               "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                             "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                             "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                             "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                             "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                   param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

save(gal_lib051,
   gal_lib052,
   gal_lib053,
   gal_lib054,
   gal_lib055,
   gal_lib057,
   file = file.path(data_dir,"atac/gal.RData"))

#+end_src
- Reference
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
******* ATAC-seq QC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule atac-seq_qc:
    input:
    params:
        script = config["repo"] + "workflow/scripts/atac-seq_qc.R"
    output:
    log:
        config["data_dir"] + "/logs/atac-seq_qc.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./scripts/atac-seq_qc.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/atac-seq_qc.R
#########1#########2#########3#########4#########5#########6#########7#########8

###
###   / SCRIPT TITLE   ###
###

#+end_src

******** Transcription start sites occupancy
:PROPERTIES:
:CREATED:  [2021-09-15 Wed 10:09]
:ID:       eecd41c6-4f32-4d79-b7d5-40d666b8f85b
:END:
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#setwd("/home/jeszyman/repos/card-rad-bio")
#source("./src/setup.R")
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                                "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                                "TC", "UQ"),
                 "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                               "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                               "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                               "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                               "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                     param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

save(gal_lib051,
     gal_lib052,
     gal_lib053,
     gal_lib054,
     gal_lib055,
     gal_lib057,
     file = file.path(data_dir,"atac/gal.RData"))


#########1#########2#########3#########4#########5#########6#########7#########8
tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+begin_src R
#TODO LOAD gals
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
txs <- transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)

tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+caption: CAPTION label:fig-atac-nuc-position
[[file:results/imgs/atac_nuc_position.pdf][file:results/imgs/atac_nuc_position.pdf]]



- Post-atacseqqc
#+end_src

BiocManager::install("diffloop")

library(diffloop)
library(TxDb.Mmusculus.UCSC.mm10.knownGene)

seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = scanBam(bam_list[1])
class(test)


bamTop100 <- scanBam(BamFile(bam_list[1], yieldSize = 100))
bam_list[1]
bamTag(bamTop100)



gal = readBamFile(bam_list[1], tags = tags, which = which, asMates = T, bigFile=T)

gal
param = ScanBamParam(tag))

which
test = rmchr(which)
test
test = renameSeqlevels(which, c("chr1"="1"))
test


test=rmchr(which)
head(which)


gal
## Promotor / transcript score
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
pt = PTscore(gal, txs)

## Nucleosome free regions score
nfr = NFRscore(gal, txs)

## Transcription start site enrichment
tsse = TSSEscore(gal, txs)

# Ideas
## Adjust start sites
#+end_src
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
- lib complexity w/ preseq http://smithlabresearch.org/software/preseq/ https://github.com/smithlabcode/preseq


TSSEs
ir01 - 2.75


#+caption: CAPTION label:fig-atac-tss
[[file:results/imgs/atac_tss.pdf]]

******** Aggregate
:PROPERTIES:
:CREATED:  [2021-09-21 Tue 07:29]
:ID:       a9426a9b-16e8-4356-8d98-314b4c7f8ec5
:END:
******** notes
:PROPERTIES:
:ID:       06f9345e-a489-4b5e-9f68-82e22e468096
:END:
- run on server, run launch_atac to load docker with ATACseqQC package
- do not run R docker through docker_interactive function- unknown error
- cite:liu2021 https://www.sciencedirect.com/science/article/pii/S1672022921001479

******* MultiQC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule multiqc:
    input:
    output:
    shell:
        """
        scripts/multiqc.sh
        """
#+end_src
- [[file:./scripts/multiqc.sh][Base script]]
  #+begin_src bash :tangle ./scripts/multiqc.sh
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

# Snakemake variables
# Function
# Run command
#########1#########2#########3#########4#########5#########6#########7#########8
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

#+end_src
******* Make frag distribution mat:smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_frag_distribution_mat:
    input:
        bam_dir = config["data_dir"] + "/atac/bam",
    params:
        script = config["repo"] + "/workflow/scripts/make_frag_distribution_mat.R",
    output:
        frag_dist = config["data_dir"] + "/qc/frag_dist.rds",
    log:
        config["data_dir"] + "/logs/make_frag_distribution_mat.log"
    shell:
        """
        Rscript {params.script} \
	{input.bam_dir} \
	{output.frag_dist}
        >& {log}
        """
#+end_src
- [[file:./scripts/make_frag_distribution_mat.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/make_frag_distribution_mat.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make fragment size distribution matrix   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)

bam_files = list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = TRUE)

names(bam_files) = gsub("_dedup.bam", "", list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = FALSE))

#' @title fragment size distribution
#' @description estimate the fragment size of bams
#' @param bamFiles A vector of characters indicates the file names of bams.
#' @param index The names of the index file of the 'BAM' file being processed;
#'        This is given without the '.bai' extension.
#' @param bamFiles.labels labels of the bam files, used for pdf file naming.
#' @param ylim numeric(2). ylim of the histogram.
#' @param logYlim numeric(2). ylim of log-transformed histogram for the insert.
#' @return Invisible fragment length distribution list.
#' @importFrom Rsamtools ScanBamParam scanBamFlag scanBam idxstatsBam
#' @importFrom graphics axis par
#' @import GenomicRanges
#' @export
#' @author Jianhong Ou
#' @examples
#' bamFiles <- dir(system.file("extdata", package="ATACseqQC"), "GL.*.bam$", full.names=TRUE)
#' bamFiles.labels <- sub(".bam", "", basename(bamFiles))
#' fragSizeDist(bamFiles, bamFiles.labels)

fragSizeDist <- function(bamFiles, bamFiles.labels, index=bamFiles, ylim=NULL,
                         logYlim=NULL){
  opar <- par(c("fig", "mar"))
  on.exit(par(opar))
  pe <- mapply(testPairedEndBam, bamFiles, index)
  if(any(!pe)){
    stop(paste(bamFiles[!pe], collapse = ", "),
         "is not Paired-End file.")
  }
  summaryFunction <- function(seqname, seqlength, bamFile, ind, ...) {
    param <-
      ScanBamParam(what=c('isize'),
                   which=GRanges(seqname, IRanges(1, seqlength)),
                   flag=scanBamFlag(isSecondaryAlignment = FALSE,
                                    isUnmappedQuery=FALSE,
                                    isNotPassingQualityControls = FALSE))
    table(abs(unlist(sapply(scanBam(bamFile, index=ind, ..., param=param),
                            `[[`, "isize"), use.names = FALSE)))
  }
}

idxstats <- unique(do.call(rbind, mapply(function(.ele, .ind)
    idxstatsBam(.ele, index = .ind)[, c("seqnames", "seqlength")], bamFiles, index, SIMPLIFY=FALSE)))
  seqnames <- as.character(idxstats[, "seqnames"])
  seqlen <- as.numeric(idxstats[, "seqlength"])
  fragment.len <- mapply(function(bamFile, ind) summaryFunction(seqname=seqnames, seqlength=seqlen, bamFile, ind),
                         bamFiles, index, SIMPLIFY=FALSE)

  names(fragment.len) <- bamFiles.labels

  ## minor.ticks.axis <- function(ax,n=9,t.ratio=0.5,mn,mx,...){

  ##   lims <- par("usr")
  ##   lims <- if(ax %in% c(1,3)) lims[1:2] else lims[3:4]

  ##   major.ticks <- pretty(lims,n=5)
  ##   if(missing(mn)) mn <- min(major.ticks)
  ##   if(missing(mx)) mx <- max(major.ticks)

  ##   major.ticks <- major.ticks[major.ticks >= mn & major.ticks <= mx]

  ##   labels <- sapply(major.ticks,function(i)
  ##     as.expression(bquote(10^ .(i)))
  ##   )
  ##   axis(ax,at=major.ticks,labels=labels,
  ##        las=ifelse(ax %in% c(2, 4), 2, 1), ...)

  ##   n <- n+2
  ##   minors <- log10(pretty(10^major.ticks[1:2],n))-major.ticks[1]
  ##   minors <- minors[-c(1,n)]

  ##   minor.ticks = c(outer(minors,major.ticks,`+`))
  ##   minor.ticks <- minor.ticks[minor.ticks > mn & minor.ticks < mx]


  ##   axis(ax,at=minor.ticks,tcl=par("tcl")*t.ratio,labels=FALSE)
  ## }

  ## null <- mapply(function(frag.len, frag.name){
  ##   x <- 1:1010
  ##   frag.len <- frag.len[match(x, names(frag.len))]
  ##   frag.len[is.na(frag.len)] <- 0
  ##   y <- frag.len / sum(frag.len)
  ##   y <- as.numeric(y)
  ##   names(y) <- x
  ##   par(mar=c(5, 5, 4, 2) +.1)
  ##   plot(x, y*10^3, main=paste(frag.name, "fragment sizes"),
  ##        xlim=c(0, 1010), ylim=ylim,
  ##        xlab="Fragment length (bp)",
  ##        ylab=expression(Normalized ~ read ~ density ~ x ~ 10^-3),
  ##        type="l")
  ##   par(fig=c(.4, .95, .4, .95), new=TRUE)
  ##   plot(x, log10(y), xlim=c(0, 1010), ylim=logYlim,
  ##        xlab="Fragment length (bp)", ylab="Norm. read density",
  ##        type="l", yaxt="n")
  ##   minor.ticks.axis(2)
  ##   par(opar)
  ## }, fragment.len, names(fragment.len))

  #return(invisible(fragment.len))
}

frag_dist = fragSizeDist(bam_files, names(bam_files))

saveRDS(object = frag_dist,
        file  = rds)
#+end_src
- Old code
  #+begin_src R



class(test)


names(test)

class(test[[1]])

head(test[[1]])
data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

pdf("/tmp/test.pdf")
lib051_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib051_aut_blk_ddp.bam", bamFiles.labels = "lib051")
lib052_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib052_aut_blk_ddp.bam", bamFiles.labels = "lib052")
lib053_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib053_aut_blk_ddp.bam", bamFiles.labels = "lib053")
lib054_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib054_aut_blk_ddp.bam", bamFiles.labels = "lib054")
lib055_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib055_aut_blk_ddp.bam", bamFiles.labels = "lib055")
lib056_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib056_aut_blk_ddp.bam", bamFiles.labels = "lib056")
lib057_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib057_aut_blk_ddp.bam", bamFiles.labels = "lib057")
dev.off()

save(lib051_frag,lib052_frag,lib053_frag,lib054_frag,lib055_frag,lib056_frag,lib057_frag, file = "~/repos/card-rad-bio/results/qc/frag.RData")

#########1#########2#########3#########4#########5#########6#########7#########8
load("./results/qc/frag.RData")
getwd()
#+end_src
  #+begin_src R
load("/mnt/ris/jschwarz/cardiac-radiobiology/atac/fragsize.RData")

ls()

fragsize_ct01
#+end_src
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#
load(file.path(data_dir,"/atac/fragsize.RData"))

# Rename old frag size files
fragsize_lib051 = fragsize_ct01
fragsize_lib052 = fragsize_ct02
fragsize_lib053 = fragsize_ir01
fragsize_lib054 = fragsize_ir02
fragsize_lib055 = fragsize_ir03
fragsize_lib056 = fragsize_ir04
fragsize_lib057 = fragsize_ct03

# create df
fragsize = data.frame(
  length = as.numeric(names(head(fragsize_lib051[[1]], n = 1000))),
  lib051 = as.vector(head(fragsize_lib051[[1]], n = 1000)),
  lib052 = as.vector(head(fragsize_lib052[[1]], n = 1000)),
  lib053 = as.vector(head(fragsize_lib053[[1]], n = 1000)),
  lib054 = as.vector(head(fragsize_lib054[[1]], n = 1000)),
  lib055 = as.vector(head(fragsize_lib055[[1]], n = 1000)),
  lib057 = as.vector(head(fragsize_lib057[[1]], n = 1000)))
fragsize = as_tibble(fragsize)

# save df
save(fragsize, file = file.path(repo,"/results/rdata/atac_fragsize.RData"))

# make plot
fragsize %>%
  pivot_longer(cols = !length, names_to = "library_id", values_to = "count") %>%
  ggplot(., aes(x = length, y = count, group = library_id)) + geom_line() + xlim()

+ geom_bar(stat = "identity")

#+end_src


****** Library complexity:smk_rule:
- Snakemake
  #+begin_src snakemake
rule library_complexity:
    input:
        config["bam_dir"] + "/{library_id}.bam",
    params:
        script = config["atac_script_dir_dir"] + "/library_complexity.R",
    output:
        config["qc_dir"] + "/{library_id}_libcomplex.rds",
    log:
        config["log_dir"] + "/{library_id}_library_complexity.log",
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./scripts/library_complexity.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/library_complexity.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to assess ATAC-seq library complexity by fragment length   ###
###

args = commandArgs(trailingOnly = TRUE)
bam = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

libCompWrap = function(dup_bam){
  estimateLibComplexity(readsDupFreq(dup_bam))
}

complex = libCompWrap("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5469_MGI2048/lc-08.TCGTGATCAG-ACACTACGTA/lc-08.TCGTGATCAG-ACACTACGTA.genome_accepted_hits.bam")

saveRDS(object = complex,
        file = rds)

#+end_src
- Reference
  - https://github.com/smithlabcode/preseq
  - lib complexity w/ preseq http://smithlabresearch.org/software/preseq/
  - Old code
    #+begin_src R
  load(file.path(repo,"/results/rdata/library_complexity_raw.RData"))
  ls()
  head(library_complexity_raw)

  test = as.data.frame(library_complexity_raw)

  lib_complex_plot =
    as.data.frame(library_complexity_raw) %>%
    pivot_longer(cols = ends_with("values"), names_to = "library_id", values_to = "pred") %>%
    pivot_longer(cols = ends_with("reads"), names_to = "library_id2", values_to = "reads") %>%
    select(!(ends_with("relative.size"))) %>%
    mutate(library_id = substr(library_id, 1, 6)) %>%
    select(library_id, pred, reads) %>%
    filter(library_id != "lib056") %>%
    ggplot(., aes(x = reads, y = pred, group = library_id)) + geom_smooth(se = FALSE) +
     xlab("Total molecules") + ylab("Unique molecules")
  save_plot("./results/imgs/lib_complex.pdf", lib_complex_plot)

  #+end_src

    #+begin_src R

  load("./results/rdata/library_complexity_raw.RData")
  load("./data/data_model.RData")

  atac_multiqc_general_raw =
    as_tibble(
      read.table(
        file.path(repo,"results/qc/atac_qc_data/multiqc_general_stats.txt"),
        header = T,
        sep = '\t',
        fill = T))

  atac_multiqc_general_raw


  ## Modify atac multiqc df
  atac_multiqc_general_mod =
    atac_multiqc_general_raw %>%
    mutate(library_id = gsub("^.....", "", Sample)) %>%
    mutate(library_id = gsub("_.*$", "", library_id)) %>%
    mutate(total_reads = FastQC_mqc.generalstats.fastqc.total_sequences) %>%
    mutate(aligned_reads = Samtools_mqc.generalstats.samtools.mapped_passed) %>%
    mutate(processing = ifelse(grepl("_R1", Sample), "raw",
                        ifelse(grepl("ddp_flagstat", Sample), "processed",
                               ifelse(grepl("ddp_open_flagstat", Sample), "open", "other")))) %>%
    filter(processing != "other") %>%
    filter(!grepl("_R2", Sample)) %>%
    filter(!grepl("flex", Sample)) %>%
    filter(!is.na(total_reads) | !is.na(aligned_reads)) %>%
    mutate(read_prs = ifelse(!is.na(total_reads), total_reads, aligned_reads)) %>%
    select(library_id, processing, read_prs) %>%
    pivot_wider(names_from = processing, values_from = read_prs) %>%
    mutate(p_proc = processed/raw*100) %>%
    mutate(p_open = open/raw*100)
  atac_multiqc_general_mod

  library_complexity_mod = as_tibble(data.frame(lib051 = library_complexity_raw[[1]],
                                      lib052 = library_complexity_raw[[2]],
                                      lib053 = library_complexity_raw[[3]],
                                      lib054 = library_complexity_raw[[4]],
                                      lib055 = library_complexity_raw[[5]],
                                      lib056 = library_complexity_raw[[6]],
                                      lib057 = library_complexity_raw[[7]])) %>%
    mutate(rel_size = lib051.relative.size) %>%
    select(!ends_with("relative.size")) %>%
    pivot_longer(cols = starts_with("lib"), names_to = "label", values_to = "count") %>%
    mutate(library_id = substr(label, 1, 6)) %>%
    mutate(label = gsub("^.*\\.","",label)) %>%
    pivot_wider(names_from = label, values_from = count) %>%
    left_join(libraries, by = "library_id")
  library_complexity_mod

  library_complexity =
    library_complexity_mod %>%
    left_join(atac_multiqc_general_mod, by = "library_id") %>%
    filter(p_proc > 25)

  library_complexity_plot =
    library_complexity %>%
    ggplot(., aes(x = values, y = reads)) + geom_smooth()
  library_complexity_plot

  save_plot("./results/imgs/lib_complex.pdf", library_complexity_plot)

  #+end_src
****** Make fastq input symlinks
#+begin_src snakemake
rule symlink_fastqs:
    params:
        fastq = lambda w: libraries[libraries.library_id == w.library_id].fq_basename.tolist()
    output:
        r1 = config["fq_sym_dir"] + "/{library_id}_R1.fastq.gz",
        r2 = config["fq_sym_dir"] + "/{library_id}_R2.fastq.gz",
    shell:
        """
        ln -sf --relative {config[fq_src_dir]}/{params.fastq}_R1.fastq.gz {output.r1}
        ln -sf --relative {config[fq_src_dir]}/{params.fastq}_R2.fastq.gz {output.r2}
        """
#+end_src
****** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/differential_accessibility.R
#!/usr/env R

#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
### Script to generate ATAC-seq differential accessibility model with EdgeR  ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8

# Setup

## Command line arguements
args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

## Load libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Load data
counts = readRDS(counts_rds)
background = readRDS(background_rds)
load(data_model)

# Run EdgeR workflow
counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design = model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src

******* Differential accessibility 6wk vs. sham                    :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/differential_accessibility.R

#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to generate differential accessibility model with EdgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
load(data_model)
background = readRDS(background_rds)

counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design <- model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src

******* Differential accessibility 48h vs. sham                    :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/differential_accessibility.R

# needs to be part of counts step
colnames(counts) = c("lib001","lib002","lib003","lib004")


#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
###   Script to generate differential accessibility model with EdgeR         ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8

args = commandArgs(trailingOnly = TRUE)

counts_rds = "~/repos/atac-seq/test/csaw/counts_all_regfilt_rse.rds"
background_rds = "~/repos/atac-seq/test/csaw/background_counts_all_regfilt_rse.rds"
groups = as.factor(c("ir48h","ir48h","sham","sham"))
contrast = "ir48h-sham"

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
background = readRDS(background_rds)
counts = normFactors(background, se.out = counts)
y = asDGEList(counts)
colnames(y$counts) = colnames(counts)
rownames(y$samples) = colnames(counts)
y$samples$group = groups
design = model.matrix(~0 + groups, data=y$samples)
colnames(design) = levels(groups)
y = estimateDisp(y, design)
fit = glmQLFit(y, design, robust=TRUE)
results <- glmQLFTest(fit, contrast=makeContrasts(contrast, levels=design))
# combine GRanges rowdata with DA statistics
rowData(counts) = cbind(rowData(counts), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
#merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
#merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)


# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src

****** Pathway analysis
- GSEA
  #+begin_src R
library(msigdbr)
library(fgsea)

## Generate all msigdb mouse hallmark gene sets as list of lists
msigdbr_df <- msigdbr(species = "mouse", category = "H")
ms_path_list = split(x = msigdbr_df$ensembl_gene, f = msigdbr_df$gs_name)

test = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/dca_ir84_sham_annot.RDS")

str(annotation)


sign = sign(annotation$logFC)
logP = -log10(annotation$PValue)
rank = logP/sign

names(rank) = annotation$ENSEMBL

gsea = as_tibble(fgseaMultilevel(ms_path_list, rank, maxSize = 500))

min(gsea$padj, na.rm = T)

gsea %>% arrange(pval)

gsea = gsea[,1:7]

gsea = as.data.frame(gsea)

gsea
write.csv(file = "/tmp/test.csv", gsea)

#########1#########2#########3#########4#########5#########6#########7#########8

# Promoter only

promoters = annotation %>%
  filter(grepl("Promoter", annotation))

nrow(promoters)

sign = sign(promoters$logFC)
logP = -log10(promoters$PValue)
rank = logP/sign

names(rank) = promoters$ENSEMBL

gsea = as_tibble(fgseaMultilevel(ms_path_list, rank, maxSize = 500))

min(gsea$padj, na.rm = T)

gsea %>% arrange(pval)


#########1#########2#########3#########4#########5#########6#########7#########8

str(annotation)

annotation$pos = as.character(annotation$annotation)

annotation %>% filter(FDR < 0.05, logFC > 1) %>% dplyr::select(pos)


test =annotation %>% filter(FDR < 0.05, logFC < -1, grepl("Promoter", annotation)) %>% pull(SYMBOL)

cat(test, file = "~/down.txt")
annotation %>% filter()

#########1#########2#########3#########4#########5#########6#########7#########8
library(biomaRt)


ensembl <- useEnsembl(biomart = "ensembl")

datasets <- listDatasets(ensembl)

searchDatasets(mart = ensembl, pattern = "mmusculus")

ensembl <- useDataset(dataset = "mmusculus_gene_ensembl", mart = ensembl)


grep("entrez", filters, ignore.case = T, value = T)

values = test$ENTREZID


values = values[!is.na(values)]

index = getBM(attributes = c('ensembl_gene_id','entrezgene_id'),
              filters = 'entrezgene_id',
              values = values,
              mart = ensembl, useCache = F)

nrow(index
index$entrezgene_id = as.character(index$entrezgene_id)

library(tidyverse)


test2 = test %>% left_join(index, by = c("ENTREZID" = "entrezgene_id"))
test2 = test2[!is.na(test2$ensembl_gene_id),]
test2 = test2[grepl("Promoter", test2$annotation), ]
#########1#########2#########3#########4#########5#########6#########7#########8

#enricher lists
test = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/dca_ir48_sham.RDS")

head(test)
res = as.data.frame(test)
ggplot(res, aes(x = logFC))+geom_density()

ls()

res %>% filter(rep.logFC > 2)
str(res)
#+end_src
#+begin_src R
annotation

annotation %>% filter(logFC > 2)
#+end_src

******* Transcription factors
******* Mouse Ventricle Radiation-induced Chromatin Remodeling at 48 Hours :sci_rep:
:PROPERTIES:
:export_latex_class: paper
:export_latex_header: \usepackage{./latex/tex/report}
:export_title: Mouse Ventricle Radiation-induced Chromatin Remodeling at 48 Hours
:export_options: tags:nil todo:nil toc:2 \n:t ^:nil
:export_file_name: ./results/reports/szymanski_ms_atac_48_report.pdf
:ID:       70d78969-3820-4def-b6f3-ab3c7c3e5d87
:END:
******** LaTeX settings                                            :noexport:
[[file:results/reports/szymanski_ms_atac_48_report.tex]]
[[file:~/repos/latex/tex/report.sty]]
\usepackage[T1]{fontenc}
\usepackage{tgbonum}
******** LaTeX Preamble                                              :ignore:
\setcounter{secnumdepth}{0}
\vspace{5mm}
\hfill Last compiled {{{time(%Y-%m-%d)}}}.
\newpage
******** Discussion
Expect immune infiltrate at > 1 week supercite:colman2015
******** References                                                  :ignore:
\printbibliography
******** External files
******* ATAC-seq peak calling and chromatin accessibility run 1 for PCAs
Error in env[[as.character(i)]] <- value :
  wrong args for environment subassignment
Calls: regionCounts ... bploop -> bploop.iterate -> <Anonymous> -> add_inorder
Execution halted


install.packages("tidyverse")
library(tidyverse)

- base rscript
  #+begin_src R :noweb yes :tangle ./scripts/csaw_peak.R

#############################################################################
###              Script for csaw ATAC-seq local peak calling
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
threads = args[4]
background_rds = args[5]
counts_rds = args[6]

filt_libs = unlist(strsplit(filt_libs_str, " "))

library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)
names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))
bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

dimnames(wider) = c()
dimnames(counts) = c()

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

colnames(filtered_counts) = names(bam_list)

saveRDS(object = filtered_counts,
file = counts_rds)

colnames(background) = names(bam_list)

saveRDS(object = background,
file = background_rds)
#+end_src
- [X] run test
  #+begin_src bash
lib_str="lib001 lib002"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
        "_regfilt_tn5.bam$" \
        "${lib_str}" \
        8 \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_background_counts.rds \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_counts.rds
#+end_src
- [X] run for open
  #+begin_src bash
lib_str="lib001 lib002 lib003 lib004 lib005 lib006 lib007 lib008 lib009 lib010 lib011 lib012 lib013 lib015 lib016 lib017 lib018 lib019 lib020 lib021 lib022 lib023 lib024 lib025"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
        "_open_tn5.bam$" \
        "${lib_str}" \
        4 \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_open_background_counts.rds \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_open_counts.rds
#+end_src
- [-] run for full
  #+begin_src bash
lib_str="lib001 lib002 lib003 lib004 lib005 lib006 lib007 lib008 lib009 lib010 lib011 lib012 lib013 lib015 lib016 lib017 lib018 lib019 lib020 lib021 lib022 lib023 lib024 lib025"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
        "_regfilt_tn5.bam$" \
        "${lib_str}" \
        8 \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_regfilt_background_counts.rds \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_regfilt_counts.rds
#+end_src



******** Ideas and dev
********* Description                                                :ignore:
ATAC-seq peaks were counted by /de novo/ enriched local windows using csaw. Peak counts were normalized by the trimmed mean of M values method in EdgeR. Normalized peak counts were used to test differential chromatin accessibility in EdgeR.

Peaks were annotated from the UCSC mm10 ensGene table using ChIPseeker.

********* ATAC-seq peak calling and chromatin accessibility, 6wks
********** [[file:workflow/peak_calling.smk][Snakefile]]       :smk:noexport:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/peak_calling.smk
:END:
*********** Smk preamble
#+begin_src snakemake :noweb yes

#+end_src
*********** All rule
#+begin_src snakemake
rule all:
    input:
        config["data_dir"] + "/atac/bk_rse.rds",
        config["data_dir"] + "/atac/counts_rse.rds",
#+end_src

*********** TEST Make peak counts                                  :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-03-11 Fri 12:20]
:END:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    params:
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = {lib_str}

        expand(config["data_dir"] + "/atac/bam/{library_id}.bam", library_id=RUNSAMPLES),

        lib_str = config["IR48H_V_SHAM"],
        script = config["repo"] + "/workflow/scripts/make_peak_counts.R",
    output:
        background_counts = config["data_dir"] + "/atac/{c}background_counts_rse.rds"
        counts_rse = config["data_dir"] + "/atac/counts_rse.rds"
    log:
        config["data_dir"] + "/logs/make_peak_counts.log",
    shell:
        """
        lib_str="{params.lib_str}"
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        "${{lib_str}}" \
        {config.threads} \
        {output.background_counts} \
        {output.counts_rse} \
        >& {log}
        """
#+end_src
- [[file:./scripts/select_window_size.R][Base script]]


*********** TEST Make peak counts                                  :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-03-11 Fri 12:20]
:END:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    params:
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
        script = config["repo"] + "/workflow/scripts/make_peak_counts.R",
    output:
        background_counts = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rse = config["data_dir"] + "/atac/counts_rse.rds"
	window_size = config["data_dir"] + "/atac/window_size.rds",
    log:
        config["data_dir"] + "/logs/make_peak_counts.log",
    shell:
        """
        lib_str="{params.lib_str}"
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        "${{lib_str}}" \
        {config.threads} \
        {output.background_counts} \
        {output.counts_rse} \
        >& {log}
        """
#+end_src
- [[file:./scripts/select_window_size.R][Base script]]
  #+begin_src R :noweb yes


#############################################################################
###              Script for csaw ATAC-seq local peak calling
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
threads = args[4]
background_rds = args[5]
rse_rds = args[6]

filt_libs = unlist(strsplit(filt_libs_str, " "))

library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)
names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))
bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

saveRDS(object = filtered_counts,
file = counts_rds)

saveRDS(object = background,
file = background_rds)
#+end_src
*********** TEST Differential accessibility                        :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/differential_accessibility.R

#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to generate differential accessibility model with EdgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
load(data_model)
background = readRDS(background_rds)

counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design <- model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src
*********** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
*********** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
************ Make backgroud bins                                   :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_backgroud_bins:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/make_backgroud_bins.R"
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
    output:
    log:
        config["data_dir"] + "/logs/make_backgroud_bins.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./scripts/make_backgroud_bins.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/make_backgroud_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to make background bins for csaw TMM normalization   ###
###

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
window_file =  args[1]
bam_dir = args[2]
bam_pattern = args[3]
filt_libs_str = args[4]
rse = args[4]
bk = args[5]

filt_libs = unlist(strsplit(filt_libs_str, " "))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

#+end_src
************ d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src

************* edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./scripts/edger.R][Base script]]
#+begin_src R :noweb yes :tangle ./scripts/edger.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src

********** Description                                               :ignore:
ATAC-seq peaks were counted by /de novo/ enriched local windows using csaw. Peak counts were normalized by the trimmed mean of M values method in EdgeR. Normalized peak counts were used to test differential chromatin accessibility in EdgeR.

Peaks were annotated from the UCSC mm10 ensGene table using ChIPseeker.


******* All count logcpms for QC
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-03-31 Thu 14:24]
:END:

- [X] Functions and test
  #+begin_src R :tangle ./scripts/counts_to_logcpm.R
args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
logcpm_file = args[3]

background = readRDS(background_rds)
counts = readRDS(counts_rds)

library(csaw)
library(edgeR)
library(tidyverse)

counts = normFactors(background, se.out = counts)

make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm = make_logcpm(counts)

saveRDS(object = logcpm,
        file = logcpm_file)
#+end_src
  #+begin_src bash
Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/counts_to_logcpm.R \
	/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_counts.rds \
	/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_background_counts.rds \
	/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_logcpm.rds
#+end_src

- All sample PCA
  #+begin_src bash

#+end_src
- Filtered PCA
- Reference
  - PCA of mislabeled samples
    #+begin_src R
  load("/mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48_v_sham_tmp.rdata")

  load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

  participants$cohort_id[which(participants$part_id == "ms015")] = "ir48h"

  libraries_full$cohort_id[which(libraries_full$library_id == "lib009")] = "ir48h"

  libraries_full$cohort_id[which(libraries_full$library_id == "lib016")] = "sham"

  library(csaw)

  make_logcpm = function(in_norm){
    dge = asDGEList(in_norm)
    colnames(dge) = colnames(in_norm)
    log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
    return(log_cpm)
  }

  logcpm = make_logcpm(filtered_counts)

  pca = prcomp(t(logcpm))
  summary(pca)

  library(tidyverse)
  library(ggrepel)

  make_pca_plots = function(in_pca, full_libs){
    pve_pc1=round(100*summary(in_pca)$importance[2,1])
    pve_pc2=round(100*summary(in_pca)$importance[2,2])

    pca_plot = as.data.frame(in_pca$x) %>%
      rownames_to_column(var = "library_id") %>%
      left_join(full_libs, by = "library_id") %>%
      ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
      geom_point(size = 4) +
      geom_text_repel() +
      xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
      ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
      guides(color="none")
    return(pca_plot)
  }



  test =make_pca_plots(pca, libraries_full)


  in_pca = pca
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(libraries_full, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel(force = 10) +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")


  ggsave(pca_plot, filename = "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/pca2.pdf")

  ggsave(pca_plot, filename = "~/repos/cardradbio-atac/results/imgs/ir48h_v_sham_full_pca.pdf")
  #+end_src

******* Read processing and alignment
******** Description                                                 :ignore:
Sequencing read adapters were removed and reads were quality trimmed using flexbar.

Processed reads were aligned to mm10 using bowtie2.

PCR duplicate reads were removed using samtools. Reads were then filtered and processed for ATAC-seq analysis as follows. Only paired reads aligning to mm10 autosomes were retained. Read pairs were also removed if they overlapped known problematic regions from the ENCODE blacklist_bed supercite:amemiya2019. Finally, alignments were shifted on the forward strand by +4 bp and on the reverse strand by 5 bp to account for the 9-bp duplication introduced by Tn5.


******** DONE [[file:workflow/preprocess_align.smk][Snakefile]]         :smk:
CLOSED: [2022-03-11 Fri 12:19]
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/preprocess_align.smk
:CUSTOM_ID: readp
:END:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-03-11 Fri 12:19]
:END:
********* Smk preamble
#+begin_src snakemake
container: config["container"]
RUNSAMPLES =  ["lib001", "lib002", "lib003", "lib004", "lib005", "lib006", "lib007", "lib008", "lib009", "lib010", "lib011", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib024", "lib025"]
#+end_src
********* Smk rules
********** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["data_dir"] + "/atac/bam/{library_id}.bam", library_id=RUNSAMPLES),
        config["data_dir"] + "/ref/keep.bed",
        expand(config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/atac/bam/{library_id}_open.bam", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/atac/bam/{library_id}_regfilt_tn5.bam", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/atac/bam/{library_id}_open_tn5.bam", library_id=RUNSAMPLES),
#+end_src
********** Read trim                                               :smk_rule:
- Snakemake
  #+begin_src snakemake
rule read_trim:
    input:
        r1 = config["data_dir"] + "/atac/fastq/{library_id}_R1.fastq.gz",
        r2 = config["data_dir"] + "/atac/fastq/{library_id}_R2.fastq.gz",
    params:
        outdir = config["data_dir"] + "/atac/fastq",
        threads = config["threads"],
    output:
        config["data_dir"] + "/atac/fastq/{library_id}_flex_1.fastq.gz",
        config["data_dir"] + "/atac/fastq/{library_id}_flex_2.fastq.gz",
    resources:
        mem_mb=5000
    shell:
        """
        workflow/scripts/read_trim.sh {input.r1} {input.r2} {params.outdir} {params.threads}
        """
#+end_src
- Script [[file:workflow/scripts/read_trim.sh]]
  #+begin_src bash :noweb yes :tangle ./scripts/read_trim.sh
#########1#########2#########3#########4#########5#########6#########7#########8
#
# Function for flexbar processing
flexbar_atac() {
    base=$(basename -s _R1.fastq.gz $1)
    flexbar \
        --adapter-pair-overlap ON \
        --adapter-preset Nextera \
        --pre-trim-right 1 \
        --reads "${1}" \
        --reads2 "${2}" \
        --target "${3}/${base}_flex" \
        --threads ${4} \
        --zip-output GZ
}

# Snakemake parameters
input_r1="$1"
input_r2="$2"
params_outdir="$3"
params_threads="$4"

# Run
flexbar_atac "${input_r1}" "${input_r2}" "${params_outdir}" "${params_threads}"
#+end_src
********** Make bowtie index                                       :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_bowtie_index:
    input:
        fa = config["data_dir"] + "/ref/mm10.fa",
    params:
        prefix = config["data_dir"] + "/ref/ucsc_mm10_bt2/ucsc_mm10_bt2",
        threads = config["threads"]
    output:
        config["data_dir"] + "/ref/ucsc_mm10_bt2/ucsc_mm10_bt2.1.bt2",
    shell:
        """
        workflow/scripts/make_bowtie_index.sh {input.fa} {params.prefix} {params.threads}
        """
#+end_src
- [[file:./scripts/make_bowtie_index.sh][Base script]]
  #+begin_src bash :tangle ./scripts/make_bowtie_index.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function
make_bt2_index(){
    index_dir=$(dirname $3)
    mkdir -p $index_dir
    bowtie2-build -f \
                  --threads $1 \
                  $2 \
                  $3
}

# Snakemake variables
input_fa="$1"
params_prefix="$2"
params_threads="$3"

# Run
make_bt2_index $params_threads $input_fa $params_prefix
#+end_src
********** Align BT2                                               :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2021-12-23 Thu 12:41]
:END:
- Snakemake
  #+begin_src snakemake
rule align_bt2:
    input:
        r1 = config["data_dir"] + "/atac/fastq/{library_id}_flex_1.fastq.gz",
        r2 = config["data_dir"] + "/atac/fastq/{library_id}_flex_2.fastq.gz",
    params:
        prefix = config["data_dir"] + "/ref/ucsc_mm10_bt2/ucsc_mm10_bt2",
        threads = config["threads"],
    output:
        bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
    shell:
        """
        workflow/scripts/align_bt2.sh {input.r1} {input.r2} {params.prefix} {params.threads} {output.bam}
        """
#+end_src
- [[file:./scripts/align_bt2.sh][Base script]]
  #+begin_src bash :tangle ./scripts/align_bt2.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function
bt2_align(){
    bowtie2 --maxins 2000 --threads $1 --very-sensitive -x $2 -1 $3 -2 $4 | samtools view -bS - > $5
}

# Snakemake variables
input_r1="$1"
input_r2="$2"
params_prefix="$3"
params_threads="$4"
output_bam="$5"

# Run
bt2_align "$params_threads" "$params_prefix" "$input_r1" "$input_r2" "$output_bam"
#+end_src
**** move back
***** Filter and dedup                                             :smk_rule:
- Snakemake
  #+begin_src snakemake
rule filter_and_dedup:
    input:
        bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
    params:
        atac_keep_bed = config["data_dir"] + "/ref/keep.bed",
        threads = config["threads"],
    output:
        dedup_bam = config["data_dir"] + "/atac/bam/{library_id}_dedup.bam",
        qfilt_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_qfilt.bam"),
        regfilt_bam = config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam",
        regfilt_index = config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam.bai",
    resources:
        mem_mb=5000
    shell:
        """
        workflow/scripts/filter_and_dedup.sh {input.bam} \
	                                     {params.atac_keep_bed} \
	                                     {params.threads} \
	                                     {output.dedup_bam} \
	                                     {output.qfilt_bam} \
	                                     {output.regfilt_bam}
        """
#+end_src
- [[file:./scripts/filter_and_dedup.sh][Base script]]
  #+begin_src bash :tangle ./scripts/filter_and_dedup.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function

atac_bam_processing(){
    #
    # Dedup
    samtools sort -@ $1 -n -o - $2 |
    samtools fixmate -m - - |
    samtools sort -@ $1 -o - - |
    samtools markdup -@ $1 -r - $3
    #
    # Filter to aligned, properly paired reads
    samtools view -@ $1 -b -f 3 -h -o $4 $3
    #
    # Filter to autosomes and remove blacklist_beded regions
    samtools view -@ $1 -b -h -L $5 -o - $4 |
    samtools sort -@ $1 -n -o - - |
    samtools fixmate -m - - |
    samtools sort -@ $1 -o $6 -
    samtools index $6
}

# Snakemake variables
input_bam="$1"
params_atac_keep_bed="$2"
params_threads="$3"
output_dedup_bam="$4"
output_qfilt_bam="$5"
output_regfilt_bam="$6"

# Run command
atac_bam_processing "$params_threads" \
                    "$input_bam" \
                    "$output_dedup_bam" \
                    "$output_qfilt_bam" \
                    "$params_atac_keep_bed" \
                    "$output_regfilt_bam"
samtools index "$output_regfilt_bam"
#+end_src

***** Tn5 shift                                                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "DELEGATED"  [2022-02-11 Fri 16:40]
- State "DONE"       from "CLOSEOUT"   [2022-02-11 Fri 16:40]
- State "DONE"       from "RUN"        [2022-02-11 Fri 16:40]
- State "WAITING"    from "TODO"       [2022-01-06 Thu 09:09] \\
  add to next run
:END:
- Snakemake
  #+begin_src snakemake
rule tn5_shift_and_open:
    input:
        atac_bam =         config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam",
    output:
        tmp_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_regfilt_tmp.bam"),
        tn5_bam =      config["data_dir"] + "/atac/bam/{library_id}_regfilt_tn5.bam",
    log:
        config["data_dir"] + "/logs/tn5_shift_and_open_{library_id}_regfilt.log",
    shell:
        """
        workflow/scripts/tn5_shift.sh {input.atac_bam} \
	                              {config[threads]} \
	                              {output.tmp_bam} \
                                      {output.tn5_bam} > {log} 2>&1
        """
#+end_src
- [[file:./scripts/todo_tn5_shift.sh][Base script]]
  #+begin_src bash :tangle ./scripts/tn5_shift.sh
alignmentSieve --ATACshift --bam "$1" --numberOfProcessors $2 --outFile "$3"

samtools sort -@ $2 -o $4 $3

samtools index -@ $2 $4
#+end_src
***** Tn5 open shift                                               :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-01-06 Thu 09:09] \\
  add to next run
:END:
- Snakemake
  #+begin_src snakemake
rule tn5_shift_open:
    input:
        atac_bam =         config["data_dir"] + "/atac/bam/{library_id}_open.bam",
    output:
        tmp_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_open_tmp.bam"),
        tn5_bam =      config["data_dir"] + "/atac/bam/{library_id}_open_tn5.bam",
    log:
        config["data_dir"] + "/logs/tn5_shift_and_open_{library_id}_open.log",
    shell:
        """
        workflow/scripts/tn5_shift.sh {input.atac_bam} \
	                              {config[threads]} \
	                              {output.tmp_bam} \
                                      {output.tn5_bam} > {log} 2>&1
        """
#+end_src
- [[file:./scripts/todo_tn5_shift.sh][Base script]]
  #+begin_src bash :tangle ./scripts/tn5_shift.sh
alignmentSieve --ATACshift --bam "$1" --numberOfProcessors $2 --outFile "$3"

samtools sort -@ $2 -o $4 $3

samtools index -@ $2 $4
#+end_src

***** Ideas
- redefine samtools tmp dir outside repo




***** Motif analysis
- Get gene list- Takes annotated edger results as table
  #+begin_src R
library(tidyverse)
test = as_tibble(read.csv("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_de.csv", header = T))

motifs_down_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC < 0) %>%
  pull(geneId)

motifs_up_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC > 0) %>%
  pull(geneId)

writeLines(as.character(motifs_down_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt")
writeLines(as.character(motifs_up_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_up.txt")

#+end_src

- Find motifs
  #+begin_src bash
mkdir -p /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/

nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/ -fdr 10 -p 12

# try



Number of CPUs to use ("-p <#>", default 1)
HOMER is now multicore compliant.  It's not perfectly parallelized, however, certain types of analysis can benefit.  In general, the longer the length of the motif, the better the speed-up you'll see.

Number of motifs to find ("-S <#>", default 25)
Specifies the number of motifs of each length to find.  25 is already quite a bit.  If anything, I'd recommend reducing this number, particularly for long motifs to reduce the total execution time.
perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src

- Extract gene names
  #+begin_src bash

#+end_src


****** Snakefile                                               :smk:noexport:
:PROPERTIES:
:header-args:snakemake:  :tangle ./workflow/motifs.smk
:END:
******* Smk preamble
#+begin_src snakemake :noweb yes

#+end_src
******* All rule
#+begin_src snakemake
rule all:
    input:
#+end_src
******* Extract gene list                                          :smk_rule:

extract ensembl ID lists from csaw-EdgeR DCA workflow

- Snakemake
  #+begin_src snakemake
rule extract_gene_list:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/extract_gene_list.R"
    output:
    log:
        config["data_dir"] + "/logs/extract_gene_list.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./scripts/extract_gene_list.R][Base script]]
  #+begin_src R :noweb yes :tangle ./scripts/extract_gene_list.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###    SCRIPT TITLE   ###
###

args = commandArgs(trailingOnly = TRUE)
dca_tbl = args[1]

#+end_src
******* Find motifs for gene list promoters
#+begin_src bash
#nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/ -fdr 10 -p 12

findMotifs.pl test/homer/open_48hr-sham_down_genelist.txt \
              mouse \
              test/homer/open_ir48h-sham_less -fdr10 -p 4

#+end_src
- Find motifs by gene list
  #+begin_src bash
# TODO install homer w/ mouse-p promoter set

source ~/repos/cardradbio-atac/config/${HOSTNMAE}.sh

# Fake gene list from peak annotation output, is ensembl IDs
#

# Install mouse homer promotor set
perl /home/jeszyman/homer/.//configureHomer.pl -install mouse-p

mkdir -p /tmp/out

findMotifs.pl /tmp/test.txt mouse /tmp/out

perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src
****** Description                                                   :ignore:
***** [[file:workflow/dca_and_annot.smk][Differential chromatin accessibility and annotation]] :smk:
:PROPERTIES:
:header-args:snakemake:
:END:
:LOGBOOK:
- State "WAITING"    from "TEST"       [2022-03-31 Thu 14:33]
:END:
# Latest deepTools on bioconda does not contain alignmentSieve
RUN conda install -c bioconda deeptools=3.4 --force

****** Differential chromatin accessibility
- Snakemake
  #+begin_src snakemake
rule diff_chrom_accessibility:
    input:
        dge = config["data_dir"] + "/csaw/dge_{bam_process}.rds",
        norm_counts_rse = config["data_dir"] + "/csaw/norm_counts_rse_{bam_process}.rds",
    params:
        groups_str = "ir48h ir48h sham sham",
        contrast = "ir48h-sham",
        script = config["atac_script_dir_dir"] + "/diff_chrom_accessibility.R",
    output:
        config["data_dir"] + "/dca/dca_granges_{bam_process}.rds"
    log:
        config["log_dir"] + "/diff_chrom_accessibility_{bam_process}.log",
    shell:
        """
        Rscript {params.script} \
        {input.dge} \
        "{params.groups_str}" \
        "{params.contrast}" \
        {input.norm_counts_rse} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:workflow/scripts/diff_chrom_accessibility.R][Base script]]
  #+begin_src R :noweb yes

#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
###   Script to generate differential accessibility model with EdgeR         ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8

# Setup

## Arguements for testing
dge_rds = "~/repos/atac-seq/test/csaw/dge_regfilt.rds"
groups_str = "ir48h ir48h sham sham"
contrast = "ir48h-sham"
norm_counts_rds = "~/repos/atac-seq/test/csaw/norm_counts_rse_regfilt.rds"
dca_granges_rds = "/tmp/test.rds"

args = commandArgs(trailingOnly = TRUE)
dge_rds = args[1]
groups_str =args [2]
contrast = args[3]
norm_counts_rds = args[4]
dca_granges_rds = args[5]

library(csaw)
library(edgeR)
library(tidyverse)

y = readRDS(dge_rds)
groups = as.factor(unlist(strsplit(groups_str, " ")))

design = model.matrix(~0 + groups, data=y$samples)
colnames(design) = levels(groups)
y = estimateDisp(y, design)
fit = glmQLFit(y, design, robust=TRUE)
results = glmQLFTest(fit, contrast=makeContrasts(contrast, levels=design))

# combine GRanges rowdata with DA statistics
counts = readRDS(norm_counts_rds)
rowData(counts) = cbind(rowData(counts), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best = getBestTest(merged.peaks$id, results$table)

# combine merged peaks window range with statistics
final.merged.peaks = merged.peaks$region
final.merged.peaks@elementMetadata = cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks = final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_granges_rds)

#+end_src

***** Update via biopipe mod
***** [[file:workflow/qc.smk][Quality control]]                         :smk:
:PROPERTIES:
:header-args:snakemake:
:END:
****** Smk preamble
#+begin_src snakemake
RUNSAMPLES =  ["lib001", "lib002", "lib003", "lib004", "lib005", "lib006", "lib007", "lib008", "lib009", "lib010", "lib011", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib024", "lib025"]
#+end_src
****** Smk rules
******* All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["data_dir"] + "/qc/{library_id}_stat.txt", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/qc/{library_id}_flagstat.txt", library_id=RUNSAMPLES),
#+end_src
- add rules with smk.rule
******* Samstats:smk_rule:
- Snakemake
  #+begin_src snakemake
rule samstats:
    input:
        bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
    output:
        stat = config["data_dir"] + "/qc/{library_id}_stat.txt",
        flagstat = config["data_dir"] + "/qc/{library_id}_flagstat.txt",
    log:
        config["data_dir"] + "/logs/{library_id}_samstats.log",
    shell:
        """
        "workflow/scripts/samstats.sh" {config[threads]} {input.bam} {output.stat} {output.flagstat} 2>&1 >> {log}
        """
#+end_src
- [[file:./scripts/samstats.sh][Base script]]
  #+begin_src bash
#########1#########2#########3#########4#########5#########6#########7#########8
samtools stats -@ $1 $2 > $3
samtools flagstat -@ $1 $2 > $4
#+end_src
******* FastQC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule fastqc:
    input:
    output:
    shell:
        """
        scripts/fastqc.sh
        """
#+end_src
- [[file:./scripts/fastqc.sh][Base script]]
  #+begin_src bash
# Snakemake variables
# Function
# Run command
for file in $data_dir}/atac/atac-fastq/*.fastq.gz;
do
    fastqc --outdir=$data_dir}/results/qc $file &>> "$data_dir}/log/fastqc_log.txt"
done


#+end_src
******* MultiQC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule multiqc:
    input:
    output:
    shell:
        """
        scripts/multiqc.sh
        """
#+end_src
- [[file:./scripts/multiqc.sh][Base script]]
  #+begin_src bash
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

# Snakemake variables
# Function
# Run command
#########1#########2#########3#########4#########5#########6#########7#########8
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

#+end_src
******* ATAC-seq QC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule atac-seq_qc:
    input:
    params:
        script = config["repo"] + "workflow/scripts/atac-seq_qc.R"
    output:
    log:
        config["data_dir"] + "/logs/atac-seq_qc.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./scripts/atac-seq_qc.R][Base script]]
  #+begin_src R :noweb yes
#########1#########2#########3#########4#########5#########6#########7#########8

###
###   / SCRIPT TITLE   ###
###

#+end_src

******** Transcription start sites occupancy
:PROPERTIES:
:CREATED:  [2021-09-15 Wed 10:09]
:ID:       eecd41c6-4f32-4d79-b7d5-40d666b8f85b
:END:
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#setwd("/home/jeszyman/repos/card-rad-bio")
#source("./src/setup.R")
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                                "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                                "TC", "UQ"),
                 "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                               "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                               "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                               "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                               "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                     param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

save(gal_lib051,
     gal_lib052,
     gal_lib053,
     gal_lib054,
     gal_lib055,
     gal_lib057,
     file = file.path(data_dir,"atac/gal.RData"))


#########1#########2#########3#########4#########5#########6#########7#########8
tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+begin_src R
#TODO LOAD gals
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
txs <- transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)

tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+caption: CAPTION label:fig-atac-nuc-position
[[file:results/imgs/atac_nuc_position.pdf][file:results/imgs/atac_nuc_position.pdf]]



- Post-atacseqqc
#+end_src

BiocManager::install("diffloop")

library(diffloop)
library(TxDb.Mmusculus.UCSC.mm10.knownGene)

seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = scanBam(bam_list[1])
class(test)


bamTop100 <- scanBam(BamFile(bam_list[1], yieldSize = 100))
bam_list[1]
bamTag(bamTop100)



gal = readBamFile(bam_list[1], tags = tags, which = which, asMates = T, bigFile=T)

gal
param = ScanBamParam(tag))

which
test = rmchr(which)
test
test = renameSeqlevels(which, c("chr1"="1"))
test


test=rmchr(which)
head(which)


gal
## Promotor / transcript score
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
pt = PTscore(gal, txs)

## Nucleosome free regions score
nfr = NFRscore(gal, txs)

## Transcription start site enrichment
tsse = TSSEscore(gal, txs)

# Ideas
## Adjust start sites
#+end_src
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
- lib complexity w/ preseq http://smithlabresearch.org/software/preseq/ https://github.com/smithlabcode/preseq


TSSEs
ir01 - 2.75


#+caption: CAPTION label:fig-atac-tss
[[file:results/imgs/atac_tss.pdf]]

******** Aggregate
:PROPERTIES:
:CREATED:  [2021-09-21 Tue 07:29]
:ID:       a9426a9b-16e8-4356-8d98-314b4c7f8ec5
:END:
******** notes
:PROPERTIES:
:ID:       06f9345e-a489-4b5e-9f68-82e22e468096
:END:
- run on server, run launch_atac to load docker with ATACseqQC package
- do not run R docker through docker_interactive function- unknown error
- cite:liu2021 https://www.sciencedirect.com/science/article/pii/S1672022921001479

******* RUN Library complexity:smk_rule:
- Snakemake
  #+begin_src snakemake
rule library_complexity:
input:
    bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
params:
    script = config["repo"] + "/workflow/scripts/library_complexity.R",
output:
    bam = config["data_dir"] + "/qc/{library_id}_libcomplex.rds",
log:
    config["data_dir"] + "/logs/{library_id}_library_complexity.log",
shell:
    """
    Rscript {params.script} \
    {input.bam} \
    {output.bam} \
    >& {log}
    """
#+end_src
- [[file:./scripts/library_complexity.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to assess ATAC-seq library complexity by fragment length   ###
###

args = commandArgs(trailingOnly = TRUE)
bam = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

libCompWrap = function(dup_bam){
  estimateLibComplexity(readsDupFreq(dup_bam))
}

complex = libCompWrap("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5469_MGI2048/lc-08.TCGTGATCAG-ACACTACGTA/lc-08.TCGTGATCAG-ACACTACGTA.genome_accepted_hits.bam")

saveRDS(object = complex,
        file = rds)

#+end_src
- Reference
  - https://github.com/smithlabcode/preseq
  - lib complexity w/ preseq http://smithlabresearch.org/software/preseq/
  - Old code
    #+begin_src R
  load(file.path(repo,"/results/rdata/library_complexity_raw.RData"))
  ls()
  head(library_complexity_raw)

  test = as.data.frame(library_complexity_raw)

  lib_complex_plot =
    as.data.frame(library_complexity_raw) %>%
    pivot_longer(cols = ends_with("values"), names_to = "library_id", values_to = "pred") %>%
    pivot_longer(cols = ends_with("reads"), names_to = "library_id2", values_to = "reads") %>%
    select(!(ends_with("relative.size"))) %>%
    mutate(library_id = substr(library_id, 1, 6)) %>%
    select(library_id, pred, reads) %>%
    filter(library_id != "lib056") %>%
    ggplot(., aes(x = reads, y = pred, group = library_id)) + geom_smooth(se = FALSE) +
     xlab("Total molecules") + ylab("Unique molecules")
  save_plot("./results/imgs/lib_complex.pdf", lib_complex_plot)

  #+end_src

    #+begin_src R

  load("./results/rdata/library_complexity_raw.RData")
  load("./data/data_model.RData")

  atac_multiqc_general_raw =
    as_tibble(
      read.table(
        file.path(repo,"results/qc/atac_qc_data/multiqc_general_stats.txt"),
        header = T,
        sep = '\t',
        fill = T))

  atac_multiqc_general_raw


  ## Modify atac multiqc df
  atac_multiqc_general_mod =
    atac_multiqc_general_raw %>%
    mutate(library_id = gsub("^.....", "", Sample)) %>%
    mutate(library_id = gsub("_.*$", "", library_id)) %>%
    mutate(total_reads = FastQC_mqc.generalstats.fastqc.total_sequences) %>%
    mutate(aligned_reads = Samtools_mqc.generalstats.samtools.mapped_passed) %>%
    mutate(processing = ifelse(grepl("_R1", Sample), "raw",
                        ifelse(grepl("ddp_flagstat", Sample), "processed",
                               ifelse(grepl("ddp_open_flagstat", Sample), "open", "other")))) %>%
    filter(processing != "other") %>%
    filter(!grepl("_R2", Sample)) %>%
    filter(!grepl("flex", Sample)) %>%
    filter(!is.na(total_reads) | !is.na(aligned_reads)) %>%
    mutate(read_prs = ifelse(!is.na(total_reads), total_reads, aligned_reads)) %>%
    select(library_id, processing, read_prs) %>%
    pivot_wider(names_from = processing, values_from = read_prs) %>%
    mutate(p_proc = processed/raw*100) %>%
    mutate(p_open = open/raw*100)
  atac_multiqc_general_mod

  library_complexity_mod = as_tibble(data.frame(lib051 = library_complexity_raw[[1]],
                                      lib052 = library_complexity_raw[[2]],
                                      lib053 = library_complexity_raw[[3]],
                                      lib054 = library_complexity_raw[[4]],
                                      lib055 = library_complexity_raw[[5]],
                                      lib056 = library_complexity_raw[[6]],
                                      lib057 = library_complexity_raw[[7]])) %>%
    mutate(rel_size = lib051.relative.size) %>%
    select(!ends_with("relative.size")) %>%
    pivot_longer(cols = starts_with("lib"), names_to = "label", values_to = "count") %>%
    mutate(library_id = substr(label, 1, 6)) %>%
    mutate(label = gsub("^.*\\.","",label)) %>%
    pivot_wider(names_from = label, values_from = count) %>%
    left_join(libraries, by = "library_id")
  library_complexity_mod

  library_complexity =
    library_complexity_mod %>%
    left_join(atac_multiqc_general_mod, by = "library_id") %>%
    filter(p_proc > 25)

  library_complexity_plot =
    library_complexity %>%
    ggplot(., aes(x = values, y = reads)) + geom_smooth()
  library_complexity_plot

  save_plot("./results/imgs/lib_complex.pdf", library_complexity_plot)

  #+end_src
******* RUN Make frag distribution mat:smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_frag_distribution_mat:
    input:
        bam_dir = config["data_dir"] + "/atac/bam",
    params:
        script = config["repo"] + "/workflow/scripts/make_frag_distribution_mat.R",
    output:
        frag_dist = config["data_dir"] + "/qc/frag_dist.rds",
    log:
        config["data_dir"] + "/logs/make_frag_distribution_mat.log"
    shell:
        """
        Rscript {params.script} \
	{input.bam} \
	{output.frag_dist}
        >& {log}
        """
#+end_src
- [[file:./scripts/make_frag_distribution_mat.R][Base script]]
  #+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make fragment size distribution matrix   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)

bam_files = list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = TRUE)

bam_file_names = gsub("_dedup.bam", "", bam_files = list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = FALSE))

frag_dist = fragSizeDist(bam_files, bam_file_names)

saveRDS(object = frag_dist,
        file  = rds)
#+end_src
- Old code
  #+begin_src R



class(test)


names(test)

class(test[[1]])

head(test[[1]])
data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

pdf("/tmp/test.pdf")
lib051_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib051_aut_blk_ddp.bam", bamFiles.labels = "lib051")
lib052_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib052_aut_blk_ddp.bam", bamFiles.labels = "lib052")
lib053_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib053_aut_blk_ddp.bam", bamFiles.labels = "lib053")
lib054_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib054_aut_blk_ddp.bam", bamFiles.labels = "lib054")
lib055_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib055_aut_blk_ddp.bam", bamFiles.labels = "lib055")
lib056_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib056_aut_blk_ddp.bam", bamFiles.labels = "lib056")
lib057_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib057_aut_blk_ddp.bam", bamFiles.labels = "lib057")
dev.off()

save(lib051_frag,lib052_frag,lib053_frag,lib054_frag,lib055_frag,lib056_frag,lib057_frag, file = "~/repos/card-rad-bio/results/qc/frag.RData")

#########1#########2#########3#########4#########5#########6#########7#########8
load("./results/qc/frag.RData")
getwd()
#+end_src
  #+begin_src R
load("/mnt/ris/jschwarz/cardiac-radiobiology/atac/fragsize.RData")

ls()

fragsize_ct01
#+end_src
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#
load(file.path(data_dir,"/atac/fragsize.RData"))

# Rename old frag size files
fragsize_lib051 = fragsize_ct01
fragsize_lib052 = fragsize_ct02
fragsize_lib053 = fragsize_ir01
fragsize_lib054 = fragsize_ir02
fragsize_lib055 = fragsize_ir03
fragsize_lib056 = fragsize_ir04
fragsize_lib057 = fragsize_ct03

# create df
fragsize = data.frame(
  length = as.numeric(names(head(fragsize_lib051[[1]], n = 1000))),
  lib051 = as.vector(head(fragsize_lib051[[1]], n = 1000)),
  lib052 = as.vector(head(fragsize_lib052[[1]], n = 1000)),
  lib053 = as.vector(head(fragsize_lib053[[1]], n = 1000)),
  lib054 = as.vector(head(fragsize_lib054[[1]], n = 1000)),
  lib055 = as.vector(head(fragsize_lib055[[1]], n = 1000)),
  lib057 = as.vector(head(fragsize_lib057[[1]], n = 1000)))
fragsize = as_tibble(fragsize)

# save df
save(fragsize, file = file.path(repo,"/results/rdata/atac_fragsize.RData"))

# make plot
fragsize %>%
  pivot_longer(cols = !length, names_to = "library_id", values_to = "count") %>%
  ggplot(., aes(x = length, y = count, group = library_id)) + geom_line() + xlim()

+ geom_bar(stat = "identity")

#+end_src


******* Make nucleosome positioning alignments
:PROPERTIES:
:CREATED:  [2021-09-02 Thu 11:22]
:ID:       5acea857-b98c-473b-9b23-d430665cbb4d
:END:
:LOGBOOK:
- State "RUN"        from "DONE"       [2021-09-22 Wed 10:09]
- State "DONE"       from "CANCELED"   [2021-09-22 Wed 10:09]
CLOCK: [2021-09-15 Wed 09:35]--[2021-09-15 Wed 10:53] =>  1:18
:END:
#+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                              "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                              "TC", "UQ"),
               "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                             "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                             "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                             "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                             "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                   param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

save(gal_lib051,
   gal_lib052,
   gal_lib053,
   gal_lib054,
   gal_lib055,
   gal_lib057,
   file = file.path(data_dir,"atac/gal.RData"))

#+end_src
- Reference
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
****** Ideas
  - full log to catch this error
    - - https://www.biostars.org/p/396538/
    - note- log didn't work [[file:/mnt/ris/jschwarz/cardiac-radiobiology/log/fastqc_log.txt]]
    - #TODO how to add log file to find "$data_dir}/atac/atac-fastq" -name "*.fastq.gz" | parallel fastqc --outdir="$data_dir}/qc" }
  - preamble
    #+begin_src bash :noweb yes
  #!/bin/bash
  #########1#########2#########3#########4#########5#########6#########7#########8
  #
  ### Quality control for ATAC-seq data ###
  #


  #+end_src
***** [[file:workflow/nuc_rna.smk][Nuclear bulk RNA-seq]]               :smk:
:PROPERTIES:
:header-args:snakemake:
:END:
****** Smk preamble
#+begin_src snakemake

#+end_src
****** Smk rules
******* All rule
#+begin_src snakemake
rule all:
    input:
        config["data_dir"] + "/ms_nuc_rna/nuc_deseq.rdata",
        config["data_dir"] + "/ms_nuc_rna/nuc_full_deseq.rdata",
        nuc_res = config["data_dir"] + "/ms_nuc_rna/nuc_res.csv",
#+end_src

******* Make txdb                                                  :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_txdb:
    output:
        txdb = config["data_dir"] + "/ref/ucsc_mm10_txdb.rds"
    script:
        "scripts/make_txdb.R"
#+end_src
- [[file:./scripts/make_txdb.R][Base script]]
  #+begin_src R :noweb yes
#########1#########2#########3#########4#########5#########6#########7#########8

library(TxDb.Mmusculus.UCSC.mm10.ensGene)

# Create gene-transcript index as tx2gene object from a txdb
make_index = function(txdb){
  k <- keys(txdb, keytype = "TXNAME")
  tx2gene <- AnnotationDbi::select(txdb, k, "GENEID", "TXNAME")
}

tx2gene = make_index(TxDb.Mmusculus.UCSC.mm10.ensGene)

saveRDS(tx2gene, file = snakemake@output[["txdb"]])
#+end_src
******* Make counts                                                :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_counts:
    input:
        txdb = config["data_dir"] + "/ref/ucsc_mm10_txdb.rds",
        salmon_5469 = config["data_dir"] + "/inputs/Rentschler_s5469_MGI2048",
        salmon_5708 = config["data_dir"] + "/inputs/Rentschler_s5708_MGI2548",
    output:
        nuc_gene_cnts = config["data_dir"] + "/ms_nuc_rna/nuc_gene_cnts.rds"
    script:
        "scripts/make_counts.R"
#+end_src
- [[file:./scripts/make_counts.R][Base script]]
  #+begin_src R :noweb yes
#########1#########2#########3#########4#########5#########6#########7#########8

source(snakemake@config[["r_libs"]])

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

salmon_paths_4630 = list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s4630_MGI0042",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = TRUE)

(salmon_paths_4630_alt_ids = gsub("\\..*$",
                                             "",
                                             list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s4630_MGI0042",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = FALSE)
                                         ))

salmon_paths_4730 = list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s4730_MGI0070",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = TRUE)

(salmon_paths_4730_alt_ids = gsub("\\..*$","", list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s4730_MGI0070",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = FALSE)))

salmon_paths_5469 = list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5469_MGI2048",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = TRUE)

salmon_paths_5469_alt_ids = gsub("-","_",gsub("^","sample.",substr(list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5469_MGI2048",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = FALSE), 1, 5)))

names(salmon_paths_5469) = as.character(data.frame(alt_lib_id = salmon_paths_5469_alt_ids) %>%
  left_join(libraries, by = "alt_lib_id") %>%
  pull(library_id))

salmon_paths_5708 = list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5708_MGI2548",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = TRUE)

salmon_paths_5708_alt_ids = paste0("sample.",substr(list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5708_MGI2548",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = FALSE), 1, 4))

salmon_paths = c(salmon_paths_4630,
                 salmon_paths_4730,
                 salmon_paths_5469,
                 salmon_paths_5708)

alt_ids_salmon_paths = c(salmon_paths_4630_alt_ids,
                         salmon_paths_4730_alt_ids,
                         salmon_paths_5469_alt_ids,
                         salmon_paths_5708_alt_ids)

names(salmon_paths) =
as.character(data.frame(alt_lib_id = alt_ids_salmon_paths) %>%
  left_join(libraries, by = "alt_lib_id") %>% pull(library_id))


txdb = readRDS(snakemake@input[["txdb"]])

txi_nuc = tximport(salmon_paths,
                   type = "salmon",
                   tx2gene = txdb)

saveRDS(txi_nuc, file = snakemake@output[["nuc_gene_cnts"]])
#+end_src

******* Make full nuc DESeq2 object:smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_full_nuc_deseq2_object:
    input:
        data_model = config["data_dir"] + "/data_model/data_model.RData",
        txi = config["data_dir"] + "/ms_nuc_rna/nuc_gene_cnts.rds",
    params:
        script = config["repo"] + "/workflow/scripts/make_full_nuc_deseq2_object.R"
    output:
        nuc_deseq = config["data_dir"] + "/ms_nuc_rna/nuc_full_deseq.rdata",
    log:
        config["data_dir"] + "/logs/make_full_nuc_deseq2_object.log"
    shell:
        """
        Rscript {params.script} \
	{input.data_model} \
	{input.txi} \
	{output.nuc_deseq} \
        >& {log}
        """
#+end_src
- [[file:./scripts/make_full_nuc_deseq2_object.R][Base script]]
  #+begin_src R :noweb yes
#########1#########2#########3#########4#########5#########6#########7#########8

###############################################################################
###    Script to make a custom DESeq2 object for QC-filtered nuclear bulk   ###
###    RNA-seq data  WITHOUT FILTERING                                      ###
###############################################################################

args = commandArgs(trailingOnly = TRUE)
data_model = args[1]
txi_counts = readRDS(args[2])
nuc_deseq = args[3]

load(data_model)
library(tidyverse)
library(DESeq2)
library(EnsDb.Mmusculus.v79)
edb = EnsDb.Mmusculus.v79

deseq_column_data =
  data.frame(library_id = colnames(txi_counts$counts)) %>%
  left_join(libraries_full, by = "library_id") %>%
  dplyr::select(run_id,flow_date,cohort_id, lib_typ) %>%
  mutate(flow_date = replace_na(as.character(flow_date), "noflow")) %>%
  mutate(sampletype = paste(run_id,flow_date,cohort_id,lib_typ, sep = "_"))

dds = DESeqDataSetFromTximport(txi = txi_counts,
                               colData = deseq_column_data,
                               design = ~ cohort_id + run_id)
dds$cohort_id = factor(dds$cohort_id, levels = c("sham", "ir24h", "ir2w", "ir6w"))

nuc = dds[ ,dds$lib_typ == "nuc_rna"]
nuc$lib_typ = droplevels(nuc$lib_typ)
nuc$cohort_id = droplevels(nuc$cohort_id)
design(nuc) = ~ cohort_id

full_nuc_vsd <- vst(nuc)
full_nuc_rld = rlog(nuc)

save(full_nuc_vsd,
     full_nuc_rld,
     file = nuc_deseq)

#+end_src
- [[file:/mnt/ris/jschwarz/cardiac-radiobiology/logs/make_full_nuc_deseq2_object.log][Log]]
******* Make nuc DESeq2 object                                     :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_nuc_deseq2_object:
    input:
        data_model = config["data_dir"] + "/data_model/data_model.RData",
        txi = config["data_dir"] + "/ms_nuc_rna/nuc_gene_cnts.rds",
    params:
        script = config["repo"] + "/workflow/scripts/make_nuc_deseq2_object.R"
    output:
        nuc_deseq = config["data_dir"] + "/ms_nuc_rna/nuc_deseq.rdata",
        nuc_res = config["data_dir"] + "/ms_nuc_rna/nuc_res.csv",
    log:
        config["data_dir"] + "/logs/make_nuc_deseq2_object.log"
    shell:
        """
        Rscript {params.script} \
	{input.data_model} \
	{input.txi} \
	{output.nuc_deseq} \
	{output.nuc_res}
        >& {log}
        """
#+end_src
- [[file:./scripts/make_nuc_deseq2_object.R][Base script]]
  #+begin_src R :noweb yes
#########1#########2#########3#########4#########5#########6#########7#########8

###############################################################################
###    Script to make a custom DESeq2 object for QC-filtered nuclear bulk   ###
###    RNA-seq data                                                         ###
###############################################################################

args = commandArgs(trailingOnly = TRUE)
data_model = args[1]
txi_counts = readRDS(args[2])
nuc_deseq = args[3]
nuc_res_csv = args[4]

load(data_model)
library(tidyverse)
library(DESeq2)
library(EnsDb.Mmusculus.v79)
edb = EnsDb.Mmusculus.v79

deseq_column_data =
  data.frame(library_id = colnames(txi_counts$counts)) %>%
  left_join(libraries_full, by = "library_id") %>%
  dplyr::select(run_id,flow_date,cohort_id, lib_typ) %>%
  mutate(flow_date = replace_na(as.character(flow_date), "noflow")) %>%
  mutate(sampletype = paste(run_id,flow_date,cohort_id,lib_typ, sep = "_"))

dds = DESeqDataSetFromTximport(txi = txi_counts,
                               colData = deseq_column_data,
                               design = ~ cohort_id + run_id)
dds$cohort_id = factor(dds$cohort_id, levels = c("sham", "ir24h", "ir2w", "ir6w"))

nuc = dds[ ,dds$lib_typ == "nuc_rna"]
nuc = nuc[ ,!(colnames(nuc) %in% c("lib033",
                                   "lib031",
                                   "lib030",
                                   "lib027",
                                   "lib045",
                                   "lib042"))]
nuc$lib_typ = droplevels(nuc$lib_typ)
nuc$cohort_id = droplevels(nuc$cohort_id)
design(nuc) = ~ cohort_id

nuc_vsd <- vst(nuc)
nuc_dds = DESeq(nuc)
nuc_res = results(nuc_dds, name = "cohort_id_ir6w_vs_sham")

res_genes = mapIds(edb, keys=rownames(nuc_res), column="GENENAME", keytype="GENEID", multiVals = 'first')

name_index = data.frame(name = res_genes,
                        ensembl_id = names(res_genes))

nuc_res_anno = as_tibble(as.data.frame(nuc_res)) %>%
  mutate(ensembl_id = row.names(nuc_res)) %>%
  left_join(name_index, by = "ensembl_id") %>%
  arrange(padj)

save(nuc_vsd,
     nuc_dds,
     nuc_res,
     nuc_res_anno,
     file = nuc_deseq)

write.csv(nuc_res_anno, file = nuc_res_csv, row.names = F)
#+end_src
- [[file:/mnt/ris/jschwarz/cardiac-radiobiology/logs/make_nuc_deseq2_object.log][Log]]
****** Reference
- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4700052/
- https://mail.google.com/mail/u/0/#inbox/FMfcgzGmtXGvSlSLSqqngftGtkgJvksw
- Nuclear RNA-seq expectations and limitations
  - supercite:mitchell2012
  - Whole cell / nuc rna correlation will be poor
  - Nuc rna requires different alignment to account for introns
  - More stability in the long nincodings
- nuclear RNA-seq from cardiac tissue cite:gilsbach2018
  - Nuc rna harbors unique possibly useful info?
****** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:ID:       f581d62d-0501-494e-9c00-f768a6bb1e5c
:END:
******* Nuclear RNA GSEA
#+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8

#Install packages
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("fgsea")
BiocManager::install("msigdbr")

# Load packages
library(msigdbr)
library(fgsea)
library(tidyverse)

# Get msigdb lists of interest
##
## Generate all msigdb mouse hallmark gene sets as list of lists
msigdbr_df <- msigdbr(species = "mouse", category = "H")
ms_path_list = split(x = msigdbr_df$ensembl_gene, f = msigdbr_df$gs_name)

# Get deseq2 results as numeric vectors
load("~/repos/card-rad-bio/data/mouse-hrt-deseq.RData")

stat6wk = res_rna_6wk_ctrl$stat
names(stat6wk)=res_rna_6wk_ctrl$rna
stat2wk = res_rna_2wk_ctrl$stat
names(stat2wk)=res_rna_2wk_ctrl$rna

pv6wk = res_rna_6wk_ctrl$pvalue
names(pv6wk) = res_rna_6wk_ctrl$rna
pv2wk = res_rna_2wk_ctrl$pvalue
names(pv2wk) = res_rna_2wk_ctrl$rna

#
gsea_6wk = fgseaMultilevel(ms_path_list, stat6wk, maxSize = 500)
gsea_2wk = fgseaMultilevel(ms_path_list, stat2wk, maxSize = 500)


#########1#########2#########3#########4#########5#########6#########7#########8
## Hallmark gene sets of interest
###
### Cell cycle group
cell_cycle_paths = c("HALLMARK_P53_PATHWAY",
                     "HALLMARK_E2F_TARGETS",
                     "HALLMARK_G2M_CHECKPOINT",
                     "HALLMARK_MITOTIC_SPINDLE")

### Lipogenic
lipogenic_paths = c("HALLMARK_PI3K_AKT_MTOR_SIGNALING",
                    "HALLMARK_CHOLESTEROL_HOMEOSTASIS")

### Wnt/Bcatenin
wnt_path = "HALLMARK_WNT_BETA_CATENIN_SIGNALING"

### Inflammatory
inflam_path = "HALLMARK_INFLAMMATORY_RESPONSE"

### ROS
ros_path = "HALLMARK_REACTIVE_OXYGEN_SPECIES_PATHWAY"

### Full list
(interest_paths = c(cell_cycle_paths, lipogenic_paths, wnt_path, inflam_path, ros_path))

## Subset gene sets
interest_path_genes = ms_path_list[which(names(ms_path_list) %in% interest_paths)]

# Make table of per-pathway results
gsea_path_tbl = function(pathname,stat){
  #
  annot = msigdbr_df[msigdbr_df$gs_name==pathname, ]
  ranks = sort(stat, decreasing = T)
  path = unlist(unname(ms_path_list[names(ms_path_list) == pathname]))
  gsea = calcGseaStat(ranks, na.omit(match(path, names(ranks))), returnLeadingEdge = T)
  #
  df = data.frame(ensmbl = path,
                  index = match(path, names(ranks)))
  df =
    df %>%
    filter(df$index %in% gsea$leadingEdge) %>%
    left_join(annot, by = c("ensmbl" = "ensembl_gene")) %>%
    left_join(res_rna_6wk_ctrl, by = c("ensmbl" = "rna")) %>%
    select(gene_symbol, log2FoldChange, padj)
  return(df)
}


gsea_leading_6wk = lapply(interest_paths, gsea_path_tbl, stat6wk)
names(gsea_leading_6wk) = interest_paths


gsea_leading_2wk = lapply(interest_paths, gsea_path_tbl, stat2wk)
names(gsea_leading_2wk) = interest_paths


#########1#########2#########3#########4#########5#########6#########7#########8

save(gsea_6wk,
     gsea_2wk,
     gsea_leading_6wk,
     gsea_leading_2wk,
     file = "/mnt/ris/jschwarz/cardiac-radiobiology/ms_hrt_gsea.RData")
#+end_src

******* Measure DE with EdgeR
:PROPERTIES:
:CREATED:  [2021-10-06 Wed 12:34]
:ID:       e51bfb9c-c923-4ba6-b92c-eab353ec4052
:END:
#+begin_src R
library(edgeR)

#########1#########2#########3#########4#########5#########6#########7#########8
source(paste0("./config/",as.character(Sys.info()["nodename"]),".R"))
load(file.path(data_dir,"mouse_hrt_rt_de/txi_mm10_ens.RData"))

cts = txi_mm10_ens$counts
# c5 outlier
cts = cts[,c(1:10,12)]

normMat = txi_mm10_ens$length
normMat = normMat[,c(1:10,12)]

# Obtaining per-observation scaling factors for length, adjusted to avoid
# changing the magnitude of the counts.
normMat <- normMat/exp(rowMeans(log(normMat)))
normCts <- cts/normMat

# Computing effective library sizes from scaled counts, to account for
# composition biases between samples.
eff.lib <- calcNormFactors(normCts) * colSums(normCts)

# Combining effective library sizes with the length factors, and calculating
# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)

fit <- glmFit(y, design)

lrt <- glmLRT(fit)

topTags(lrt)

summary(decideTests(lrt))

o <- order(lrt$table$PValue)
cpm(y)[o[1:10],]
#+end_src


#+begin_src R
sampleTable = data.frame(cohort_id = c(rep("ms_6wk", 6), rep("ms_sham", 6)))
rownames(sampleTable) = colnames(txi_mm10_ens$counts)

# Create the DESeq2 dataset from tximport-generated gene-level counts
dds = DESeqDataSetFromTximport(txi_mm10_ens, sampleTable, ~ cohort_id)
dds = DESeq(dds)

rld = rlog(dds)
mat = t(assay(rld))
pca = prcomp(mat)

# Get principle component 1 & 2 values
(pve_pc1=round(100*summary(pca)$importance[2,1]))
(pve_pc2=round(100*summary(pca)$importance[2,2]))

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "sample_id") %>%
  mutate(cohort_id = ifelse(grepl("a", sample_id), "ir", "sham")) %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4) +
  theme_cowplot() +
  xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
  ylab(paste("PC2, ", pve_pc2, "% variance explained", sep =""))
pca_plot


#+end_src

- Make tximport summarization from salmon files and UCSC ensemble genes
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
# Setup
##
## Config
if(file.exists(paste0("./config/",as.character(Sys.info()["nodename"]),".R")))
  source(paste0("./config/",as.character(Sys.info()["nodename"]),".R"))
} else
  stop("No config file found")
}

#########1#########2#########3#########4#########5#########6#########7#########8
source(paste0("./config/",as.character(Sys.info()["nodename"]),".R"))

# Create gene-transcript index as tx2gene object from a txdb
txdb = TxDb.Mmusculus.UCSC.mm10.ensGene
k <- keys(txdb, keytype = "TXNAME")
tx2gene <- AnnotationDbi::select(txdb, k, "GENEID", "TXNAME")

# Generate gene counts from salmon files
salmon_paths =
  list.files(
    file.path(data_dir,
              "/card-rad-bio/htcf.wustl.edu/files/NeA8Dxd2/Rentschler_s4730_MGI0070"),
    pattern = "\\.sf$",
    recursive = T,
    full.names = T)
salmon_paths = salmon_paths[!grepl("/a", salmon_paths)]
names(salmon_paths) = gsub("\\..*", "", gsub("^.*MGI0070/", "", salmon_paths))

txi_mm10_ens = tximport(salmon_paths, type = "salmon", tx2gene = tx2gene)
save(txi_mm10_ens, file = file.path(data_dir,"/mouse_hrt_rt_de/txi_mm10_ens.RData"))
#+end_src
- Make sample table
  - Test
    #+begin_src R
sampleTable = data.frame(cohort_id = c("ms_sham","ms_sham","ms_6wk","ms_6wk"),
                         )
rownames(sampleTable) = colnames(txi$counts)
#+end_src
  - Run
- edgeR for CPM and DE
- DESeq2 for DE
  #+begin_src R
dds=DESeqDataSetFromTximport(txi, sampleTable, ~cohort_id)
#+end_src

keep <- rowSums(counts(dds)) > 1
dds_counts <- dds[keep,]

##
#
# Summary
nrow(dds)
nrow(dds_counts)
nrow(dds_cibersort)
#
# Ideas for additional filtering:
## at least 3 samples with a count of 10 or higher
## keep <- rowSums(counts(dds) >= 10) >= 3
## dds <- dds[keep,]
## filter genes without cardiac muscle expression as highest of cell categories
## topcell=colnames(cibersort[,2:8])[apply(cibersort[,2:8], 1, which.max)
## cibersort$topcell=topcell
## head(cibersort)
## table(cibersort$topcell)
  #+end_src
******* Box and whisker phenotype confirmation
  - extract differential expression / accessibility
    - Scn5a ENSMUSG00000032511
    - gja1 ENSMUSG00000050953
  - plot
    #+begin_src R
load(file.path(data_dir,"mouse_cardmyo_nuc_rna/txi_mm10_ens.RData"))
(sampleTable = data.frame(cohort = factor(c(rep("ms_sham", 8), rep("ms_6wk", 8)))))
dds = DESeqDataSetFromTximport(txi_mm10_ens, sampleTable, ~cohort)

test=plotCounts(dds, gene = "ENSMUSG00000032511", intgroup="cohort", returnData=T)

test2 = test %>%
  rownames_to_column(var = "alt_id") %>%
  left_join(nuc_sort_day, by = "alt_id") %>%
  ggplot(.,aes(x = cohort, y = count, label = alt_id, shape = sort_day)) +
  geom_point()
save_plot("/tmp/test.pdf", test2)

test=plotCounts(dds, gene = "ENSMUSG00000050953", intgroup="cohort", returnData=T)

test2 = test %>%
  rownames_to_column(var = "alt_id") %>%
  left_join(nuc_sort_day, by = "alt_id") %>%
  ggplot(.,aes(x = cohort, y = count, label = alt_id, shape = sort_day)) +
  geom_point()
save_plot("/tmp/test.pdf", test2)

load(file.path(data_dir,"mouse_hrt_rt_de/txi_mm10_ens.RData"))
(sampleTable = data.frame(cohort = factor(c(rep("ms_6wk", 6), rep("ms_sham", 6)))))
dds = DESeqDataSetFromTximport(txi_mm10_ens, sampleTable, ~cohort)

test=plotCounts(dds, gene = "ENSMUSG00000032511", intgroup="cohort", returnData=T)
test

test2 = test %>%
  rownames_to_column(var = "alt_id") %>%
  ggplot(.,aes(x = cohort, y = count, label = alt_id)) +
  geom_point()
save_plot("/tmp/test.pdf", test2)


test=plotCounts(dds, gene = "ENSMUSG00000050953", intgroup="cohort", returnData=T)
test

test2 = test %>%
  rownames_to_column(var = "alt_id") %>%
  ggplot(.,aes(x = cohort, y = count, label = alt_id)) +
  geom_point()
save_plot("/tmp/test.pdf", test2)


#########1#########2#########3#########4#########5#########6#########7#########8
pdf("/tmp/test.pdf")
plotCounts(dds, gene = "ENSMUSG00000032511", intgroup="cohort")
dev.off()

load(file.path(data_dir,"atac/macs2_counts.RData"))
load(file.path(data_dir,"atac/anno.RData"))
nrow(assay(macs2_count_list_filt$counts_full_narrow_union))

names(anno_df)
head(anno_df$macs2_full_narrow_union_loess)

(coldata = data.frame(cohort = c("ms_sham","ms_sham","ms_6wk","ms_6wk","ms_6wk","ms_sham")))
row.names(coldata)=colnames(macs2_count_list_filt$counts_full_narrow_union)

dds = DESeqDataSetFromMatrix(countData = assay(macs2_count_list_filt$counts_full_narrow_union),
                             colData = coldata,
                             design = ~ cohort)

pdf("/tmp/test.pdf")
plotCounts(dds, gene = "ENSMUSG00000032511", intgroup="cohort")
dev.off()



class(assay(macs2_count_list_filt$counts_full_narrow_union))

head(macs2_count_list_filt$counts_full_narrow_union)
#+end_src







**** Make MACS2 consensus peaks:smk_rule:
- Snakemake
#+begin_src snakemake
rule make_macs2_consensus_peaks:
    input:
	expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_granges.rds")
    params:
        script = config["repo"] + "/workflow/scripts/make_macs2_consensus_peaks.R"
    output:
    log:
        config["data_dir"] + "/logs/make_macs2_consensus_peaks.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./scripts/make_macs2_consensus_peaks.R][Base script]]
#+begin_src R :noweb yes
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Makes consensus peak sets from GRanges MACS2 peaks   ###
###

peaks = list.files(path = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2",
                   pattern = "regfilt_narrow.*rds$",
                   full.names = TRUE)
names(peaks) = gsub(".rds","",list.files(path = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2",
                   pattern = "regfilt_narrow.*rds$",
                   full.names = FALSE))

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

sham_libs =
 libraries_full %>%
 filter(lib_typ == "atac") %>%
 filter(cohort_id == "sham") %>%
 pull(library_id)
sham_peaks_list = grep(paste(sham_libs, collapse = "|"), peaks, value = TRUE)

sham_peaks_list = lapply(sham_peaks_list, readRDS)

library(GenomicRanges)

library(GenomicAlignments)

gr1 = sham_peaks_list[[1]]
gr2 = sham_peaks_list[[2]]

test = subsetByOverlaps(gr1, gr2, ignore.strand = TRUE)

test


test = GRangesList(unlist(sham_peaks_list))

test2 = summarizeOverlaps(gr1, test, mode = )

head(assays(test2)$counts, n = 100)

sham_peaks = GenomicRanges::union(unlist(sham_peaks_list))

test = c(sham_peaks_list[[1]], sham_peaks_list[[2]])

test = sham_peaks_list[1][sham_peaks_list[1] %over% sham_peaks_list[2]]

sham_peaks_list[[1]] %over% sham_peaks_list[[2]] %over% sham_peaks_list[[3]]

union(sham_peaks_list[[1]]

sham_peaks_list
sham_peaks = GenomicRanges::union(unlist(sham_peaks_list))

test = unlist(sham_peaks_list)

class(test)


head(test
     )
head(unlist(sham_peaks_list))

test = union(sham_peaks_list[[1]],sham_peaks_list[[2]])

test = for (i in sham_peaks_list) {union(i)}



test = for (i in 1:length(sham_peaks_list)) {union (sham_peaks_list[[i]])}

union(i )
length(sham_peaks_list)

ir6w_libs =
  libraries_full %>%
  filter(lib_typ == "atac") %>%
  filter(cohort_id == "ir6w") %>%
  pull(library_id)
ir6w_peaks = grep(paste(ir6w_libs, collapse = "|"), peaks, value = TRUE)

ir48h_libs =
  libraries_full %>%
  filter(lib_typ == "atac") %>%
  filter(cohort_id == "ir48h") %>%
  pull(library_id)
ir48h_peaks = grep(paste(ir48h_libs, collapse = "|"), peaks, value = TRUE)

#+end_src

*** Fragment size distribution                                     :smk_rule:
- Snakemake
  #+begin_src snakemake
#
rule bampefragsize:
    container: atac_container,
    input:     expand(atac_bam_dir + "/{library}_filt.bam", library = ATAC_LIBS),
    log:       log_dir + "/bampefragsize.log",
    output:
        hist = qc_dir + "/deeptools_frag_lengths.png",
        raw = qc_dir + "/deeptools_frag_lengths.txt",
    params:
        blacklist_bed = blacklist_bed,
        script  = atac_script_dir + "/bamPEFragmentSize_wrapper.sh",
	threads = threads,
    shell:
        """
        {params.script} \
        "{input}" \
        {log} \
        {output.hist} \
        {output.raw} \
        {params.blacklist_bed} \
        {params.threads}
        """
#+end_src
- Script
  #+begin_src bash
#!/usr/bin/env bash
set -o errexit   # abort on nonzero exitstatus
set -o nounset   # abort on unbound variable
set -o pipefail  # don't hide errors within pipes

# Script variables

input="${1}"
log="${2}"
output_hist="${3}"
output_raw="${4}"
blacklist_bed="${5}"
threads="${6}"


bamPEFragmentSize --bamfiles $input \
                  --numberOfProcessors $threads \
                  --blacklist_bedFileName $blacklist_bed \
                  --histogram $output_hist \
                  --maxFragmentLength 1000 \
                  --outRawFragmentLengths $output_raw
#+end_src
*** Ideas
:PROPERTIES:
:header-args: :tangle no
:END:
- upgrade region enrichment with unibind and lola? https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-021-07760-6
**** confirm DCA by deseq2
#+begin_src R
libraries_full_tsv = "~/cards/data-model/libraries_full.tsv"

bamscale = read_tsv("~/cards/tmp/bamscale/raw_coverages.tsv")

mat = bamscale %>% select(!coordinate)
mat = as.matrix(mat)
rownames(mat) = bamscale$coordinate

bamscale_counts_rds = "/tmp/human_union_mat.rds"

library(DESeq2)
library(tidyverse)
bamscale_counts = assays(naive_union_counts)$counts


(design_data = data.frame(library = substr(colnames(bamscale_counts), 1, 6)))

design_data = design_data %>% left_join(libraries_full, by = "library")

dds = DESeqDataSetFromMatrix(countData = bamscale_counts,
                             colData = design_data,
                             design = ~ tx)

run1=design_data %>% filter(run== "Rentschler_s4730_MGI0070") %>% pull(library)

#dds <- dds[, dds$library != "lib188"]
dds <- dds[, (dds$library %in% run1)]

dds <- dds[, (dds$library %in% c("lib019","lib020","lib021","lib022","lib023","lib024","lib025"))]

vsd = vst(dds, blind = TRUE)
mat = assay(vsd)

# Calculate row sums
row_sums <- rowSums(mat)

# Find indices of top 10000 rows
top_indices <- order(row_sums, decreasing = TRUE)[1:20000]
# Subset matrix
subset_matrix <- mat[top_indices, ]
library(pheatmap)
# Create the color palette
my_palette <- colorRampPalette(c("blue", "white", "red"))(n = 100)

anno = design_data %>% filter(library %in% run1) %>% select(tx)

rownames(anno)=colnames(mat)
# Create the heatmap

test2 = as.ggplot(pheatmap(subset_matrix,
         scale = "row",
         clustering_method = "ward.D2",
         color = my_palette,
         annotation_col = anno,
         show_rownames = F))



pheatmap(subset_matrix, scale = "row", clustering_method = "ward.D2")

make_heat = function(mat,gene_filt,col_anno,colors){
  new_mat = mat[gene_filt,]
  new_mat = new_mat[,row.names(col_anno)]
  pal = colorRampPalette(c("blue","white","red"))
  bwr = pal(colors)
  pheatmap(new_mat,
           scale = "row",
           clustering_method = "ward.D2",
           cluster_col = F,
           color = myCol,
           breaks = myBreaks,
           annotation_col = col_anno,
           border_color = NA)
}


pca = prcomp(t(mat))
summary(pca)

bamscale_counts_tsv = "~/cards/analysis/atac/dca/human_union.raw_coverages.tsv"
libraries_full_tsv = "~/cards/data-model/libraries_full.tsv"

library(tidyverse)

bamscale_counts = read_tsv(bamscale_counts_tsv)
libraries_full = read_tsv(libraries_full_tsv)

libs = substr(colnames(bamscale_counts[-1]), 1, 6)
bed = bamscale_counts$coordinate
bamscale_counts = as.matrix(bamscale_counts[,-1])
colnames(bamscale_counts) = libs
rownames(bamscale_counts) = bed

library(DESeq2)


library(ggplotify)

test2 + test1
#+end_src
***** Differential chromatin accessibility
- DESeq2
  - Bamscale counts to matrix
    #+begin_src R
bamscale_counts = "~/cards/analysis/atac/dca/human_union.raw_coverages.tsv"
counts_mat = "/tmp/human_union_mat.rds"

library(tidyverse)

counts = read_tsv(bamscale_counts)
libs = substr(colnames(counts[-1]), 1, 6)
bed = counts$coordinate
counts = as.matrix(counts[,-1])
colnames(counts) = libs
rownames(counts) = bed

saveRDS(counts, file = counts_mat)
#+end_src
  - Subset
    #+begin_src R
design_data = data.frame(library = libs)
design_data = design_data %>% left_join(libraries_full) %>% filter(post_ir_d == 7)

counts = counts[, colnames(counts) %in% design_data$library]

dds = DESeqDataSetFromMatrix(countData = counts,
                             colData = design_data,
                             design = ~ gy)

dds = DESeq(dds)

res = results(dds)

head(res[order(res$padj),], 40)

#+end_src
  - LRT
    #+begin_src R
libraries_full$post_ir_d = factor(libraries_full$post_ir_d, levels = c(1,7,14))
libraries_full$gy = factor(libraries_full$gy, levels = c(0,25))

#########1#########2#########3#########4#########5#########6#########7#########8

counts_mat = "/tmp/human_union_mat.rds"
libraries_full_tsv = "~/cards/data-model/libraries_full.tsv"

library(DESeq2)
library(tidyverse)

counts = readRDS(counts_mat)
libraries_full = read_tsv(libraries_full_tsv)

design_data = data.frame(library = libs)
design_data = design_data %>% left_join(libraries_full)

dds = DESeqDataSetFromMatrix(countData = counts,
                             colData = design_data,
                             design = ~ gy + post_ir_d + post_ir_d:gy)

dds = DESeq(dds, test="LRT", reduced = ~ gy + post_ir_d)

dds = DESeq(dds, test="LRT", reduced = ~ gy + post_ir_d)

res = results(dds)

head(res[order(res$padj),], 40)



  head(res[order(res$padj),], 40)

  #########1#########2#########3#########4#########5#########6#########7#########8
  dds = DESeqDataSetFromMatrix(countData = counts,
                         colData = fordesign,
                         design = ~ ir + day)


  radtest = DESeq(dds, test="LRT", reduced = ~ ir)

  res = results(radtest)


  #########1#########2#########3#########4#########5#########6#########7#########8
  dds = DESeqDataSetFromMatrix(countData = counts,
                         colData = fordesign,
                         design = ~ ir + day)


  radtest = DESeq(dds, test="LRT", reduced = ~ day)

  res = results(radtest)

  head(res[order(res$padj),], 40)

  #########1#########2#########3#########4#########5#########6#########7#########8
  library(regioneR)
  library(ChIPpeakAnno)

  head(counts)

  peaks = data.frame(str = row.names(res))
  peaks$chr=gsub(":.*$","",peaks$str)
  peaks$start=gsub("-.*$","",gsub("^.*:","",peaks$str))
  peaks$end=gsub("^.*-","",gsub("^.*:","",peaks$str))


  peaks=peaks[,-1]
  peaks = peaks[as.numeric(peaks$end) > (1+as.numeric(peaks$start)),]

  peaks = peaks[complete.cases(peaks),]
  write.table(peaks, file  ="/tmp/peaks.bed", sep = "\t", col.names = F, row.names = F, quote=F)

  library(rtracklayer)
  peaks = rtracklayer::import("/tmp/peaks.bed", format="BED")


  library(TxDb.Hsapiens.UCSC.hg38.knownGene)
  TxDb.Hsapiens.UCSC.hg38.knownGene

  annoDataTxDb = ChIPpeakAnno::toGRanges(TxDb.Hsapiens.UCSC.hg38.knownGene)

  library(ChIPseeker)

  anno=annotatePeak(peaks, TxDb = TxDb.Hsapiens.UCSC.hg38.knownGene)

  anno=as_tibble(anno)

  mart = useDataset("hsapiens_gene_ensembl", useMart("ensembl"))

  annotation = getBM(
    filters = "entrezgene_id",
    attributes=c("ensembl_gene_id",
                 "entrezgene_id",
                 "description",
                 "external_gene_name",
                 "gene_biotype"),
    values = anno$geneId,
    mart = mart)

  annotation$entrezgene_id=as.character(annotation$entrezgene_id)

  anno = anno %>% left_join(annotation, by = c("geneId" = "entrezgene_id"))

  anno$start = anno$start-1
  anno$bed=as.character(anno$seqnames)

  anno$bed=paste0(anno$bed,":",anno$start,"-",anno$end)

  anno$bed

  res2 = as.data.frame(res)

  res2 = res2 %>% rownames_to_column(var = "bed") %>% as_tibble()

  res3 = res2 %>% inner_join(anno, by = "bed")

  anno[1,]
  res2 = res2 %>% left_join(anno, by = "bed")

  res2 %>% arrange(bed)

  head(anno$bed, n = 100)

  res2

  res2%>% filter(padj < 0.1) %>% write_tsv(.,"/tmp/test.tsv")

  head(res2)
  res %>% arrange(padj)

  names(annotation)
  make_annotation = function(entrez_gene_vect, species){
    # Define species mart
    martdataset = ifelse(species == "human", "hsapiens_gene_ensembl", "mmusculus_gene_ensembl")

    # Fetch organism appriopriate Ensembl data mart


    # Make the annotation dataframe
    annotation = getBM(
      filters = "ensembl_gene_id",
      attributes=c("ensembl_gene_id",
                   "entrezgene_id",
                   "description",
                   "external_gene_name",
                   "gene_biotype"),
      values = ensembl_gene_vect,
      mart = mart)

    annotation = as_tibble(annotation)

    return(annotation)
  }

  annotation = make_annotation(genevect, human)

  library(org.Hs.eg.db)


  anno = addGeneIDs(anno, orgAnn="org.Hs.eg.db",
                    feature_id_type="entrez_gene_id",
                    IDs2Add=c("symbol"))


  class(anno)

  anno= as_tibble(anno)
  anno

  # An annotation file
  BiocManager::install("org.Hs.eg.db")
  class(anno)
  names(anno)
  # works with any granges object, and can bin at 1, so can get TSS from this
  test=binOverFeature(anno, annotationData=annoDataTxDb,
                 radius=5000, nbins=5000, FUN=length, errFun=0,
                 ylab="count",
                 main="Distribution of aggregated peak numbers around TSS")
  test

  #########1#########2#########3#########4#########5#########6#########7#########8
  class(res)

  (col_idx=which(colnames(dds) == "lib188"))

  dds = dds[, -16]
  vsd <- vst(dds, blind = FALSE)

  dds=dds[,!colnames(dds) %in% "lib188"]
  mat=assay(vsd)


  pca = prcomp(t(mat))
  summary(pca)
  pca_in=pca
  library(tidyverse)
  library(ggrepel)


  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library") %>%
    left_join(full_libs, by = "library") %>%
    ggplot(., aes(x = PC1, y = PC2, color = post_ir_d_im, label = library, shape = gy_im)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep =""))
  pca_plot


    return(pca_plot)
  }

  make_pca_plots(pca, libraries)


  res = results(radtest)
  res

  genevect = rownames(res)

  make_annotation = function(ensembl_gene_vect, species){
    # Define species mart
    martdataset = ifelse(species == "human", "hsapiens_gene_ensembl", "mmusculus_gene_ensembl")

    # Fetch organism appriopriate Ensembl data mart
    mart = useDataset(martdataset, useMart("ensembl"))

    # Make the annotation dataframe
    annotation = getBM(
      filters = "ensembl_gene_id",
      attributes=c("ensembl_gene_id",
                   "entrezgene_id",
                   "description",
                   "external_gene_name",
                   "gene_biotype"),
      values = ensembl_gene_vect,
      mart = mart)

    annotation = as_tibble(annotation)

    return(annotation)
  }

  annotation = make_annotation(genevect, human)


  test=as.data.frame(res)

  results = test %>% rownames_to_column(var = "ensembl_gene_id") %>% left_join(annotation, by = "ensembl_gene_id") %>% as_tibble()

  results %>% arrange(padj) %>% filter(padj < 0.05) %>% dplyr::select(external_gene_name, description, log2FoldChange, padj) %>% write_tsv("/tmp/test.tsv")

  names(res)
  #+end_src
  - Flat wald
    #+begin_src R
  bamscale_counts = "~/cards/analysis/atac/dca/human_union.raw_coverages.tsv"

  library(DESeq2)
  library(tidyverse)

  counts = read_tsv(bamscale_counts)
  libs = substr(colnames(counts[-1]), 1, 6)
  bed = counts$coordinate
  counts = as.matrix(counts[,-1])
  colnames(counts) = libs
  rownames(counts) = bed

  # Using flat contrasts

  design_data = data.frame(library = libs)
  design_data = design_data %>% left_join(libraries_full)
  design_data$cond = paste0("gy", design_data$gy, "_d",design_data$post_ir_d)

  dds = DESeqDataSetFromMatrix(countData = counts,
                               colData = design_data,
                               design = ~ cond)

  dds$cond

  dds = DESeq(dds)

  res = results(dds, contrast = c("cond", "gy25_d7", "gy0_d7"))

  res = results(dds, contrast = c("cond", "gy0_d7", "gy25_d7"))

  head(res[order(res$padj),], 40)


  = DESeq(dds, test="LRT", reduced = ~ gy + post_ir_d)

  test = results(dds, contrast=list(c("gy_25_vs_0", "gy25.post_ir_d7")), test = "Wald")



  #########1#########2#########3#########4#########5#########6#########7#########8
  design_data = data.frame(library = libs)
  design_data = design_data %>% left_join(libraries_full)

  dds = DESeqDataSetFromMatrix(countData = counts,
                               colData = design_data,
                               design = ~ gy + post_ir_d + post_ir_d:gy)

  dds$post_ir_d = factor(dds$post_ir_d, levels = c(1, 7, 14))
  dds$gy = factor(dds$gy, levels = c(0,25))

  dds = DESeq(dds)

  res = DESeq(dds, test="LRT", reduced = ~ gy + post_ir_d)

  test = results(dds, contrast=list(c("gy_25_vs_0", "gy25.post_ir_d7")), test = "Wald")

  head(test[order(test$padj),], 40)

  test
  # Create a contrast matrix for comparing ir versus sham at day 7
  contrast_mat <- makeContrasts(ir_vs_sham_7day = treatmentir.time7 - treatmentsham.time7, levels = colnames(dds))

  contrast_mat = makeContrasts(test = gy25.post_ir_d7 - gy0.post_ir_d7)



  res = results(dds, contrast = c("")

  contrasts <- resultsNames(dds)
  contrasts



  res = results(radtest)




  # Fit the DESeq2 model and get the results for the contrast of interest
  dds <- DESeq(dds)
  results_7day <- results(dds, contrast = contrast_mat["ir_vs_sham_7day", ])


  head(counts)
  #counts <- counts[apply(counts, 1, function(x) all(x > 20)), ]
  counts<- counts[rowSums(counts) > 20*ncol(counts), ]
  nrow(counts)

  libs= data.frame(library = libs)
  fordesign = libs %>% left_join(libraries) %>% mutate(ir = gy_im) %>% mutate(day = post_ir_d_im) %>% dplyr::select(library,ir, day)


  design = model.matrix(~0 + ir + day + ir:day, data = fordesign)

  design

  dds = DESeqDataSetFromMatrix(countData = counts,
                         colData = fordesign,
                         design = ~ ir + day + ir:day)


  radtest = DESeq(dds, test="LRT", reduced = ~ ir + day)

  res = results(radtest)

  head(res[order(res$padj),], 40)

  #########1#########2#########3#########4#########5#########6#########7#########8
  dds = DESeqDataSetFromMatrix(countData = counts,
                         colData = fordesign,
                         design = ~ ir + day)


  radtest = DESeq(dds, test="LRT", reduced = ~ ir)

  res = results(radtest)

  head(res[order(res$padj),], 40)
  #########1#########2#########3#########4#########5#########6#########7#########8
  dds = DESeqDataSetFromMatrix(countData = counts,
                         colData = fordesign,
                         design = ~ ir + day)


  radtest = DESeq(dds, test="LRT", reduced = ~ day)

  res = results(radtest)

  head(res[order(res$padj),], 40)

  #########1#########2#########3#########4#########5#########6#########7#########8
  library(regioneR)
  library(ChIPpeakAnno)

  head(counts)

  peaks = data.frame(str = row.names(res))
  peaks$chr=gsub(":.*$","",peaks$str)
  peaks$start=gsub("-.*$","",gsub("^.*:","",peaks$str))
  peaks$end=gsub("^.*-","",gsub("^.*:","",peaks$str))


  peaks=peaks[,-1]
  peaks = peaks[as.numeric(peaks$end) > (1+as.numeric(peaks$start)),]

  peaks = peaks[complete.cases(peaks),]
  write.table(peaks, file  ="/tmp/peaks.bed", sep = "\t", col.names = F, row.names = F, quote=F)

  library(rtracklayer)
  peaks = rtracklayer::import("/tmp/peaks.bed", format="BED")


  library(TxDb.Hsapiens.UCSC.hg38.knownGene)
  TxDb.Hsapiens.UCSC.hg38.knownGene

  annoDataTxDb = ChIPpeakAnno::toGRanges(TxDb.Hsapiens.UCSC.hg38.knownGene)

  library(ChIPseeker)

  anno=annotatePeak(peaks, TxDb = TxDb.Hsapiens.UCSC.hg38.knownGene)

  anno=as_tibble(anno)

  mart = useDataset("hsapiens_gene_ensembl", useMart("ensembl"))

  annotation = getBM(
    filters = "entrezgene_id",
    attributes=c("ensembl_gene_id",
                 "entrezgene_id",
                 "description",
                 "external_gene_name",
                 "gene_biotype"),
    values = anno$geneId,
    mart = mart)

  annotation$entrezgene_id=as.character(annotation$entrezgene_id)

  anno = anno %>% left_join(annotation, by = c("geneId" = "entrezgene_id"))

  anno$start = anno$start-1
  anno$bed=as.character(anno$seqnames)

  anno$bed=paste0(anno$bed,":",anno$start,"-",anno$end)

  anno$bed

  res2 = as.data.frame(res)

  res2 = res2 %>% rownames_to_column(var = "bed") %>% as_tibble()

  res3 = res2 %>% inner_join(anno, by = "bed")

  anno[1,]
  res2 = res2 %>% left_join(anno, by = "bed")

  res2 %>% arrange(bed)

  head(anno$bed, n = 100)

  res2

  res2%>% filter(padj < 0.1) %>% write_tsv(.,"/tmp/test.tsv")

  head(res2)
  res %>% arrange(padj)

  names(annotation)
  make_annotation = function(entrez_gene_vect, species){
    # Define species mart
    martdataset = ifelse(species == "human", "hsapiens_gene_ensembl", "mmusculus_gene_ensembl")

    # Fetch organism appriopriate Ensembl data mart


    # Make the annotation dataframe
    annotation = getBM(
      filters = "ensembl_gene_id",
      attributes=c("ensembl_gene_id",
                   "entrezgene_id",
                   "description",
                   "external_gene_name",
                   "gene_biotype"),
      values = ensembl_gene_vect,
      mart = mart)

    annotation = as_tibble(annotation)

    return(annotation)
  }

  annotation = make_annotation(genevect, human)

  library(org.Hs.eg.db)


  anno = addGeneIDs(anno, orgAnn="org.Hs.eg.db",
                    feature_id_type="entrez_gene_id",
                    IDs2Add=c("symbol"))


  class(anno)

  anno= as_tibble(anno)
  anno

  # An annotation file
  BiocManager::install("org.Hs.eg.db")
  class(anno)
  names(anno)
  # works with any granges object, and can bin at 1, so can get TSS from this
  test=binOverFeature(anno, annotationData=annoDataTxDb,
                 radius=5000, nbins=5000, FUN=length, errFun=0,
                 ylab="count",
                 main="Distribution of aggregated peak numbers around TSS")
  test

  #########1#########2#########3#########4#########5#########6#########7#########8
  class(res)

  (col_idx=which(colnames(dds) == "lib188"))

  dds = dds[, -16]
  vsd <- vst(dds, blind = FALSE)

  dds=dds[,!colnames(dds) %in% "lib188"]
  mat=assay(vsd)


  pca = prcomp(t(mat))
  summary(pca)
  pca_in=pca
  library(tidyverse)
  library(ggrepel)


  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library") %>%
    left_join(full_libs, by = "library") %>%
    ggplot(., aes(x = PC1, y = PC2, color = post_ir_d_im, label = library, shape = gy_im)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep =""))
  pca_plot


    return(pca_plot)
  }

  make_pca_plots(pca, libraries)


  res = results(radtest)
  res

  genevect = rownames(res)

  make_annotation = function(ensembl_gene_vect, species){
    # Define species mart
    martdataset = ifelse(species == "human", "hsapiens_gene_ensembl", "mmusculus_gene_ensembl")

    # Fetch organism appriopriate Ensembl data mart
    mart = useDataset(martdataset, useMart("ensembl"))

    # Make the annotation dataframe
    annotation = getBM(
      filters = "ensembl_gene_id",
      attributes=c("ensembl_gene_id",
                   "entrezgene_id",
                   "description",
                   "external_gene_name",
                   "gene_biotype"),
      values = ensembl_gene_vect,
      mart = mart)

    annotation = as_tibble(annotation)

    return(annotation)
  }

  annotation = make_annotation(genevect, human)


  test=as.data.frame(res)

  results = test %>% rownames_to_column(var = "ensembl_gene_id") %>% left_join(annotation, by = "ensembl_gene_id") %>% as_tibble()

  results %>% arrange(padj) %>% filter(padj < 0.05) %>% dplyr::select(external_gene_name, description, log2FoldChange, padj) %>% write_tsv("/tmp/test.tsv")

  names(res)
  #+end_src
- Rscript
  - https://www.nature.com/articles/s41598-020-66998-4
**** peak filtering visualizations
#+begin_src R
libraries_full_rds = "~/cards/data-model/libraries_full.rds"
macs2_dir = "~/cards/analysis/atac/human/peaks"

#!/usr/bin/env Rscript

################################
###   Macs2 Peak Filtering   ###
################################

# Load required packages
library(tidyverse)

libraries_full = readRDS(libraries_full_rds)

# Narrow peaks

(macs2_files = list.files(macs2_dir,
                          pattern = "lib.*ds9_multi_peaks.narrowPeak$",
                          full.names = TRUE))

(names(macs2_files) = substr(list.files(macs2_dir, pattern = "lib.*ds9_multi_peaks.narrowPeak$"), 1, 6))

ingest_macs2 = function(peak){
  macs2peak = read_tsv(peak,
                        col_names = c("chr","start","end","peak","score","strand","signal","neg_l10_pval","neg_l10_qval"))
}

macs2_list = lapply(macs2_files, ingest_macs2)
macs2 = bind_rows(macs2_list, .id = "library")
macs2 = macs2 %>% left_join(libraries_full, by = "library")

bins = c(0,0.1,0.5,1,5,10,100,Inf)
qval =
  macs2 %>%
  mutate(binned = cut(neg_l10_qval, bins, include.lowest = T, labels = c("0-0.1", "0.1-0.5", "0.5-1", "1-5","5-10", "10-100", ">100"))) %>%
  group_by(library, binned) %>%
  summarize(count = n()) %>% arrange(library, binned) %>%
  mutate(binned = factor(binned, levels = c(c(">100","10-100","5-10","1-5", "0.5-1","0.1-0.5","0-0.1")))) %>%
  left_join(libraries_full, by = "library") %>%
  left_join(qc, by = "library")

ggplot(qval, aes(x = library, y = count, fill = binned)) +
  geom_bar(stat = "identity", position = "stack") +
  coord_flip() + facet_wrap(~post_ir_d*gy, scales = "free_y")

macs2 %>%
  left_join(qc, by = "library") %>%
  mutate(cohort = paste0(post_ir_d,"_",gy)) %>%
  ggplot(., aes(x = library, y= neg_l10_qval, group = library)) + geom_boxplot() + geom_hline(yintercept = 5, linetype = "dotted") +
  scale_y_continuous(trans = "log10", breaks = c(0.1, 1, 10, 100)) +
  coord_flip() +
  facet_wrap(~post_ir_d*gy, scales = "free_y")

#########1#########2#########3#########4#########5#########6#########7#########8
macs2 %>%
  left_join(qc, by = "library") %>%
  mutate(cohort = paste0(post_ir_d,"_",gy)) %>%
  ggplot(., aes(x = reorder(library, neg_l10_qval), y= neg_l10_qval, group = library, fill = cohort)) + geom_boxplot() + geom_hline(yintercept = 8, linetype = "dotted") +
  scale_y_continuous(trans = "log10", breaks = c(0.1, 1, 10, 100)) +
  coord_flip()

library(ggrepel)

macs2 %>% group_by(library) %>%
  summarize(qval = median(neg_l10_qval)) %>%
  left_join(qc, by = "library") %>%
  left_join(libraries_full, by = "library") %>%
  mutate(cohort = paste0(post_ir_d,"_",gy)) %>%
  select(library, reads_mapped, qval, cohort) %>%
  mutate(label = ifelse(library %in% c("lib178", "lib182", "lib179", "lib181", "lib183"), library, NA)) %>%
  ggplot(., aes(x = reads_mapped, y= qval, color = cohort, label = label)) + geom_point(size = 4) + geom_label_repel()



qval %>% group_by(library) %>% summarize(count = sum(count)) %>%   left_join(qc, by = "library") %>% left_join(libraries_full, by = "library") %>%
ggplot(., aes(y = count, x = reads_mapped, color = post_ir_d, shape = gy)) + geom_point()

qc = read_tsv("~/cards/analysis/qc/atac_multiqc_data/multiqc_samtools_stats.txt") %>% select(Sample, reads_mapped) %>% filter(grepl("dedup", Sample)) %>%
  mutate(library = substr(Sample, 1,6))

macs2 %>% ggplot(., aes(x = neg_l10_qval)) + geom_density() + xlim(0,5)

macs2 %>% ggplot(., aes(x = score/10)) + geom_histogram()


library(scales)
#

ggplot(macs2, aes(x=neg_l10_qval)) +
  stat_density(aes(y=..count.., group = library), color="black", fill="blue", alpha=0.3) +
  scale_x_continuous(breaks=c(0,.1,.5, 5, 10,30,100), trans="log1p", expand=c(0,0)) +
  theme_bw()+ facet_wrap(~post_ir_d*gy)

ggplot(macs2, aes(x=neg_l10_qval)) +
  stat_density(aes(y=..count.., group = library), color="black", fill="blue", alpha=0.3) +
  scale_x_continuous(breaks=c(0,1,2,3,4,5,10,30,100,300,1000), trans="log1p", expand=c(0,0)) +
  theme_bw()+ facet_wrap(~post_ir_d*gy)


ls()

# so let's say -l10q needs to be greater than 5

macs2 = macs2 %>% filter(neg_l10_qval >5)

libs = split(macs2, f = macs2$library)

names(libs)


for (i in seq_along(libs)) {
  filename = paste0("/tmp/libs/", names(libs)[i], ".bed")
  write_tsv(libs[[i]][,-1],col_names = F, file = filename)
}


#########1#########2#########3#########4#########5#########6#########7#########8


(macs2_files = list.files(macs2_dir,
                          pattern = "lib.*ds9_peaks.*broadPeak",
                          full.names = TRUE))

(names(macs2_files) = substr(list.files(macs2_dir, pattern = "lib.*ds9_peaks.*broadPeak"), 1, 6))

ingest_macs2_broad = function(broadPeak){
  macs2broad = read_tsv(broadPeak,
                        col_names = c("chr","start","end","peak","score","strand","signal","neg_l10_pval","neg_l10_qval")) %>%
    mutate(pval = 10^(-neg_l10_pval)) %>%
    mutate(qval = 10^(-neg_l10_qval)) %>%
    mutate(width = end - start) %>%
    # corces2018 normalization of libraries
    mutate(corces = neg_l10_pval/sum(neg_l10_pval/1000000))
}

macs2_list = lapply(macs2_files, ingest_macs2_broad)
macs2 = bind_rows(macs2_list, .id = "library")
macs2 = macs2 %>% left_join(libraries_full, by = "library")

names(macs2)
nrow(macs2)
head(macs2)

# Check distribution of corces-normalized peak significance
ggplot(macs2, aes(x = corces)) + geom_density() + xlim(0,50)

ggplot(macs2, aes(x = neg_l10_pval, group = library, fill = post_ir_d)) + geom_density() + xlim(0,50)

ggplot(macs2, aes(x = neg_l10_qval)) +
  geom_histogram(bins = 10) +
  stat_bin(bins = 10, aes(label=..count..), vjust=-0.5, geom = "text")

ggplot(macs2, aes(x = neg_l10_qval)) +
  geom_histogram(bins = 10) +
  stat_bin(bins = 10, aes(label=..count..), vjust=-0.5, geom = "text") + facet_grid(~post_ir_d*gy)

ggplot(macs2, aes(x = neg_l10_qval)) +
  geom_histogram(center = .00000000000000000001, pad = T)

breaks = c(0, 0.0000001, 0.001, 0.01, 0.1, 1, 10, 10000))

ggplot(macs2, aes(x = neg_l10_qval)) + geom_histogram(breaks = c(0.001, 0.01, 0.1, 1, 10))

library(scales)
#

ggplot(macs2, aes(x=neg_l10_qval)) +
  stat_density(aes(y=..count..), color="black", fill="blue", alpha=0.3) +
  scale_x_continuous(breaks=c(0,1,2,3,4,5,10,30,100,300,1000), trans="log1p", expand=c(0,0)) +
  theme_bw()+ facet_wrap(~post_ir_d*gy)

ggplot(macs2, aes(x=neg_l10_qval)) +
  stat_density(aes(y=..count.., group = library), color="black", fill="blue", alpha=0.3) +
  scale_x_continuous(breaks=c(0,1,2,3,4,5,10,30,100,300,1000), trans="log1p", expand=c(0,0)) +
  theme_bw()+ facet_wrap(~post_ir_d*gy)


# so let's say -l10q needs to be greater than 5

macs2 = macs2 %>% filter(neg_l10_qval >5)

libs = split(macs2, f = macs2$library)

names(libs)


for (i in seq_along(libs)) {
  filename = paste0("/tmp/libs/", names(libs)[i], ".bed")
  write_tsv(libs[[i]][,-1],col_names = F, file = filename)
}
#+end_src
*** Insert size distributions                                      :smk_rule:
- Snakemake
  #+begin_src snakemake
checkpoint insert_size:
    container: atac_container,
    input: expand(atac_bam_dir + "/{library}_filt.bam", library = ATAC_LIBS),
    log: log_dir + "/insert_size.log",
    output:
        tsv = qc_dir + "/insert_sizes.tsv",
        plot = qc_dir + "/insert_sizes.pdf",
    params:
        peak_cut = atac_peak_cut,
        script = atac_script_dir + "/insert_size.R",
    shell:
        """
        Rscript {params.script} \
        "{input}" \
        {output.tsv} \
        {output.plot} \
        {params.peak_cut} > {log} 2>&1
        """
#+end_src
- Rscript
  #+begin_src R :tangle ./scripts/insert_size.R
args = commandArgs(trailingOnly = TRUE)
bam_list_str = args[1]
peak_ratio_tsv = args[2]
peak_ratio_plot = args[3]
peak_cut = args[4]

library(GenomicAlignments)
library(tidyverse)

bam_list = unlist(strsplit(bam_list_str, " "))
names(bam_list) = substr(gsub("^.*lib","lib", bam_list), 1, 6)

tally_lengths = function(in_bam){
  # Make a tibble with counts of fragment lengths
  gal = readGAlignments(in_bam,
                        param=ScanBamParam(what=c("isize")))
  tib = mcols(gal) %>%
    as_tibble() %>%
    mutate(frag_len = abs(isize)) %>%
    group_by(frag_len) %>%
    tally()
  return(tib)
}

change_column_name <- function(x, aList) {
  # For each per-library tibble, change column to library ID
  dat <- aList[[x]]
  names(dat)[2] <- x
  return(dat)
}

pre_frag_len_list = lapply(bam_list, tally_lengths)
frag_len_list = lapply(names(pre_frag_len_list), change_column_name, pre_frag_len_list)

frags =
  # Make a complete list of fragment sizes, 1-1000
  data.frame(frag_len = 1:1000) %>%
  as_tibble()
frags

frag_len_tib =
  frag_len_list %>% purrr::reduce(full_join, by = "frag_len") %>%
  full_join(frags, by = "frag_len") %>%
  arrange(frag_len) %>%
   replace(is.na(.), 0) %>%
   mutate(frag_len_fct = ifelse(frag_len > 1000, "other", frag_len)) %>%
  select(!frag_len) %>%
  pivot_longer(!frag_len_fct, names_to = "library", values_to = "count") %>%
  group_by(frag_len_fct, library) %>%
  summarize(count = sum(count)) %>%
  mutate(frag_len_fct = as.numeric(frag_len_fct)) %>%
  arrange(frag_len_fct)

cut = frag_len_tib %>%
  mutate(mono_cut = ifelse(frag_len_fct < 146, "open", "mono")) %>%
  group_by(library,mono_cut) %>%
  summarize(high = max(count)) %>%
  pivot_wider(names_from = mono_cut, values_from = high) %>%
  mutate(peak_ratio = open / mono) %>%
  select(library, open, mono, peak_ratio)

cut %>% write_tsv(file = peak_ratio_tsv)

plot = frag_len_tib %>%
  left_join(cut, by = "library") %>%
  mutate(peak_ratio_mod = ifelse(peak_ratio < peak_cut, NA, peak_ratio)) %>%
  ggplot(., aes(x=frag_len_fct, y = count)) +
  geom_line(aes(color = peak_ratio_mod)) +
  facet_wrap(vars(library)) +
  xlab("Fragment Length") + ylab("Count") +
  geom_hline(aes(yintercept = mono)) +
  scale_color_continuous(name = "Ratio of open to mononucleosomal peaks", na.value = "red") +
  theme(legend.position = "bottom")

ggsave(plot, file = peak_ratio_plot)


#+end_src

*** other macs and peaks
**** MACS2 single summit                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
#
checkpoint macs2_single_summit:
    container: atac_container,
    input: atac_bam_dir + "/{library}_filt.bam",
    log: log_dir + "/{library}_macs2_single_summit.log",
    output: atac_macs2_dir + "/{library}_single_peaks.narrowPeak",
    params:
        gsize = config["gsize"],
        outdir = atac_macs2_dir,
        script  = atac_script_dir + "/run_macs2_corces_onesummit.sh",
    shell:
        """
        base=$(basename -s _filt.bam {input})
        name=${{base}}_single
        {params.script} \
        {input} \
        $name \
        {params.gsize} \
        {params.outdir} &> {log}
        """
#+end_src
- Script
  #+begin_src bash :tangle ./scripts/run_macs2_corces_onesummit.sh
#!/usr/bin/env bash
set -o errexit   # abort on nonzero exitstatus
set -o nounset   # abort on unbound variable
set -o pipefail  # don't hide errors within pipes

# Script variables
inbam="${1}"
name="${2}"
gsize="${3}"
outdir="${4}"

main(){
    macs2_wrapper $inbam $name $gsize $outdir
}

macs2_wrapper(){
    local inbam="${1}"
    local name="${2}"
    local gsize="${3}"
    local outdir="${4}"
    #
    macs2 callpeak \
          --extsize 150 \
          --format BAMPE \
          --gsize $gsize \
          --keep-dup all \
          --name $name \
          --nolambda \
          --nomodel \
          --outdir $outdir \
          -p 0.01 \
          --shift -75 \
          --treatment $inbam
}

main "$@"
#+end_src
- per cite:corces2018
**** MACS2 consensus peaks                                         :smk_rule:
- snakemake
  #+begin_src snakemake
rule macs2_consensus:
    container: atac_container,
    input:
        libraries = sample_sheet,
    output: atac_macs2_dir + "/{group}_consensus.bed",
    params:
        log_dir = log_dir,
        atac_macs2_dir = atac_macs2_dir,
        script = atac_script_dir + "/macs2_consensus.R",
    shell:
        """
        Rscript {params.script} \
        {input.libraries} \
        {params.atac_macs2_dir} \
        > {params.log_dir}/macs2_consensus.log 2>&1
        """
#+end_src
- Rscript
  #+begin_src R :tangle ./scripts/macs2_consensus.R
# For unit testing
libraries_tsv = "test/inputs/libraries.tsv"
macs2_dir = "test/analysis/atac/macs2"

# Command line arguments
args = commandArgs(trailingOnly = TRUE)
libraries_tsv = args[1]
macs2_dir = args[2]

library(tidyverse)

libraries = read_tsv(libraries_tsv)
groups = unique(libraries$group)

#groups = unlist(strsplit(groups_str, " "))

make_consensus = function(library_tib, group_filt){
  path_vect =
    library_tib %>%
    filter(group == group_filt) %>%
    mutate(path = paste0(macs2_dir, "/", library, "_single_peaks.narrowPeak")) %>%
    pull(path)
  path_str = paste(path_vect, collapse=" ")
  system(
    paste0("bedops --intersect ", path_str, " > ",macs2_dir,"/",group_filt,"_consensus.bed")
    )
}

for (i in 1:length(groups)){
  make_consensus(libraries, groups[i])
}

#+end_src
**** MACS2 naive overlap                                           :smk_rule:
- snakemake
  #+begin_src snakemake
#
rule naive_overlap :
    container: atac_container,
    input:
        peaks = atac_macs2_dir + "/{library}_single_peaks.narrowPeak",
        sample_sheet = sample_sheet,
    log: log_dir + "/{library}_naive_overlap.log",
    output: atac_macs2_dir + "/{library}_naive.bed",
    params:
        atac_macs2_dir = atac_macs2_dir,
        script = atac_script_dir + "/naive_overlap.R",
    shell:
        """
        Rscript {params.script} \
        {input.peaks} \
        {input.sample_sheet} \
        {params.atac_macs2_dir} \
        {output} \
        > {log} 2>&1
        """
#+end_src
- Rscript
  #+begin_src R :tangle ./scripts/naive_overlap.R
args = commandArgs(trailingOnly = TRUE)
in_peaks_bed = args[1]
sample_sheet_tsv = args[2]
atac_macs2_dir = args[3]
out_peaks_bed = args[4]

library(tidyverse)

make_naive = function(sample_sheet,in_peaks_bed,atac_macs2_dir,out_peaks_bed){
  libraries = read_tsv(sample_sheet)
  library_filt = substr(gsub("^.*lib","lib",in_peaks_bed), 1, 6)
  group = libraries %>% filter(library == library_filt) %>% slice_head(n = 1L) %>% pull(group)
  consensus = paste0(atac_macs2_dir,"/",group,"_consensus.bed")
  system(paste("bedops --element-of 50%", in_peaks_bed, consensus, ">", out_peaks_bed))
}

make_naive(sample_sheet_tsv, in_peaks_bed, atac_macs2_dir, out_peaks_bed)
#+end_src
** README
[[file:resources/int_test.png]]
*** Prerequisites to run repository local integration testing
- Singularity container built from https://github.com/jeszyman/atac-seq/blob/master/config/atac_Dockerfile
- Local snakemake
- Local snakemake configuration YAML
*** Changelog
- [2022-09-06 Tue] Re-written for my biotools repo best practices [2022-09-06 Tue]. Downgraded to alignment and qc only. Need to add back macs2.
- [2022-08-29 Mon] Initial pre-processing, peak calling, and normalization validated.
** Reference
ENCODE blacklist_bed cite:amemiya2019
- old code
- Make reference gtf
  #+begin_src bash
wget --directory-prefix test/inputs https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/genes/mm10.ensGene.gtf.gz
zcat test/inputs/mm10.ensGene.gtf.gz | grep chr19 > test/inputs/chr19.gtf
\rm test/inputs/mm10.ensGene.gtf.gz
#+end_src
- Make reference chromosome bed file
    https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/mm10.chrom.sizes
    | chr1  | 1 | 195471971 |
    | chr2  | 1 | 182113224 |
    | chr3  | 1 | 160039680 |
    | chr4  | 1 | 156508116 |
    | chr5  | 1 | 151834684 |
    | chr6  | 1 | 149736546 |
    | chr7  | 1 | 145441459 |
    | chr10 | 1 | 130694993 |
    | chr8  | 1 | 129401213 |
    | chr14 | 1 | 124902244 |
    | chr9  | 1 | 124595110 |
    | chr11 | 1 | 122082543 |
    | chr13 | 1 | 120421639 |
    | chr12 | 1 | 120129022 |
    | chr15 | 1 | 104043685 |
    | chr16 | 1 |  98207768 |
    | chr17 | 1 |  94987271 |
    | chr18 | 1 |  90702639 |
    | chr19 | 1 |  61431566 |
  - Get sample fastqs
    #+begin_src bash
  zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib008_R1.fastq.gz | head -n 1500000 > /home/jeszyman/repos/atac-seq/test/inputs/atac1_R1.fastq

  zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib008_R2.fastq.gz | head -n 1500000 > test/inputs/atac1_R2.fastq

  zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib009_R1.fastq.gz | head -n 1500000 > test/inputs/atac2_R1.fastq

  zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib009_R2.fastq.gz | head -n 1500000 > test/inputs/atac2_R2.fastq

  zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib015_R1.fastq.gz | head -n 1500000 > test/inputs/atac3_R1.fastq

  zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib015_R2.fastq.gz | head -n 1500000 > test/inputs/atac3_R2.fastq

  zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib016_R1.fastq.gz | head -n 1500000 > test/inputs/atac4_R1.fastq

  zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib016_R2.fastq.gz | head -n 1500000 > test/inputs/atac4_R2.fastq

  for file in "test/inputs/*.fastq"; do gzip -f $file; done

  #+end_src
  - Blacklist_bed
    #+begin_src bash
  wget --directory-prefix="/home/jeszyman/repos/atac-seq/test/inputs" https://raw.githubusercontent.com/Boyle-Lab/Blacklist_bed/master/lists/mm10-blacklist.v2.bed.gz

  gunzip /home/jeszyman/repos/atac-seq/test/inputs/mm10-blacklist.v2.bed.gz
  #+end_src

- [[https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt][reske csaw workflow]]
- [[id:271b4d5f-727e-496e-b835-8fe9f8655655][biopipe module]]
- [[id:22e31d06-f5df-427e-bd70-3a2ccd3f47ec][ATAC-seq]]
*** [[id:57458bd3-005f-4342-ada7-58c55a74d7d0][ATAC-seq docker]]
