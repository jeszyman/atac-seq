* ATAC-seq                                                          :biopipe:
:PROPERTIES:
:header-args:bash: :tangle-mode (identity #o555)
:header-args:snakemake: :tangle-mode (identity #o555)
:header-args+h: :noweb yes
:logging: nil
:END:
** Setup
*** Bash preamble
#+name: bash_preamble
#+begin_src bash

#  Note: This script is tangled from code blocks in the Emacs Org-mode file at
#  https://github.com/jeszyman/atac-seq/blob/master/atac-seq.org. Changes
#  made directly to this file will be overwritten upon tangle from Org-mode.

#+end_src
*** [[id:57458bd3-005f-4342-ada7-58c55a74d7d0][ATAC-seq docker]]
*** Integration testing Snakemake YAML
:PROPERTIES:
:header-args:bash: :tangle ./config/int_test.yaml
:END:
#+begin_src bash

# Common names across repositories and snakefiles
datadir: "test"
fasta: "test/inputs/chr19.fa"
logdir: "test/logs"
threads: 4

# Repository and snakefile-specific names
container:
  atac: "~/sing_containers/atac.1.1.0.sif"
scriptdir:
  atac: "workflow/scripts"

keep_bed: "resources/keep.bed"

gtf: "test/inputs/chr19.gtf"
#+end_src
*** Integration testing inputs setup
- Sample sheet
  | library | basename          |
  |---------+-------------------|
  | lib001  | atac1_R1.fastq.gz |
  | lib002  | atac2_R1.fastq.gz |
  | lib003  | atac3_R1.fastq.gz |
  | lib004  | atac4_R1.fastq.gz |
- Make reference fasta from mm10 chr 19
  #+begin_src bash
mkdir -p "test/inputs"

wget --directory-prefix="test/inputs/" "https://hgdownload.soe.ucsc.edu/goldenPath/mm10/chromosomes/chr19.fa.gz"

zcat "test/inputs/chr9.fa.gz" | grep -A 200000 chr9 > test/inputs/chr9.fa

mkdir -p "test/inputs/ucsc_mm10_chr19"

chmod -R 777  "test/inputs/ucsc_mm10_chr19"

singularity shell ~/sing_containers/atac.sif

zcat "test/inputs/chr19.fa.gz" > test/inputs/chr19.fa


\rm /home/jeszyman/repos/atac-seq/test/inputs/chr19.fa

#+end_src
- Make reference gtf
  #+begin_src bash
wget --directory-prefix test/inputs https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/genes/mm10.ensGene.gtf.gz
zcat test/inputs/mm10.ensGene.gtf.gz | grep chr19 > test/inputs/chr19.gtf
\rm test/inputs/mm10.ensGene.gtf.gz
#+end_src
- Make reference chromosome bed file
  https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/mm10.chrom.sizes
  | chr1  | 1 | 195471971 |
  | chr2  | 1 | 182113224 |
  | chr3  | 1 | 160039680 |
  | chr4  | 1 | 156508116 |
  | chr5  | 1 | 151834684 |
  | chr6  | 1 | 149736546 |
  | chr7  | 1 | 145441459 |
  | chr10 | 1 | 130694993 |
  | chr8  | 1 | 129401213 |
  | chr14 | 1 | 124902244 |
  | chr9  | 1 | 124595110 |
  | chr11 | 1 | 122082543 |
  | chr13 | 1 | 120421639 |
  | chr12 | 1 | 120129022 |
  | chr15 | 1 | 104043685 |
  | chr16 | 1 |  98207768 |
  | chr17 | 1 |  94987271 |
  | chr18 | 1 |  90702639 |
  | chr19 | 1 |  61431566 |
- Get sample fastqs
  #+begin_src bash
zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib008_R1.fastq.gz | head -n 1500000 > /home/jeszyman/repos/atac-seq/test/inputs/atac1_R1.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib008_R2.fastq.gz | head -n 1500000 > test/inputs/atac1_R2.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib009_R1.fastq.gz | head -n 1500000 > test/inputs/atac2_R1.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib009_R2.fastq.gz | head -n 1500000 > test/inputs/atac2_R2.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib015_R1.fastq.gz | head -n 1500000 > test/inputs/atac3_R1.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib015_R2.fastq.gz | head -n 1500000 > test/inputs/atac3_R2.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib016_R1.fastq.gz | head -n 1500000 > test/inputs/atac4_R1.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib016_R2.fastq.gz | head -n 1500000 > test/inputs/atac4_R2.fastq

for file in "test/inputs/*.fastq"; do gzip -f $file; done

#+end_src
** ATAC-seq :smk:
*** DONE ATAC-seq read processing and alignment
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/atac.smk
:END:
**** Description
Sequencing read adapters were removed and reads were quality trimmed using flexbar.

Processed reads were aligned to mm10 using bowtie2.

PCR duplicate reads were removed using samtools. Reads were then filtered and processed for ATAC-seq analysis as follows. Only paired reads aligning to mm10 autosomes were retained. Read pairs were also removed if they overlapped known problematic regions from the ENCODE blacklist supercite:amemiya2019. Finally, alignments were shifted on the forward strand by +4 bp and on the reverse strand by âˆ’5 bp to account for the 9-bp duplication introduced by Tn5.
**** DONE Read trimming                                               :smk_rule:
- Snakemake
  #+begin_src snakemake
# Uses flexbar to trim and quality-filter fastq reads
rule trim:
    container:
        atac_container,
    input:
        r1 = atac_fastq_raw + "/{library}_R1.fastq.gz",
        r2 = atac_fastq_raw + "/{library}_R2.fastq.gz",
    log:
        config["logdir"] + "/{library}_atac_trim.log",
    output:
        atac_fastq_proc + "/{library}_flex_1.fastq.gz",
        atac_fastq_proc + "/{library}_flex_2.fastq.gz",
    params:
        outdir = atac_fastq_proc,
        script = config["scriptdir"]["atac"] + "/trim.sh",
        threads = config["threads"],
    resources:
        mem_mb=5000,
    shell:
        """
        {params.script} \
        {input.r1} \
        {input.r2} \
        {params.outdir} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:./workflow/scripts/trim.sh][Shell script]]
  #+begin_src bash :tangle ./workflow/scripts/trim.sh
#!/usr/bin/env bash

# Function for flexbar processing
flexbar_atac() {
    base=$(basename -s _R1.fastq.gz $1)
    flexbar \
        --adapter-pair-overlap ON \
        --adapter-preset Nextera \
        --pre-trim-right 1 \
        --reads "${1}" \
        --reads2 "${2}" \
        --target "${3}/${base}_flex" \
        --threads ${4} \
        --zip-output GZ
}

# Snakemake parameters
input_r1="$1"
input_r2="$2"
params_outdir="$3"
params_threads="$4"

# Run
flexbar_atac "${input_r1}" "${input_r2}" "${params_outdir}" "${params_threads}"

#+end_src
**** DONE Make bowtie2 index                                          :smk_rule:
- Snakemake
  #+begin_src snakemake
# Make bowtie2 index
rule atac_index:
    input:
        config["fasta"]
    params:
        base = atac_bowtie2_index,
        script = config["scriptdir"]["atac"] + "/index.sh",
    output:
        directory(atac_bowtie2_dir),
	atac_bowtie2_index + ".1.bt2",
    log:
        config["logdir"] + "/atac_index.log",
    container:
        atac_container,
    shell:
        """
        {params.script} \
        {input} \
        {params.base} \
        {output} &> {log}
        """
#+end_src
- [[file:./workflow/scripts/index.sh][Shell script]]
  #+begin_src bash :tangle ./workflow/scripts/index.sh
#!/usr/bin/env bash
reference=$1
bt2_index_base=$2
output=$3

mkdir -p $output
bowtie2-build \
    $reference \
    $bt2_index_base

#+end_src

**** DONE Align trimmed reads using bowtie2                           :smk_rule:
- Snakemake
  #+begin_src snakemake
rule align_bt2:
    container:
        atac_container,
    input:
        r1 = atac_fastq_proc + "/{library}_flex_1.fastq.gz",
        r2 = atac_fastq_proc + "/{library}_flex_2.fastq.gz",
        index = atac_bowtie2_index + ".1.bt2",
    log:
        config["logdir"] + "/{library}_align_bt2.log",
    params:
        prefix = atac_bowtie2_index,
        script = config["scriptdir"]["atac"] + "/align_bt2.sh",
        threads = config["threads"],
    output:
        atac_bam_raw + "/{library}.bam",
    shell:
        """
        {params.script} \
        {input.r1} \
        {input.r2} \
        {params.prefix} \
        {params.threads} \
        {output}
        """
#+end_src
- [[file:./workflow/scripts/align_bt2.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/align_bt2.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function
bt2_align(){
    bowtie2 --maxins 2000 --threads $1 --very-sensitive -x $2 -1 $3 -2 $4 |
        samtools view -@ $4 -bS - |
        samtools sort -@ $4 -o $5 -
    samtools index -@ $4 $5
}

# Snakemake variables
input_r1="$1"
input_r2="$2"
params_prefix="$3"
params_threads="$4"
output_bam="$5"

# Run
bt2_align "$params_threads" "$params_prefix" "$input_r1" "$input_r2" "$output_bam"
samtools index $output_bam
#+end_src
**** DONE De-duplicate alignments                                     :smk_rule:
- Snakemake
  #+begin_src snakemake
# De-duplicate alignments
rule dedup:
    container:
        atac_container,
    input:
        atac_bam_raw + "/{library}.bam",
    log:
        config["logdir"] + "/{library}_atac_dedup.log",
    output:
        atac_bam_dedup + "/{library}_dedup.bam",
    params:
        script = config["scriptdir"]["atac"] + "/dedup.sh",
	threads = config["threads"],
    resources:
        mem_mb=5000
    shell:
        """
        {params.script} \
        {input} \
        {params.threads} \
        {output} &> {log}
        """
#+end_src
- [[file:workflow/scripts/dedup.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/dedup.sh
raw_bam="${1}"
threads="${2}"
dedup_bam="${3}"
samtools sort -@ $threads -n -o - $raw_bam |
    samtools fixmate -m - - |
    samtools sort -@ $threads -o - - |
    samtools markdup -@ $threads -r - $dedup_bam
samtools index $dedup_bam
#+end_src

**** DONE Filter de-duplicated alignments                             :smk_rule:
- Snakemake
  #+begin_src snakemake
# Filter alignments by quality and reference position
rule filter_bam:
    container:
        atac_container,
    input:
        atac_bam_dedup + "/{library}_dedup.bam",
    log:
        config["logdir"] + "/{library}_atac_filter_bam.log",
    output:
        atac_bam_filt + "/{library}_filt.bam",
    params:
        keep_bed = atac_keep_bed,
        script = config["scriptdir"]["atac"] + "/filter_bam.sh",
	threads = config["threads"],
    shell:
        """
        {params.script} \
        {input} \
        {output} \
        {params.keep_bed} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:./workflow/scripts/filter_bam.sh][Shell script]]
  #+begin_src bash :tangle ./workflow/scripts/filter_bam.sh
#!/usr/bin/env bash

inbam="${1}"
outbam="${2}"
bed="${3}"
threads="${4}"
samtools view -@ $threads -b -f 3 -h -L $bed -M -q 20 -o $outbam $inbam
samtools index $outbam

#+end_src
**** DONE Tn5 shift filtered alignments                               :smk_rule:
- Snakemake
  #+begin_src snakemake
rule tn5_shift:
    container:
        atac_container,
    input:
        atac_bam_filt + "/{library}_filt.bam",
    log:
        config["logdir"] + "/{library}_tn5_shift.log",
    output:
        tmp = temp(atac_bam_tn5 + "/{library}_tn5_tmp.bam"),
        tn5 =      atac_bam_tn5 + "/{library}_tn5.bam",
    params:
        script = config["scriptdir"]["atac"] + "/tn5_shift.sh",
        threads = config["threads"],
    shell:
        """
        {params.script} \
        {input} \
        {output.tmp} \
        {output.tn5} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:./workflow/scripts/todo_tn5_shift.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/tn5_shift.sh
inbam=$1
outtmp=$2
outbam=$3
threads=$4

alignmentSieve --ATACshift --bam "$1" --numberOfProcessors $4 --outFile "$2"

samtools sort -@ $4 -o $3 $2
samtools index -@ $4 $3
#+end_src
**** DONE Get Tn5-shifted alignments to open chromatin                :smk_rule:
- Snakemake
  #+begin_src snakemake
rule open_chrom:
    container:
        atac_container,
    input:
        atac_bam_tn5 + "/{library}_tn5.bam",
    log:
        config["logdir"] + "/{library}_open_chrom.log",
    output:
        tmp = temp(atac_bam_open + "/{library}_open_tmp.bam"),
        open = atac_bam_open + "/{library}_open.bam",
    params:
        script = config["scriptdir"]["atac"] + "/open_chrom.sh",
        threads = config["threads"],
    shell:
        """
        {params.script} \
        {input} \
        {output.tmp} \
        {output.open} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:workflow/scripts/open_chrom.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/open_chrom.sh
  input=$1
    tmp=$2
   open=$3
threads=$4

alignmentSieve --bam $input \
               --maxFragmentLength 150 \
               --numberOfProcessors $threads \
               --outFile $tmp
samtools sort -@ $threads -o $open $tmp
samtools index -@ $threads $open
#+end_src
*** Quality control
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/atac.smk
:END:
**** DONE Make R txdb database                                        :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_txdb:
    container:
        atac_container,
    log:
        config["logdir"] + "/make_txdb.log",
    output:
        config["datadir"] + "/ref/txdb",
    params:
        gtf = config["gtf"],
        script = config["scriptdir"]["atac"] + "/make_txdb.R",
    shell:
        """
        Rscript {params.script} \
        {params.gtf} \
        {output} \
        > {log} 2>&1
        """
#+end_src
- [[file:./workflow/scripts/make_txdb.R][Rscript]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_txdb.R
#!/usr/bin/env Rscript
args = commandArgs(trailingOnly = TRUE)
gtf_file = args[1]
txdb_file = args[2]

library(GenomicFeatures)

txdb = makeTxDbFromGFF(gtf_file,
                       format = "gtf")

saveDb(txdb, file = txdb_file)
#+end_src
**** DONE ATAC-seq QC                                                 :smk_rule:
- Snakemake
  #+begin_src snakemake
rule atacseq_qc:
    container:
        atac_container,
    input:
        dup_bams = expand(atac_bam_raw + "/{library}.bam", library = ATAC_LIBRARIES),
        processed_bams = expand(atac_bam_tn5 + "/{library}_tn5.bam", library = ATAC_LIBRARIES),
        txdb = config["datadir"] + "/ref/txdb",
    log:
        config["logdir"] + "/atacseq_qc.log",
    output:
        config["datadir"] + "/qc/atac_qc.rdata",
    params:
        script = config["scriptdir"]["atac"] + "/atacseq_qc.R",
    shell:
        """
        Rscript {params.script} \
        "{input.dup_bams}" \
        "{input.processed_bams}" \
        {input.txdb} \
        {output} > {log} 2>&1
        """
#+end_src
- [[file:workflow/scripts/atac-seq_qc.R][Rscript]]
#+begin_src R :tangle ./workflow/scripts/atacseq_qc.R
#!/usr/bin/env Rscript
args = commandArgs(trailingOnly = TRUE)
dup_bam_str = args[1]
proc_bam_str = args[2]
txdb_file = args[3]
atac_qc_file = args[4]

library(ATACseqQC)
library(tidyverse)
library(AnnotationDbi)

txdb = loadDb(txdb_file)

split_filename_str = function(filename_str){
  vect = strsplit(filename_str, " ")[[1]]
  return(vect)
}

dup_bam_vect = split_filename_str(dup_bam_str)
proc_bam_vect = split_filename_str(proc_bam_str)
bam_vect = data.frame(
  dup = dup_bam_vect,
  proc = proc_bam_vect
)

atacqc = function(dup_bam, proc_bam, txdb){
  freq = readsDupFreq(dup_bam)
  libcomp = estimateLibComplexity(freq)
  txs = transcripts(txdb)
  gal = readBamFile(proc_bam)
  tsse_list = TSSEscore(gal, txs)
  tsse_df = data.frame(
    tsse = tsse_list[1],
    distance = 100*(-9:10-.5)
  )
  tsse = tsse_list[2]
  atac = list(libcomp, tsse, tsse_df)
  names(atac) = c("libcomp_df", "tsse", "tsse_df")
  return(atac)
}

atac_qc_out = mapply(atacqc, dup_bam_vect, proc_bam_vect, MoreArgs = list(txdb = txdb))

save(atac_qc_out, file = atac_qc_file)
#+end_src
**** DONE FastQC :smk_rule:                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
# <DESCRIPTIVE COMMENT>
rule fastqc:
    container:
        atac_container,
    input:
        raw = atac_fastq_raw + "/{library}_R{read}.fastq.gz",
        filt = atac_fastq_proc + "/{library}_flex_{read}.fastq.gz",
    log:
        config["logdir"] + "/{library}_R{read}_atac_fastqc.log",
    output:
        raw = config["datadir"] + "/qc/{library}_R{read}_fastqc.html",
        filt = config["datadir"] + "/qc/{library}_flex_{read}_fastqc.html",
    params:
        outdir = config["datadir"] + "/qc",
    shell:
        """
        fastqc --outdir {params.outdir} --quiet --threads {config[threads]} {input.raw}
        fastqc --outdir {params.outdir} --quiet --threads {config[threads]} {input.filt}
        """
#+end_src


**** DONE Samstats                                                    :smk_rule:
- Snakemake
  #+begin_src snakemake
rule samstats:
    container:
        atac_container,
    input:
        atac_bam_filt + "/{library}_filt.bam",
    output:
        stat = config["datadir"] + "/qc/{library}_filt_stat.txt",
        flagstat = config["datadir"] + "/qc/{library}_filt_flagstat.txt",
    log:
        config["logdir"] + "/{library}_samstats.log",
    shell:
        """
        workflow/scripts/samstats.sh {config[threads]} {input} {output.stat} {output.flagstat} 2>&1 >> {log}
        """
#+end_src
- [[file:./workflow/scripts/samstats.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/samstats.sh
samtools stats -@ $1 $2 > $3
samtools flagstat -@ $1 $2 > $4
#+end_src

** INPROCESS Integration testing :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/int_test.smk :tangle-mode (identity #o555)
:END:
*** Preamble, variable naming, etc
#+begin_src snakemake
atac_fastq_raw =     config["datadir"] + "/fastq_atac_raw"
atac_fastq_proc =    config["datadir"] + "/fastq_atac_proc"
logdir =             config["logdir"]
atac_container =     config["container"]["atac"]
atac_bowtie2_index = config["datadir"] + "/ref/ucsc_mm10_chr19/ucsc_mm10_chr19"
atac_bowtie2_dir =   config["datadir"] + "/ref/ucsc_mm10_chr19"
atac_bam_raw =       config["datadir"] + "/bam_atac_raw"
atac_bam_dedup =     config["datadir"] + "/bam_atac_dedup"
atac_bam_filt =      config["datadir"] + "/bam_atac_filt"
atac_keep_bed =      config["datadir"] + "/inputs/mm10chrs.bed"
atac_bam_tn5 =       config["datadir"] + "/bam_atac_tn5"
atac_bam_open =      config["datadir"] + "/bam_atac_open"

import pandas as pd
import re
import numpy as np

libraries = pd.read_table("test/inputs/libraries.tsv")
libraries["r1_path"]="test/inputs/" + libraries["basename"]

readable = []
for x in libraries.r1_path:
    readable.append(os.access(x, os.R_OK))
libraries['readable']=readable

libraries = libraries[libraries.readable == True]

library_indict = libraries["library"].tolist()
file_indict = libraries["r1_path"].tolist()
lib_dict = dict(zip(library_indict, file_indict))

ATAC_LIBRARIES = list(lib_dict.keys())
#+end_src
*** All rule
#+begin_src snakemake

rule all:
    input:
        expand(atac_fastq_raw + "/{library}_R1.fastq.gz", library = ATAC_LIBRARIES),
        expand(atac_fastq_raw + "/{library}_R2.fastq.gz", library = ATAC_LIBRARIES),
        expand(atac_fastq_proc + "/{library}_flex_1.fastq.gz", library = ATAC_LIBRARIES),
        expand(atac_fastq_proc + "/{library}_flex_2.fastq.gz", library = ATAC_LIBRARIES),
	atac_bowtie2_dir,
        expand(atac_bam_raw + "/{library}.bam",	library = ATAC_LIBRARIES),
        expand(atac_bam_dedup + "/{library}_dedup.bam", library = ATAC_LIBRARIES),
        expand(atac_bam_filt + "/{library}_filt.bam", library = ATAC_LIBRARIES),
        expand(atac_bam_tn5 + "/{library}_tn5.bam", library = ATAC_LIBRARIES),
        expand(atac_bam_open + "/{library}_open.bam", library = ATAC_LIBRARIES),
        config["datadir"] + "/ref/txdb",
        config["datadir"] + "/qc/atac_qc.rdata",
        expand(config["datadir"] + "/qc/{library}_R{read}_fastqc.html", library = ATAC_LIBRARIES, read=["1","2"]),
        expand(config["datadir"] + "/qc/{library}_flex_{read}_fastqc.html", library = ATAC_LIBRARIES, read=["1","2"]),
        expand(config["datadir"] + "/qc/{library}_filt_stat.txt", library = ATAC_LIBRARIES),
        expand(config["datadir"] + "/qc/{library}_filt_flagstat.txt", library = ATAC_LIBRARIES),

        #expand(config["qc_dir"] + "/{library_id}_{read}_fastqc.html", library_id = LIBRARY_IDS, read = ["R1", "R2"]),
        #expand(config["qc_dir"] + "/{library_id}_stat.txt", library_id = LIBRARY_IDS),
        #expand(config["qc_dir"] + "/{library_id}_flagstat.txt", library_id = LIBRARY_IDS),
        #expand(config["data_dir"] + "/macs2/{library_id}_{bam_process}_{macs_broad}", library_id = LIBRARY_IDS, bam_process = ["open", "regfilt"], macs_broad = MACS_BROAD_EXT),
        #expand(config["data_dir"] + "/macs2/{library_id}_{bam_process}_{macs_narrow}", library_id = LIBRARY_IDS, bam_process = ["open", "regfilt"], macs_narrow = MACS_NARROW_EXT),
        #expand(config["data_dir"] + "/csaw/background_counts_all_{bam_process}_rse.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/csaw/counts_all_{bam_process}_rse.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/open_chrom/{library_id}_open_chrom.txt", library_id = LIBRARY_IDS),
	#expand(config["data_dir"] + "/csaw/norm_counts_rse_{bam_process}.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/csaw/dge_{bam_process}.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/dca/dca_granges_{bam_process}.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/dca/{bam_process}_dca.csv", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/dca/{bam_process}_chipseek.rds", bam_process = BAM_PROCESS),
#+end_src

*** Symlink input fastqs                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
rule symlink:
    container:
        atac_container,
    input:
        lambda wildcards: lib_dict[wildcards.library],
    output:
        r1 = atac_fastq_raw + "/{library}_R1.fastq.gz",
        r2 = atac_fastq_raw + "/{library}_R2.fastq.gz",
    shell:
        """
        r2=$(echo {input} | sed "s/_R1/_R2/g")
        ln -sf --relative {input} {output.r1}
        ln -sf --relative $r2 {output.r2}
        """
#+end_src

*** Includes statements
#+begin_src snakemake

include: "atac.smk"

#+end_src
** :dev:
:PROPERTIES:
:header-args:snakemake: :tangle no
:header-args:bash: :tangle no
:END:
- ? cp /mnt/ris/jschwarz/cardiac-radiobiology/ref/keep.bed resources/keep.bed
*** ideas
- cite:liu2021 https://www.sciencedirect.com/science/article/pii/S1672022921001479
- for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
- lib complexity w/ preseq http://smithlabresearch.org/software/preseq/ https://github.com/smithlabcode/preseq

- common
  #+begin_src bash


CHROM_FILT:
  - "open"
  - "regfilt"

JOIN:
  - "union"
  - "intersect"
  - "naive"

WIDTH:
  - "broad"
  - "narrow"

#+end_src
#+begin_src bash
git add -A
git commit -m "feat: initial dev"
git push origin master

git branch dev_initial
git checkout dev_initial
git push origin dev_initial
#+end_src

#+begin_src bash
git init
git add -A
git commit -am "First commit"
git branch -M master

#
git remote add origin git@github.com:jeszyman/atac-seq.git
git branch -M master
git push -u origin master

cp basecamp/src/pre-commit src/precommit_git_hook
ln -s src/precommit_git_hook .git/hooks/precommit
chmod 777 .git/hooks/precommit
#+end_src

- startup script
  #+begin_src bash
#!/usr/bin/env bash
repo=$1
mntpt=$2
sif_dir=$3

# Check for parameters, return usage if empty
if [ $# -ne 3 ];
then
    printf "\n usage: repo_startup.sh <REPO PATH> <RIS MOUNT PT> <SINGULARITY CONTAINER DIR>
    \n ATAC-seq repo development helper script
    \n "
else

    # Check git file hook is read-able
    if [ -r "${repo}/.git/hooks/precommit" ]; then
        echo "Git size check is read-able"
    else
        echo
        "Git size check is not read-able"
        exit 1
    fi

    # Check mount point
    if grep -qs $mntpt /proc/mounts; then
        echo "RIS storage mounted."
    else
        echo "RIS storage NOT mounted, exiting."
        exit 1
    fi

    # Check singularity container
    if [ -r $sif_dir/atac.sif ]; then
        echo "Local SIF file present"
    else
        echo "No local SIF file found"
        exit 1
    fi

    # Check singularity container up-to-date
    if [ /mnt/ris/jschwarz/cardiac-radiobiology/atac.sif -nt $sif_dir/atac.sif ]; then
        echo "Local SIF is out of date. Updating ..."
        cp /mnt/ris/jschwarz/cardiac-radiobiology/atac.sif $sif_dir/atac.sif
    else
        echo "Local SIF file is up to date"
    fi

    cur_branch=$(git branch | head -n 1)
    echo "Current branch is $cur_branch"
fi
#+end_src




- [ ] https://github.com/snakemake-workflows/rna-seq-star-deseq2/blob/master/workflow/rules/common.smk


#+begin_src python
import pandas as pd
import re

libraries = (
    pd.read_csv("/home/jeszyman/repos/atac-seq/test/inputs/full_libraries.tsv", sep="\t",
		dtype={"library_id": str})
    .set_index("library_id", drop=False)
    .sort_index()
)

read1str=pd.Series(libraries.library_fq_r1_basename, dtype="string")

libraries["library_fq_r2_basename"] = [re.sub("R1.fastq.gz","R2.fastq.gz", x) for x in read1str]

#+end_src

libraries = (
    pd.read_csv("/home/jeszyman/repos/atac-seq/test/inputs/full_libraries.tsv", sep="\t",
		dtype={"library_id": str})
    .set_index("library_id", drop=False)
    .sort_index()
)


- add tablular sample input https://github.com/snakemake-workflows/rna-seq-star-deseq2
:header-args: :tangle no
- transcription factor sites
- homer superenhancers http://homer.ucsd.edu/homer/ngs/peaks.html

**** Make keep bed                                                 :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_keep_bed:
    input:
        autosome_bed = config["data_dir"] + "/ref/grcm38_primary_assembly_chr.bed",
        blacklist_bed = config["data_dir"] + "/ref/mm10-blacklist.v2_ENSEMBL_chr.bed",
    output:
        keep_bed = config["data_dir"] + "/ref/keep.bed",
    shell:
        """
        bedtools subtract -a {input.autosome_bed} -b {input.blacklist_bed} > {output.keep_bed}
        """
#+end_src
**** ATAC-seq peak calling and chromating accessibility on subsets
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-03-31 Thu 14:25]
:END:
  - [-] run 48h
    #+begin_src bash
lib_str="lib008 lib009 lib010 lib011 lib012 lib013 lib014 lib015 lib016"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
      "_open_tn5.bam$" \
      "${lib_str}" \
      16 \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_open_background_counts.rds \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_open_counts.rds

#+end_src
  - [ ] run 6wk
  - [-] run 48h
    #+begin_src bash
lib_str="lib008 lib009 lib010 lib011 lib012 lib013 lib014 lib015 lib016"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
      "_regfilt_tn5.bam$" \
      "${lib_str}" \
      16 \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_regfilt_background_counts.rds \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_regfilt_counts.rds

#+end_src
  - [ ] run 6wk

- run ir48h vs sham
- run ir6w vs sham

***** Peak annotation
- Snakemake
  #+begin_src snakemake
rule peak_annotation:
    input:
        config["data_dir"] + "/atac/dca.rds"
    params:
        script = config["repo"] + "/workflow/scripts/peak_annotation.R"
    output:
        annotated_counts = config["data_dir"] + "/atac/annotated_counts.rds",
    log:
        config["data_dir"] + "/logs/peak_annotation.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output.annot} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/peak_annotation.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/peak_annotation.R
<<r_smk_preabmle>>

#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to annotate csaw peaks   ###
###

args = commandArgs(trailingOnly = TRUE)
peaks_rds = args[1]
annotation_file = args[2]

peaks = readRDS(peaks_rds)

library(ChIPseeker)
library(csaw)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
library(tidyverse)

txdb = TxDb.Mmusculus.UCSC.mm10.ensGene

peak_loc = peaks

chipseek = annotatePeak(peak_loc, TxDb = txdb, annoDb = "org.Mm.eg.db")

annotation = as_tibble(as.data.frame(chipseek))

write.csv(annotation, row.names = F, file = annotation_file)
#+end_src
****** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
****** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
******* Make backgroud bins                                        :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_backgroud_bins:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/make_backgroud_bins.R"
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
    output:
    log:
        config["data_dir"] + "/logs/make_backgroud_bins.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_backgroud_bins.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_backgroud_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to make background bins for csaw TMM normalization   ###
###

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
window_file =  args[1]
bam_dir = args[2]
bam_pattern = args[3]
filt_libs_str = args[4]
rse = args[4]
bk = args[5]

filt_libs = unlist(strsplit(filt_libs_str, " "))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

#+end_src
******* d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src

******** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./workflow/scripts/edger.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/edger.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src
**** Ideas
  - full log to catch this error
    - - https://www.biostars.org/p/396538/
    - note- log didn't work [[file:/mnt/ris/jschwarz/cardiac-radiobiology/log/fastqc_log.txt]]
    - #TODO how to add log file to find "$data_dir}/atac/atac-fastq" -name "*.fastq.gz" | parallel fastqc --outdir="$data_dir}/qc" }
  - preamble


***** Reference
- [[https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt][reske csaw workflow]]
***** Hold and dev
:PROPERTIES:
header-args:snakemake: :tangle no
:END:
***** Ideas
:PROPERTIES:
header-args:snakemake: :tangle no
:END:
**** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:

***** [#Y] Make nucleosome positioning alignments
:PROPERTIES:
:CREATED:  [2021-09-02 Thu 11:22]
:ID:       5acea857-b98c-473b-9b23-d430665cbb4d
:END:
:LOGBOOK:
- State "RUN"        from "DONE"       [2021-09-22 Wed 10:09]
- State "DONE"       from "CANCELED"   [2021-09-22 Wed 10:09]
CLOCK: [2021-09-15 Wed 09:35]--[2021-09-15 Wed 10:53] =>  1:18
:END:
#+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                              "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                              "TC", "UQ"),
               "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                             "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                             "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                             "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                             "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                   param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

save(gal_lib051,
   gal_lib052,
   gal_lib053,
   gal_lib054,
   gal_lib055,
   gal_lib057,
   file = file.path(data_dir,"atac/gal.RData"))

#+end_src
- Reference
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
***** ATAC-seq QC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule atac-seq_qc:
    input:
    params:
        script = config["repo"] + "workflow/scripts/atac-seq_qc.R"
    output:
    log:
        config["data_dir"] + "/logs/atac-seq_qc.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/atac-seq_qc.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/atac-seq_qc.R
#########1#########2#########3#########4#########5#########6#########7#########8

###
###   / SCRIPT TITLE   ###
###

#+end_src

****** Transcription start sites occupancy
:PROPERTIES:
:CREATED:  [2021-09-15 Wed 10:09]
:ID:       eecd41c6-4f32-4d79-b7d5-40d666b8f85b
:END:
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#setwd("/home/jeszyman/repos/card-rad-bio")
#source("./src/setup.R")
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                                "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                                "TC", "UQ"),
                 "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                               "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                               "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                               "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                               "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                     param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

save(gal_lib051,
     gal_lib052,
     gal_lib053,
     gal_lib054,
     gal_lib055,
     gal_lib057,
     file = file.path(data_dir,"atac/gal.RData"))


#########1#########2#########3#########4#########5#########6#########7#########8
tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+begin_src R
#TODO LOAD gals
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
txs <- transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)

tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+caption: CAPTION label:fig-atac-nuc-position
[[file:results/imgs/atac_nuc_position.pdf][file:results/imgs/atac_nuc_position.pdf]]



- Post-atacseqqc
#+end_src

BiocManager::install("diffloop")

library(diffloop)
library(TxDb.Mmusculus.UCSC.mm10.knownGene)

seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = scanBam(bam_list[1])
class(test)
>>>>>>> 9b786365ee566b1a63eb65edb3a6fa94e4ad8e97

bamTop100 <- scanBam(BamFile(bam_list[1], yieldSize = 100))
bam_list[1]
bamTag(bamTop100)



gal = readBamFile(bam_list[1], tags = tags, which = which, asMates = T, bigFile=T)

gal
param = ScanBamParam(tag))

which
test = rmchr(which)
test
test = renameSeqlevels(which, c("chr1"="1"))
test


test=rmchr(which)
head(which)


gal
## Promotor / transcript score
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
pt = PTscore(gal, txs)

## Nucleosome free regions score
nfr = NFRscore(gal, txs)

## Transcription start site enrichment
tsse = TSSEscore(gal, txs)

# Ideas
## Adjust start sites
#+end_src
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
- lib complexity w/ preseq http://smithlabresearch.org/software/preseq/ https://github.com/smithlabcode/preseq


TSSEs
ir01 - 2.75


#+caption: CAPTION label:fig-atac-tss
[[file:results/imgs/atac_tss.pdf]]

****** Aggregate
:PROPERTIES:
:CREATED:  [2021-09-21 Tue 07:29]
:ID:       a9426a9b-16e8-4356-8d98-314b4c7f8ec5
:END:
****** notes
:PROPERTIES:
:ID:       06f9345e-a489-4b5e-9f68-82e22e468096
:END:
- run on server, run launch_atac to load docker with ATACseqQC package
- do not run R docker through docker_interactive function- unknown error
- cite:liu2021 https://www.sciencedirect.com/science/article/pii/S1672022921001479

***** MultiQC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule multiqc:
    input:
    output:
    shell:
        """
        scripts/multiqc.sh
        """
#+end_src
- [[file:./workflow/scripts/multiqc.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/multiqc.sh
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

# Snakemake variables
# Function
# Run command
#########1#########2#########3#########4#########5#########6#########7#########8
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

#+end_src
***** Make frag distribution mat:smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_frag_distribution_mat:
    input:
        bam_dir = config["data_dir"] + "/atac/bam",
    params:
        script = config["repo"] + "/workflow/scripts/make_frag_distribution_mat.R",
    output:
        frag_dist = config["data_dir"] + "/qc/frag_dist.rds",
    log:
        config["data_dir"] + "/logs/make_frag_distribution_mat.log"
    shell:
        """
        Rscript {params.script} \
	{input.bam_dir} \
	{output.frag_dist}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_frag_distribution_mat.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_frag_distribution_mat.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make fragment size distribution matrix   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)

bam_files = list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = TRUE)

names(bam_files) = gsub("_dedup.bam", "", list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = FALSE))

#' @title fragment size distribution
#' @description estimate the fragment size of bams
#' @param bamFiles A vector of characters indicates the file names of bams.
#' @param index The names of the index file of the 'BAM' file being processed;
#'        This is given without the '.bai' extension.
#' @param bamFiles.labels labels of the bam files, used for pdf file naming.
#' @param ylim numeric(2). ylim of the histogram.
#' @param logYlim numeric(2). ylim of log-transformed histogram for the insert.
#' @return Invisible fragment length distribution list.
#' @importFrom Rsamtools ScanBamParam scanBamFlag scanBam idxstatsBam
#' @importFrom graphics axis par
#' @import GenomicRanges
#' @export
#' @author Jianhong Ou
#' @examples
#' bamFiles <- dir(system.file("extdata", package="ATACseqQC"), "GL.*.bam$", full.names=TRUE)
#' bamFiles.labels <- sub(".bam", "", basename(bamFiles))
#' fragSizeDist(bamFiles, bamFiles.labels)

fragSizeDist <- function(bamFiles, bamFiles.labels, index=bamFiles, ylim=NULL,
                         logYlim=NULL){
  opar <- par(c("fig", "mar"))
  on.exit(par(opar))
  pe <- mapply(testPairedEndBam, bamFiles, index)
  if(any(!pe)){
    stop(paste(bamFiles[!pe], collapse = ", "),
         "is not Paired-End file.")
  }
  summaryFunction <- function(seqname, seqlength, bamFile, ind, ...) {
    param <-
      ScanBamParam(what=c('isize'),
                   which=GRanges(seqname, IRanges(1, seqlength)),
                   flag=scanBamFlag(isSecondaryAlignment = FALSE,
                                    isUnmappedQuery=FALSE,
                                    isNotPassingQualityControls = FALSE))
    table(abs(unlist(sapply(scanBam(bamFile, index=ind, ..., param=param),
                            `[[`, "isize"), use.names = FALSE)))
  }
}

idxstats <- unique(do.call(rbind, mapply(function(.ele, .ind)
    idxstatsBam(.ele, index = .ind)[, c("seqnames", "seqlength")], bamFiles, index, SIMPLIFY=FALSE)))
  seqnames <- as.character(idxstats[, "seqnames"])
  seqlen <- as.numeric(idxstats[, "seqlength"])
  fragment.len <- mapply(function(bamFile, ind) summaryFunction(seqname=seqnames, seqlength=seqlen, bamFile, ind),
                         bamFiles, index, SIMPLIFY=FALSE)

  names(fragment.len) <- bamFiles.labels

  ## minor.ticks.axis <- function(ax,n=9,t.ratio=0.5,mn,mx,...){

  ##   lims <- par("usr")
  ##   lims <- if(ax %in% c(1,3)) lims[1:2] else lims[3:4]

  ##   major.ticks <- pretty(lims,n=5)
  ##   if(missing(mn)) mn <- min(major.ticks)
  ##   if(missing(mx)) mx <- max(major.ticks)

  ##   major.ticks <- major.ticks[major.ticks >= mn & major.ticks <= mx]

  ##   labels <- sapply(major.ticks,function(i)
  ##     as.expression(bquote(10^ .(i)))
  ##   )
  ##   axis(ax,at=major.ticks,labels=labels,
  ##        las=ifelse(ax %in% c(2, 4), 2, 1), ...)

  ##   n <- n+2
  ##   minors <- log10(pretty(10^major.ticks[1:2],n))-major.ticks[1]
  ##   minors <- minors[-c(1,n)]

  ##   minor.ticks = c(outer(minors,major.ticks,`+`))
  ##   minor.ticks <- minor.ticks[minor.ticks > mn & minor.ticks < mx]


  ##   axis(ax,at=minor.ticks,tcl=par("tcl")*t.ratio,labels=FALSE)
  ## }

  ## null <- mapply(function(frag.len, frag.name){
  ##   x <- 1:1010
  ##   frag.len <- frag.len[match(x, names(frag.len))]
  ##   frag.len[is.na(frag.len)] <- 0
  ##   y <- frag.len / sum(frag.len)
  ##   y <- as.numeric(y)
  ##   names(y) <- x
  ##   par(mar=c(5, 5, 4, 2) +.1)
  ##   plot(x, y*10^3, main=paste(frag.name, "fragment sizes"),
  ##        xlim=c(0, 1010), ylim=ylim,
  ##        xlab="Fragment length (bp)",
  ##        ylab=expression(Normalized ~ read ~ density ~ x ~ 10^-3),
  ##        type="l")
  ##   par(fig=c(.4, .95, .4, .95), new=TRUE)
  ##   plot(x, log10(y), xlim=c(0, 1010), ylim=logYlim,
  ##        xlab="Fragment length (bp)", ylab="Norm. read density",
  ##        type="l", yaxt="n")
  ##   minor.ticks.axis(2)
  ##   par(opar)
  ## }, fragment.len, names(fragment.len))

  #return(invisible(fragment.len))
}

frag_dist = fragSizeDist(bam_files, names(bam_files))

saveRDS(object = frag_dist,
        file  = rds)
#+end_src
- Old code
  #+begin_src R



class(test)


names(test)

class(test[[1]])

head(test[[1]])
data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

pdf("/tmp/test.pdf")
lib051_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib051_aut_blk_ddp.bam", bamFiles.labels = "lib051")
lib052_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib052_aut_blk_ddp.bam", bamFiles.labels = "lib052")
lib053_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib053_aut_blk_ddp.bam", bamFiles.labels = "lib053")
lib054_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib054_aut_blk_ddp.bam", bamFiles.labels = "lib054")
lib055_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib055_aut_blk_ddp.bam", bamFiles.labels = "lib055")
lib056_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib056_aut_blk_ddp.bam", bamFiles.labels = "lib056")
lib057_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib057_aut_blk_ddp.bam", bamFiles.labels = "lib057")
dev.off()

save(lib051_frag,lib052_frag,lib053_frag,lib054_frag,lib055_frag,lib056_frag,lib057_frag, file = "~/repos/card-rad-bio/results/qc/frag.RData")

#########1#########2#########3#########4#########5#########6#########7#########8
load("./results/qc/frag.RData")
getwd()
#+end_src
  #+begin_src R
load("/mnt/ris/jschwarz/cardiac-radiobiology/atac/fragsize.RData")

ls()

fragsize_ct01
#+end_src
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#
load(file.path(data_dir,"/atac/fragsize.RData"))

# Rename old frag size files
fragsize_lib051 = fragsize_ct01
fragsize_lib052 = fragsize_ct02
fragsize_lib053 = fragsize_ir01
fragsize_lib054 = fragsize_ir02
fragsize_lib055 = fragsize_ir03
fragsize_lib056 = fragsize_ir04
fragsize_lib057 = fragsize_ct03

# create df
fragsize = data.frame(
  length = as.numeric(names(head(fragsize_lib051[[1]], n = 1000))),
  lib051 = as.vector(head(fragsize_lib051[[1]], n = 1000)),
  lib052 = as.vector(head(fragsize_lib052[[1]], n = 1000)),
  lib053 = as.vector(head(fragsize_lib053[[1]], n = 1000)),
  lib054 = as.vector(head(fragsize_lib054[[1]], n = 1000)),
  lib055 = as.vector(head(fragsize_lib055[[1]], n = 1000)),
  lib057 = as.vector(head(fragsize_lib057[[1]], n = 1000)))
fragsize = as_tibble(fragsize)

# save df
save(fragsize, file = file.path(repo,"/results/rdata/atac_fragsize.RData"))

# make plot
fragsize %>%
  pivot_longer(cols = !length, names_to = "library_id", values_to = "count") %>%
  ggplot(., aes(x = length, y = count, group = library_id)) + geom_line() + xlim()

+ geom_bar(stat = "identity")

#+end_src


**** Library complexity:smk_rule:
- Snakemake
  #+begin_src snakemake
rule library_complexity:
    input:
        config["bam_dir"] + "/{library_id}.bam",
    params:
        script = config["atac_scripts_dir"] + "/library_complexity.R",
    output:
        config["qc_dir"] + "/{library_id}_libcomplex.rds",
    log:
        config["log_dir"] + "/{library_id}_library_complexity.log",
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/library_complexity.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/library_complexity.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to assess ATAC-seq library complexity by fragment length   ###
###

args = commandArgs(trailingOnly = TRUE)
bam = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

libCompWrap = function(dup_bam){
  estimateLibComplexity(readsDupFreq(dup_bam))
}

complex = libCompWrap("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5469_MGI2048/lc-08.TCGTGATCAG-ACACTACGTA/lc-08.TCGTGATCAG-ACACTACGTA.genome_accepted_hits.bam")

saveRDS(object = complex,
        file = rds)

#+end_src
- Reference
  - https://github.com/smithlabcode/preseq
  - lib complexity w/ preseq http://smithlabresearch.org/software/preseq/
  - Old code
    #+begin_src R
  load(file.path(repo,"/results/rdata/library_complexity_raw.RData"))
  ls()
  head(library_complexity_raw)

  test = as.data.frame(library_complexity_raw)

  lib_complex_plot =
    as.data.frame(library_complexity_raw) %>%
    pivot_longer(cols = ends_with("values"), names_to = "library_id", values_to = "pred") %>%
    pivot_longer(cols = ends_with("reads"), names_to = "library_id2", values_to = "reads") %>%
    select(!(ends_with("relative.size"))) %>%
    mutate(library_id = substr(library_id, 1, 6)) %>%
    select(library_id, pred, reads) %>%
    filter(library_id != "lib056") %>%
    ggplot(., aes(x = reads, y = pred, group = library_id)) + geom_smooth(se = FALSE) +
     xlab("Total molecules") + ylab("Unique molecules")
  save_plot("./results/imgs/lib_complex.pdf", lib_complex_plot)

  #+end_src

    #+begin_src R

  load("./results/rdata/library_complexity_raw.RData")
  load("./data/data_model.RData")

  atac_multiqc_general_raw =
    as_tibble(
      read.table(
        file.path(repo,"results/qc/atac_qc_data/multiqc_general_stats.txt"),
        header = T,
        sep = '\t',
        fill = T))

  atac_multiqc_general_raw


  ## Modify atac multiqc df
  atac_multiqc_general_mod =
    atac_multiqc_general_raw %>%
    mutate(library_id = gsub("^.....", "", Sample)) %>%
    mutate(library_id = gsub("_.*$", "", library_id)) %>%
    mutate(total_reads = FastQC_mqc.generalstats.fastqc.total_sequences) %>%
    mutate(aligned_reads = Samtools_mqc.generalstats.samtools.mapped_passed) %>%
    mutate(processing = ifelse(grepl("_R1", Sample), "raw",
                        ifelse(grepl("ddp_flagstat", Sample), "processed",
                               ifelse(grepl("ddp_open_flagstat", Sample), "open", "other")))) %>%
    filter(processing != "other") %>%
    filter(!grepl("_R2", Sample)) %>%
    filter(!grepl("flex", Sample)) %>%
    filter(!is.na(total_reads) | !is.na(aligned_reads)) %>%
    mutate(read_prs = ifelse(!is.na(total_reads), total_reads, aligned_reads)) %>%
    select(library_id, processing, read_prs) %>%
    pivot_wider(names_from = processing, values_from = read_prs) %>%
    mutate(p_proc = processed/raw*100) %>%
    mutate(p_open = open/raw*100)
  atac_multiqc_general_mod

  library_complexity_mod = as_tibble(data.frame(lib051 = library_complexity_raw[[1]],
                                      lib052 = library_complexity_raw[[2]],
                                      lib053 = library_complexity_raw[[3]],
                                      lib054 = library_complexity_raw[[4]],
                                      lib055 = library_complexity_raw[[5]],
                                      lib056 = library_complexity_raw[[6]],
                                      lib057 = library_complexity_raw[[7]])) %>%
    mutate(rel_size = lib051.relative.size) %>%
    select(!ends_with("relative.size")) %>%
    pivot_longer(cols = starts_with("lib"), names_to = "label", values_to = "count") %>%
    mutate(library_id = substr(label, 1, 6)) %>%
    mutate(label = gsub("^.*\\.","",label)) %>%
    pivot_wider(names_from = label, values_from = count) %>%
    left_join(libraries, by = "library_id")
  library_complexity_mod

  library_complexity =
    library_complexity_mod %>%
    left_join(atac_multiqc_general_mod, by = "library_id") %>%
    filter(p_proc > 25)

  library_complexity_plot =
    library_complexity %>%
    ggplot(., aes(x = values, y = reads)) + geom_smooth()
  library_complexity_plot

  save_plot("./results/imgs/lib_complex.pdf", library_complexity_plot)

  #+end_src
**** Make fastq input symlinks
#+begin_src snakemake
rule symlink_fastqs:
    params:
        fastq = lambda w: libraries[libraries.library_id == w.library_id].fq_basename.tolist()
    output:
        r1 = config["fq_sym_dir"] + "/{library_id}_R1.fastq.gz",
        r2 = config["fq_sym_dir"] + "/{library_id}_R2.fastq.gz",
    shell:
        """
        ln -sf --relative {config[fq_src_dir]}/{params.fastq}_R1.fastq.gz {output.r1}
        ln -sf --relative {config[fq_src_dir]}/{params.fastq}_R2.fastq.gz {output.r2}
        """
#+end_src
**** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/differential_accessibility.R
#!/usr/env R

#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
### Script to generate ATAC-seq differential accessibility model with EdgeR  ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8

# Setup

## Command line arguements
args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

## Load libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Load data
counts = readRDS(counts_rds)
background = readRDS(background_rds)
load(data_model)

# Run EdgeR workflow
counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design = model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src

***** Differential accessibility 6wk vs. sham                      :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/differential_accessibility.R
<<r_smk_preamble>>
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to generate differential accessibility model with EdgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
load(data_model)
background = readRDS(background_rds)

counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design <- model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src

***** Differential accessibility 48h vs. sham                      :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/differential_accessibility.R

# needs to be part of counts step
colnames(counts) = c("lib001","lib002","lib003","lib004")


#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
###   Script to generate differential accessibility model with EdgeR         ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8

args = commandArgs(trailingOnly = TRUE)

counts_rds = "~/repos/atac-seq/test/csaw/counts_all_regfilt_rse.rds"
background_rds = "~/repos/atac-seq/test/csaw/background_counts_all_regfilt_rse.rds"
groups = as.factor(c("ir48h","ir48h","sham","sham"))
contrast = "ir48h-sham"

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
background = readRDS(background_rds)
counts = normFactors(background, se.out = counts)
y = asDGEList(counts)
colnames(y$counts) = colnames(counts)
rownames(y$samples) = colnames(counts)
y$samples$group = groups
design = model.matrix(~0 + groups, data=y$samples)
colnames(design) = levels(groups)
y = estimateDisp(y, design)
fit = glmQLFit(y, design, robust=TRUE)
results <- glmQLFTest(fit, contrast=makeContrasts(contrast, levels=design))
# combine GRanges rowdata with DA statistics
rowData(counts) = cbind(rowData(counts), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
#merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
#merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)


# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src
***** Peak annotation
- is granges or rowRanges of a RSE
#+begin_src R
test=readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_counts.rds")
test
head(assays(test))
head(rowData(test))
head(rowRanges(test))
#+end_src
**** Pathway analysis
- GSEA
  #+begin_src R
library(msigdbr)
library(fgsea)

## Generate all msigdb mouse hallmark gene sets as list of lists
msigdbr_df <- msigdbr(species = "mouse", category = "H")
ms_path_list = split(x = msigdbr_df$ensembl_gene, f = msigdbr_df$gs_name)

test = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/dca_ir84_sham_annot.RDS")

str(annotation)


sign = sign(annotation$logFC)
logP = -log10(annotation$PValue)
rank = logP/sign

names(rank) = annotation$ENSEMBL

gsea = as_tibble(fgseaMultilevel(ms_path_list, rank, maxSize = 500))

min(gsea$padj, na.rm = T)

gsea %>% arrange(pval)

gsea = gsea[,1:7]

gsea = as.data.frame(gsea)

gsea
write.csv(file = "/tmp/test.csv", gsea)

#########1#########2#########3#########4#########5#########6#########7#########8

# Promoter only

promoters = annotation %>%
  filter(grepl("Promoter", annotation))

nrow(promoters)

sign = sign(promoters$logFC)
logP = -log10(promoters$PValue)
rank = logP/sign

names(rank) = promoters$ENSEMBL

gsea = as_tibble(fgseaMultilevel(ms_path_list, rank, maxSize = 500))

min(gsea$padj, na.rm = T)

gsea %>% arrange(pval)


#########1#########2#########3#########4#########5#########6#########7#########8

str(annotation)

annotation$pos = as.character(annotation$annotation)

annotation %>% filter(FDR < 0.05, logFC > 1) %>% dplyr::select(pos)


test =annotation %>% filter(FDR < 0.05, logFC < -1, grepl("Promoter", annotation)) %>% pull(SYMBOL)

cat(test, file = "~/down.txt")
annotation %>% filter()

#########1#########2#########3#########4#########5#########6#########7#########8
library(biomaRt)


ensembl <- useEnsembl(biomart = "ensembl")

datasets <- listDatasets(ensembl)

searchDatasets(mart = ensembl, pattern = "mmusculus")

ensembl <- useDataset(dataset = "mmusculus_gene_ensembl", mart = ensembl)


grep("entrez", filters, ignore.case = T, value = T)

values = test$ENTREZID


values = values[!is.na(values)]

index = getBM(attributes = c('ensembl_gene_id','entrezgene_id'),
              filters = 'entrezgene_id',
              values = values,
              mart = ensembl, useCache = F)

nrow(index
index$entrezgene_id = as.character(index$entrezgene_id)

library(tidyverse)


test2 = test %>% left_join(index, by = c("ENTREZID" = "entrezgene_id"))
test2 = test2[!is.na(test2$ensembl_gene_id),]
test2 = test2[grepl("Promoter", test2$annotation), ]
#########1#########2#########3#########4#########5#########6#########7#########8

#enricher lists
test = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/dca_ir48_sham.RDS")

head(test)
res = as.data.frame(test)
ggplot(res, aes(x = logFC))+geom_density()

ls()

res %>% filter(rep.logFC > 2)
str(res)
#+end_src
#+begin_src R
annotation

annotation %>% filter(logFC > 2)
#+end_src

***** Transcription factors
***** Mouse Ventricle Radiation-induced Chromatin Remodeling at 48 Hours :sci_rep:
:PROPERTIES:
:export_latex_class: paper
:export_latex_header: \usepackage{./latex/tex/report}
:export_title: Mouse Ventricle Radiation-induced Chromatin Remodeling at 48 Hours
:export_options: tags:nil todo:nil toc:2 \n:t ^:nil
:export_file_name: ./results/reports/szymanski_ms_atac_48_report.pdf
:ID:       70d78969-3820-4def-b6f3-ab3c7c3e5d87
:END:
****** LaTeX settings                                              :noexport:
[[file:results/reports/szymanski_ms_atac_48_report.tex]]
[[file:~/repos/latex/tex/report.sty]]
\usepackage[T1]{fontenc}
\usepackage{tgbonum}
****** LaTeX Preamble                                                :ignore:
\setcounter{secnumdepth}{0}
\vspace{5mm}
\hfill Last compiled {{{time(%Y-%m-%d)}}}.
\newpage
****** Discussion
Expect immune infiltrate at > 1 week supercite:colman2015
****** References                                                    :ignore:
\printbibliography
****** External files
***** ATAC-seq peak calling and chromatin accessibility run 1 for PCAs
Error in env[[as.character(i)]] <- value :
  wrong args for environment subassignment
Calls: regionCounts ... bploop -> bploop.iterate -> <Anonymous> -> add_inorder
Execution halted


install.packages("tidyverse")
library(tidyverse)

- base rscript
  #+begin_src R :noweb yes :tangle ./workflow/scripts/csaw_peak.R

#############################################################################
###              Script for csaw ATAC-seq local peak calling
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
threads = args[4]
background_rds = args[5]
counts_rds = args[6]

filt_libs = unlist(strsplit(filt_libs_str, " "))

library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)
names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))
bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

dimnames(wider) = c()
dimnames(counts) = c()

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

colnames(filtered_counts) = names(bam_list)

saveRDS(object = filtered_counts,
file = counts_rds)

colnames(background) = names(bam_list)

saveRDS(object = background,
file = background_rds)
#+end_src
- [X] run test
  #+begin_src bash
lib_str="lib001 lib002"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
        "_regfilt_tn5.bam$" \
        "${lib_str}" \
        8 \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_background_counts.rds \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_counts.rds
#+end_src
- [X] run for open
  #+begin_src bash
lib_str="lib001 lib002 lib003 lib004 lib005 lib006 lib007 lib008 lib009 lib010 lib011 lib012 lib013 lib015 lib016 lib017 lib018 lib019 lib020 lib021 lib022 lib023 lib024 lib025"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
        "_open_tn5.bam$" \
        "${lib_str}" \
        4 \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_open_background_counts.rds \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_open_counts.rds
#+end_src
- [-] run for full
  #+begin_src bash
lib_str="lib001 lib002 lib003 lib004 lib005 lib006 lib007 lib008 lib009 lib010 lib011 lib012 lib013 lib015 lib016 lib017 lib018 lib019 lib020 lib021 lib022 lib023 lib024 lib025"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
        "_regfilt_tn5.bam$" \
        "${lib_str}" \
        8 \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_regfilt_background_counts.rds \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_regfilt_counts.rds
#+end_src



****** Ideas and dev
******* Description                                                  :ignore:
ATAC-seq peaks were counted by /de novo/ enriched local windows using csaw. Peak counts were normalized by the trimmed mean of M values method in EdgeR. Normalized peak counts were used to test differential chromatin accessibility in EdgeR.

Peaks were annotated from the UCSC mm10 ensGene table using ChIPseeker.

******* ATAC-seq peak calling and chromatin accessibility, 6wks
******** [[file:workflow/peak_calling.smk][Snakefile]]         :smk:noexport:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/peak_calling.smk
:END:
********* Smk preamble
#+begin_src snakemake :noweb yes
<<smk_preamble>>
#+end_src
********* All rule
#+begin_src snakemake
rule all:
    input:
        config["data_dir"] + "/atac/bk_rse.rds",
        config["data_dir"] + "/atac/counts_rse.rds",
#+end_src

********* TEST Make peak counts                                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-03-11 Fri 12:20]
:END:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    params:
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = {lib_str}

        expand(config["data_dir"] + "/atac/bam/{library_id}.bam", library_id=RUNSAMPLES),

        lib_str = config["IR48H_V_SHAM"],
        script = config["repo"] + "/workflow/scripts/make_peak_counts.R",
    output:
        background_counts = config["data_dir"] + "/atac/{c}background_counts_rse.rds"
        counts_rse = config["data_dir"] + "/atac/counts_rse.rds"
    log:
        config["data_dir"] + "/logs/make_peak_counts.log",
    shell:
        """
        lib_str="{params.lib_str}"
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        "${{lib_str}}" \
        {config.threads} \
        {output.background_counts} \
        {output.counts_rse} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/select_window_size.R][Base script]]


********* TEST Make peak counts                                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-03-11 Fri 12:20]
:END:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    params:
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
        script = config["repo"] + "/workflow/scripts/make_peak_counts.R",
    output:
        background_counts = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rse = config["data_dir"] + "/atac/counts_rse.rds"
	window_size = config["data_dir"] + "/atac/window_size.rds",
    log:
        config["data_dir"] + "/logs/make_peak_counts.log",
    shell:
        """
        lib_str="{params.lib_str}"
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        "${{lib_str}}" \
        {config.threads} \
        {output.background_counts} \
        {output.counts_rse} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/select_window_size.R][Base script]]
  #+begin_src R :noweb yes
<<r_smk_preamble>>

#############################################################################
###              Script for csaw ATAC-seq local peak calling
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
threads = args[4]
background_rds = args[5]
rse_rds = args[6]

filt_libs = unlist(strsplit(filt_libs_str, " "))

library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)
names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))
bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

saveRDS(object = filtered_counts,
file = counts_rds)

saveRDS(object = background,
file = background_rds)
#+end_src
********* TEST Differential accessibility                          :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/differential_accessibility.R
<<r_smk_preamble>>
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to generate differential accessibility model with EdgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
load(data_model)
background = readRDS(background_rds)

counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design <- model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src
********* TEST Peak annotation                                     :smk_rule:
- Snakemake
  #+begin_src snakemake
rule peak_annotation:
    input:
        config["data_dir"] + "/atac/dca.rds"
    params:
        script = config["repo"] + "/workflow/scripts/peak_annotation.R"
    output:
        annotated_counts = config["data_dir"] + "/atac/annotated_counts.rds",
    log:
        config["data_dir"] + "/logs/peak_annotation.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output.annot} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/peak_annotation.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/peak_annotation.R
<<r_smk_preabmle>>

#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to annotate csaw peaks   ###
###

args = commandArgs(trailingOnly = TRUE)
peaks_rds = args[1]
annotation_file = args[2]

peaks = readRDS(peaks_rds)

library(ChIPseeker)
library(csaw)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
library(tidyverse)

txdb = TxDb.Mmusculus.UCSC.mm10.ensGene

peak_loc = peaks

chipseek = annotatePeak(peak_loc, TxDb = txdb, annoDb = "org.Mm.eg.db")

annotation = as_tibble(as.data.frame(chipseek))

write.csv(annotation, row.names = F, file = annotation_file)
#+end_src
********* Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
********* Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
********** Make backgroud bins                                     :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_backgroud_bins:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/make_backgroud_bins.R"
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
    output:
    log:
        config["data_dir"] + "/logs/make_backgroud_bins.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_backgroud_bins.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_backgroud_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to make background bins for csaw TMM normalization   ###
###

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
window_file =  args[1]
bam_dir = args[2]
bam_pattern = args[3]
filt_libs_str = args[4]
rse = args[4]
bk = args[5]

filt_libs = unlist(strsplit(filt_libs_str, " "))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

#+end_src
********** d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src

*********** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./workflow/scripts/edger.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/edger.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src

******** Description                                                 :ignore:
ATAC-seq peaks were counted by /de novo/ enriched local windows using csaw. Peak counts were normalized by the trimmed mean of M values method in EdgeR. Normalized peak counts were used to test differential chromatin accessibility in EdgeR.

Peaks were annotated from the UCSC mm10 ensGene table using ChIPseeker.


***** All count logcpms for QC
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-03-31 Thu 14:24]
:END:

- [X] Functions and test
  #+begin_src R :tangle ./workflow/scripts/counts_to_logcpm.R
args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
logcpm_file = args[3]

background = readRDS(background_rds)
counts = readRDS(counts_rds)

library(csaw)
library(edgeR)
library(tidyverse)

counts = normFactors(background, se.out = counts)

make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm = make_logcpm(counts)

saveRDS(object = logcpm,
        file = logcpm_file)
#+end_src
  #+begin_src bash
Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/counts_to_logcpm.R \
	/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_counts.rds \
	/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_background_counts.rds \
	/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_logcpm.rds
#+end_src

- All sample PCA
  #+begin_src bash

#+end_src
- Filtered PCA
- Reference
  - PCA of mislabeled samples
    #+begin_src R
  load("/mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48_v_sham_tmp.rdata")

  load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

  participants$cohort_id[which(participants$part_id == "ms015")] = "ir48h"

  libraries_full$cohort_id[which(libraries_full$library_id == "lib009")] = "ir48h"

  libraries_full$cohort_id[which(libraries_full$library_id == "lib016")] = "sham"

  library(csaw)

  make_logcpm = function(in_norm){
    dge = asDGEList(in_norm)
    colnames(dge) = colnames(in_norm)
    log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
    return(log_cpm)
  }

  logcpm = make_logcpm(filtered_counts)

  pca = prcomp(t(logcpm))
  summary(pca)

  library(tidyverse)
  library(ggrepel)

  make_pca_plots = function(in_pca, full_libs){
    pve_pc1=round(100*summary(in_pca)$importance[2,1])
    pve_pc2=round(100*summary(in_pca)$importance[2,2])

    pca_plot = as.data.frame(in_pca$x) %>%
      rownames_to_column(var = "library_id") %>%
      left_join(full_libs, by = "library_id") %>%
      ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
      geom_point(size = 4) +
      geom_text_repel() +
      xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
      ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
      guides(color="none")
    return(pca_plot)
  }



  test =make_pca_plots(pca, libraries_full)


  in_pca = pca
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(libraries_full, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel(force = 10) +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")


  ggsave(pca_plot, filename = "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/pca2.pdf")

  ggsave(pca_plot, filename = "~/repos/cardradbio-atac/results/imgs/ir48h_v_sham_full_pca.pdf")
  #+end_src

***** Read processing and alignment
****** Description                                                   :ignore:
Sequencing read adapters were removed and reads were quality trimmed using flexbar.

Processed reads were aligned to mm10 using bowtie2.

PCR duplicate reads were removed using samtools. Reads were then filtered and processed for ATAC-seq analysis as follows. Only paired reads aligning to mm10 autosomes were retained. Read pairs were also removed if they overlapped known problematic regions from the ENCODE blacklist supercite:amemiya2019. Finally, alignments were shifted on the forward strand by +4 bp and on the reverse strand by âˆ’5 bp to account for the 9-bp duplication introduced by Tn5.


****** DONE [[file:workflow/preprocess_align.smk][Snakefile]]           :smk:
CLOSED: [2022-03-11 Fri 12:19]
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/preprocess_align.smk
:CUSTOM_ID: readp
:END:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-03-11 Fri 12:19]
:END:
******* Smk preamble
#+begin_src snakemake
container: config["container"]
RUNSAMPLES =  ["lib001", "lib002", "lib003", "lib004", "lib005", "lib006", "lib007", "lib008", "lib009", "lib010", "lib011", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib024", "lib025"]
#+end_src
******* Smk rules
******** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["data_dir"] + "/atac/bam/{library_id}.bam", library_id=RUNSAMPLES),
        config["data_dir"] + "/ref/keep.bed",
        expand(config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/atac/bam/{library_id}_open.bam", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/atac/bam/{library_id}_regfilt_tn5.bam", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/atac/bam/{library_id}_open_tn5.bam", library_id=RUNSAMPLES),
#+end_src
******** Read trim                                                 :smk_rule:
- Snakemake
  #+begin_src snakemake
rule read_trim:
    input:
        r1 = config["data_dir"] + "/atac/fastq/{library_id}_R1.fastq.gz",
        r2 = config["data_dir"] + "/atac/fastq/{library_id}_R2.fastq.gz",
    params:
        outdir = config["data_dir"] + "/atac/fastq",
        threads = config["threads"],
    output:
        config["data_dir"] + "/atac/fastq/{library_id}_flex_1.fastq.gz",
        config["data_dir"] + "/atac/fastq/{library_id}_flex_2.fastq.gz",
    resources:
        mem_mb=5000
    shell:
        """
        workflow/scripts/read_trim.sh {input.r1} {input.r2} {params.outdir} {params.threads}
        """
#+end_src
- Script [[file:workflow/scripts/read_trim.sh]]
  #+begin_src bash :noweb yes :tangle ./workflow/scripts/read_trim.sh
#########1#########2#########3#########4#########5#########6#########7#########8
#
# Function for flexbar processing
flexbar_atac() {
    base=$(basename -s _R1.fastq.gz $1)
    flexbar \
        --adapter-pair-overlap ON \
        --adapter-preset Nextera \
        --pre-trim-right 1 \
        --reads "${1}" \
        --reads2 "${2}" \
        --target "${3}/${base}_flex" \
        --threads ${4} \
        --zip-output GZ
}

# Snakemake parameters
input_r1="$1"
input_r2="$2"
params_outdir="$3"
params_threads="$4"

# Run
flexbar_atac "${input_r1}" "${input_r2}" "${params_outdir}" "${params_threads}"
#+end_src
******** Make bowtie index                                         :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_bowtie_index:
    input:
        fa = config["data_dir"] + "/ref/mm10.fa",
    params:
        prefix = config["data_dir"] + "/ref/ucsc_mm10_bt2/ucsc_mm10_bt2",
        threads = config["threads"]
    output:
        config["data_dir"] + "/ref/ucsc_mm10_bt2/ucsc_mm10_bt2.1.bt2",
    shell:
        """
        workflow/scripts/make_bowtie_index.sh {input.fa} {params.prefix} {params.threads}
        """
#+end_src
- [[file:./workflow/scripts/make_bowtie_index.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/make_bowtie_index.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function
make_bt2_index(){
    index_dir=$(dirname $3)
    mkdir -p $index_dir
    bowtie2-build -f \
                  --threads $1 \
                  $2 \
                  $3
}

# Snakemake variables
input_fa="$1"
params_prefix="$2"
params_threads="$3"

# Run
make_bt2_index $params_threads $input_fa $params_prefix
#+end_src
******** Align BT2                                                 :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2021-12-23 Thu 12:41]
:END:
- Snakemake
  #+begin_src snakemake
rule align_bt2:
    input:
        r1 = config["data_dir"] + "/atac/fastq/{library_id}_flex_1.fastq.gz",
        r2 = config["data_dir"] + "/atac/fastq/{library_id}_flex_2.fastq.gz",
    params:
        prefix = config["data_dir"] + "/ref/ucsc_mm10_bt2/ucsc_mm10_bt2",
        threads = config["threads"],
    output:
        bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
    shell:
        """
        workflow/scripts/align_bt2.sh {input.r1} {input.r2} {params.prefix} {params.threads} {output.bam}
        """
#+end_src
- [[file:./workflow/scripts/align_bt2.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/align_bt2.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function
bt2_align(){
    bowtie2 --maxins 2000 --threads $1 --very-sensitive -x $2 -1 $3 -2 $4 | samtools view -bS - > $5
}

# Snakemake variables
input_r1="$1"
input_r2="$2"
params_prefix="$3"
params_threads="$4"
output_bam="$5"

# Run
bt2_align "$params_threads" "$params_prefix" "$input_r1" "$input_r2" "$output_bam"
#+end_src
******** Make keep bed                                             :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_keep_bed:
    input:
        autosome_bed = config["data_dir"] + "/ref/grcm38_primary_assembly_chr.bed",
        blacklist_bed = config["data_dir"] + "/ref/mm10-blacklist.v2_ENSEMBL_chr.bed",
    output:
        keep_bed = config["data_dir"] + "/ref/keep.bed",
    shell:
        """
        bedtools subtract -a {input.autosome_bed} -b {input.blacklist_bed} > {output.keep_bed}
        """
#+end_src
******** Filter and dedup                                          :smk_rule:
- Snakemake
  #+begin_src snakemake
rule filter_and_dedup:
    input:
        bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
    params:
        keep_bed = config["data_dir"] + "/ref/keep.bed",
        threads = config["threads"],
    output:
        dedup_bam = config["data_dir"] + "/atac/bam/{library_id}_dedup.bam",
        qfilt_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_qfilt.bam"),
        regfilt_bam = config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam",
        regfilt_index = config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam.bai",
    resources:
        mem_mb=5000
    shell:
        """
        workflow/scripts/filter_and_dedup.sh {input.bam} \
	                                     {params.keep_bed} \
	                                     {params.threads} \
	                                     {output.dedup_bam} \
	                                     {output.qfilt_bam} \
	                                     {output.regfilt_bam}
        """
#+end_src
- [[file:./workflow/scripts/filter_and_dedup.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/filter_and_dedup.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function

atac_bam_processing(){
    #
    # Dedup
    samtools sort -@ $1 -n -o - $2 |
    samtools fixmate -m - - |
    samtools sort -@ $1 -o - - |
    samtools markdup -@ $1 -r - $3
    #
    # Filter to aligned, properly paired reads
    samtools view -@ $1 -b -f 3 -h -o $4 $3
    #
    # Filter to autosomes and remove blacklisted regions
    samtools view -@ $1 -b -h -L $5 -o - $4 |
    samtools sort -@ $1 -n -o - - |
    samtools fixmate -m - - |
    samtools sort -@ $1 -o $6 -
    samtools index $6
}

# Snakemake variables
input_bam="$1"
params_keep_bed="$2"
params_threads="$3"
output_dedup_bam="$4"
output_qfilt_bam="$5"
output_regfilt_bam="$6"

# Run command
atac_bam_processing "$params_threads" \
                    "$input_bam" \
                    "$output_dedup_bam" \
                    "$output_qfilt_bam" \
                    "$params_keep_bed" \
                    "$output_regfilt_bam"
samtools index "$output_regfilt_bam"
#+end_src
******** Get open chrom                                            :smk_rule:
- Snakemake
  #+begin_src snakemake
rule get_open_chrom:
    input:
        regfilt_bam = config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam",
    output:
        unsort_open_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_unsort_open.bam"),
        open_bam = config["data_dir"] + "/atac/bam/{library_id}_open.bam",
    shell:
        """
        workflow/scripts/get_open_chrom.sh {input.regfilt_bam} \
                                           {config[threads]} \
                                           {output.unsort_open_bam} \
                                           {output.open_bam}
        """
#+end_src
- [[file:./workflow/scripts/get_open_chrom.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/get_open_chrom.sh
#########1#########2#########3#########4#########5#########6#########7#########8
alignmentSieve --bam $1 \
               --maxFragmentLength 150 \
               --numberOfProcessors $2 \
               --outFile $3
samtools sort -@ $2 -o $4 $3
samtools index -@ $2 $4
#+end_src
******** Tn5 shift                                                 :smk_rule:
:LOGBOOK:
- State "DONE"       from "DELEGATED"  [2022-02-11 Fri 16:40]
- State "DONE"       from "CLOSEOUT"   [2022-02-11 Fri 16:40]
- State "DONE"       from "RUN"        [2022-02-11 Fri 16:40]
- State "WAITING"    from "TODO"       [2022-01-06 Thu 09:09] \\
  add to next run
:END:
- Snakemake
  #+begin_src snakemake
rule tn5_shift_and_open:
    input:
        atac_bam =         config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam",
    output:
        tmp_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_regfilt_tmp.bam"),
        tn5_bam =      config["data_dir"] + "/atac/bam/{library_id}_regfilt_tn5.bam",
    log:
        config["data_dir"] + "/logs/tn5_shift_and_open_{library_id}_regfilt.log",
    shell:
        """
        workflow/scripts/tn5_shift.sh {input.atac_bam} \
	                              {config[threads]} \
	                              {output.tmp_bam} \
                                      {output.tn5_bam} > {log} 2>&1
        """
#+end_src
- [[file:./workflow/scripts/todo_tn5_shift.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/tn5_shift.sh
alignmentSieve --ATACshift --bam "$1" --numberOfProcessors $2 --outFile "$3"

samtools sort -@ $2 -o $4 $3

samtools index -@ $2 $4
#+end_src
******** Tn5 open shift                                            :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-01-06 Thu 09:09] \\
  add to next run
:END:
- Snakemake
  #+begin_src snakemake
rule tn5_shift_open:
    input:
        atac_bam =         config["data_dir"] + "/atac/bam/{library_id}_open.bam",
    output:
        tmp_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_open_tmp.bam"),
        tn5_bam =      config["data_dir"] + "/atac/bam/{library_id}_open_tn5.bam",
    log:
        config["data_dir"] + "/logs/tn5_shift_and_open_{library_id}_open.log",
    shell:
        """
        workflow/scripts/tn5_shift.sh {input.atac_bam} \
	                              {config[threads]} \
	                              {output.tmp_bam} \
                                      {output.tn5_bam} > {log} 2>&1
        """
#+end_src
- [[file:./workflow/scripts/todo_tn5_shift.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/tn5_shift.sh
alignmentSieve --ATACshift --bam "$1" --numberOfProcessors $2 --outFile "$3"

samtools sort -@ $2 -o $4 $3

samtools index -@ $2 $4
#+end_src

******* Ideas
- redefine samtools tmp dir outside repo




**** Motif analysis
- Get gene list- Takes annotated edger results as table
  #+begin_src R
library(tidyverse)
test = as_tibble(read.csv("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_de.csv", header = T))

motifs_down_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC < 0) %>%
  pull(geneId)

motifs_up_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC > 0) %>%
  pull(geneId)

writeLines(as.character(motifs_down_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt")
writeLines(as.character(motifs_up_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_up.txt")

#+end_src

- Find motifs
  #+begin_src bash
mkdir -p /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/

nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/ -fdr 10 -p 12

# try



Number of CPUs to use ("-p <#>", default 1)
HOMER is now multicore compliant.  It's not perfectly parallelized, however, certain types of analysis can benefit.  In general, the longer the length of the motif, the better the speed-up you'll see.

Number of motifs to find ("-S <#>", default 25)
Specifies the number of motifs of each length to find.  25 is already quite a bit.  If anything, I'd recommend reducing this number, particularly for long motifs to reduce the total execution time.
perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src

- Extract gene names
  #+begin_src bash

#+end_src


***** Snakefile                                                :smk:noexport:
:PROPERTIES:
:header-args:snakemake:  :tangle ./workflow/motifs.smk
:END:
****** Smk preamble
#+begin_src snakemake :noweb yes
<<smk_preamble>>
#+end_src
****** All rule
#+begin_src snakemake
rule all:
    input:
#+end_src
****** Extract gene list                                           :smk_rule:

extract ensembl ID lists from csaw-EdgeR DCA workflow

- Snakemake
  #+begin_src snakemake
rule extract_gene_list:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/extract_gene_list.R"
    output:
    log:
        config["data_dir"] + "/logs/extract_gene_list.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/extract_gene_list.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/extract_gene_list.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###    SCRIPT TITLE   ###
###

args = commandArgs(trailingOnly = TRUE)
dca_tbl = args[1]

#+end_src
****** Find motifs for gene list promoters
#+begin_src bash
#nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/ -fdr 10 -p 12

findMotifs.pl test/homer/open_48hr-sham_down_genelist.txt \
              mouse \
              test/homer/open_ir48h-sham_less -fdr10 -p 4

#+end_src
- Find motifs by gene list
  #+begin_src bash
# TODO install homer w/ mouse-p promoter set

source ~/repos/cardradbio-atac/config/${HOSTNAME}.sh

# Fake gene list from peak annotation output, is ensembl IDs
#

# Install mouse homer promotor set
perl /home/jeszyman/homer/.//configureHomer.pl -install mouse-p

mkdir -p /tmp/out

findMotifs.pl /tmp/test.txt mouse /tmp/out

perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src
***** Description                                                    :ignore:
**** [[file:workflow/dca_and_annot.smk][Differential chromatin accessibility and annotation]]                :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/dca_and_annot.smk
:END:
:LOGBOOK:
- State "WAITING"    from "TEST"       [2022-03-31 Thu 14:33]
:END:
# Latest deepTools on bioconda does not contain alignmentSieve
RUN conda install -c bioconda deeptools=3.4 --force

***** Differential chromatin accessibility
- Snakemake
  #+begin_src snakemake
rule diff_chrom_accessibility:
    input:
        dge = config["data_dir"] + "/csaw/dge_{bam_process}.rds",
        norm_counts_rse = config["data_dir"] + "/csaw/norm_counts_rse_{bam_process}.rds",
    params:
        groups_str = "ir48h ir48h sham sham",
        contrast = "ir48h-sham",
        script = config["atac_scripts_dir"] + "/diff_chrom_accessibility.R",
    output:
        config["data_dir"] + "/dca/dca_granges_{bam_process}.rds"
    log:
        config["log_dir"] + "/diff_chrom_accessibility_{bam_process}.log",
    shell:
        """
        Rscript {params.script} \
        {input.dge} \
        "{params.groups_str}" \
        "{params.contrast}" \
        {input.norm_counts_rse} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:workflow/scripts/diff_chrom_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/diff_chrom_accessibility.R

#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
###   Script to generate differential accessibility model with EdgeR         ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8

# Setup

## Arguements for testing
dge_rds = "~/repos/atac-seq/test/csaw/dge_regfilt.rds"
groups_str = "ir48h ir48h sham sham"
contrast = "ir48h-sham"
norm_counts_rds = "~/repos/atac-seq/test/csaw/norm_counts_rse_regfilt.rds"
dca_granges_rds = "/tmp/test.rds"

args = commandArgs(trailingOnly = TRUE)
dge_rds = args[1]
groups_str =args [2]
contrast = args[3]
norm_counts_rds = args[4]
dca_granges_rds = args[5]

library(csaw)
library(edgeR)
library(tidyverse)

y = readRDS(dge_rds)
groups = as.factor(unlist(strsplit(groups_str, " ")))

design = model.matrix(~0 + groups, data=y$samples)
colnames(design) = levels(groups)
y = estimateDisp(y, design)
fit = glmQLFit(y, design, robust=TRUE)
results = glmQLFTest(fit, contrast=makeContrasts(contrast, levels=design))

# combine GRanges rowdata with DA statistics
counts = readRDS(norm_counts_rds)
rowData(counts) = cbind(rowData(counts), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best = getBestTest(merged.peaks$id, results$table)

# combine merged peaks window range with statistics
final.merged.peaks = merged.peaks$region
final.merged.peaks@elementMetadata = cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks = final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_granges_rds)

#+end_src
***** Peak annotation                                              :smk_rule:
- Snakemake
  #+begin_src snakemake
rule peak_annotation:
    input:
        config["data_dir"] + "/dca/dca_granges_{bam_process}.rds",
    params:
        script = config["atac_scripts_dir"] + "/peak_annotation.R"
    output:
        csv = config["data_dir"] + "/dca/{bam_process}_dca.csv",
        chipseek = config["data_dir"] + "/dca/{bam_process}_chipseek.rds"
    log:
        config["data_dir"] + "/logs/{bam_process}_peak_annotation.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output.csv} \
        {output.chipseek} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :tangle ./workflow/scripts/peak_annotation.R
# Arguements for testing
## granges_rds = "/home/jeszyman/repos/atac-seq/test/dca/dca_granges_regfilt.rds"
## annotation_csv = "/home/jeszyman/repos/atac-seq/test/dca/regfilt_dca.csv"
## chipseek_file = "/home/jeszyman/repos/atac-seq/test/dca/regfilt_chipseek.rds"

# Arguements for command line input
args = commandArgs(trailingOnly = TRUE)
granges_rds = args[1]
annotation_csv = args[2]
chipseek_file = args[3]

peaks = readRDS(granges_rds)

library(ChIPseeker)
library(csaw)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
library(tidyverse)

txdb = TxDb.Mmusculus.UCSC.mm10.ensGene

chipseek = annotatePeak(peaks, TxDb = txdb, annoDb = "org.Mm.eg.db")

annotation = as_tibble(as.data.frame(chipseek))

write.csv(annotation, row.names = F, file = annotation_csv)

saveRDS(object = chipseek,
        file = chipseek_file)
#+end_src
- Reference
  - https://bioconductor.org/packages/release/bioc/vignettes/ChIPseeker/inst/doc/ChIPseeker.html#peak-annotation
**** Update via biopipe mod
*** [[file:workflow/int_test_peaks.smk][Peak calling and differential accessibility]]
#+begin_src snakemake :tangle ./workflow/int_test_peaks.smk


rule all:
    input:


#+end_src

#+begin_src snakemake :tangle ./workflow/int_test_peaks.smk
container: config["container"]

MACS_BROAD_EXT = ["peaks.broadPeak", "peaks.gappedPeak", "peaks.xls"]

MACS_NARROW_EXT = ["peaks.narrowPeak", "summits.bed"]

LIBRARY_IDS = ["atac1","atac2","atac3","atac4"]

BAM_PROCESS = ["regfilt", "open"]

rule all:
    input:
        expand(config["data_dir"] + "/macs2/{library_id}_{bam_process}_{macs_broad}", library_id = LIBRARY_IDS, bam_process = ["open", "regfilt"], macs_broad = MACS_BROAD_EXT),
        expand(config["data_dir"] + "/macs2/{library_id}_{bam_process}_{macs_narrow}", library_id = LIBRARY_IDS, bam_process = ["open", "regfilt"], macs_narrow = MACS_NARROW_EXT),
        expand(config["data_dir"] + "/csaw/background_counts_all_{bam_process}_rse.rds", bam_process = BAM_PROCESS),
        expand(config["data_dir"] + "/csaw/counts_all_{bam_process}_rse.rds", bam_process = BAM_PROCESS),

include: "peak_call_and_dif.smk"
#+end_src


*** [[file:workflow/peak_call_and_norm.smk][Peak calling and normalization]]                                      :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/peak_call_and_norm.smk
:END:
**** DONE Call MACS2 narrow                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_macs2_narrow:
    input:
        config["data_dir"] + "/bam/{library_id}_{bam_process}_tn5.bam",
    output:
        expand(config["data_dir"] + "/macs2/{{library_id}}_{{bam_process}}_{ext}", ext = MACS_NARROW_EXT)
    shell:
        """
        base=$(echo $(basename {input}) | sed 's/_tn5.*$//g')
        workflow/scripts/call_macs2_narrow.sh {input} ${{base}} "{config[data_dir]}/macs2"
        """
#+end_src
- Script
  #+begin_src bash :tangle ./workflow/scripts/call_macs2_narrow.sh
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8
# Check for parameters, return usage if empty
if [[ "$#" -ne 3 ]];
then
    printf "\n usage: call_macs2_broad <BAM FILE> <OUTPUT BASENAME> <OUTPUT DIRECTORY>
    \n Wrapper function for calling broad beaks from ATAC-seq data with MACS2
    \n "
elif
    [[ ! -f "${1}.bai" ]]; then echo "No index for $1"
else
    macs2 callpeak \
          --bdg \
          --call-summits \
          --extsize 150 \
          --format BAMPE \
          --gsize mm \
          --keep-dup all \
          --name $2 \
          --nolambda \
          --nomodel \
          --outdir $3 \
          --SPMR \
          --treatment $1
fi
#+end_src
**** DONE Call MACS2 broad                                            :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_macs2_broad:
    input:
        config["data_dir"] + "/bam/{library_id}_{bam_process}_tn5.bam",
    output:
        expand(config["data_dir"] + "/macs2/{{library_id}}_{{bam_process}}_{ext}", ext = MACS_BROAD_EXT)
    shell:
        """
        base=$(echo $(basename {input}) | sed 's/_tn5.*$//g')
        workflow/scripts/call_macs2_broad.sh {input} ${{base}} "{config[data_dir]}/macs2"
        """
#+end_src
- [[file:workflow/scripts/call_macs2_broad.sh][Script]]
  #+begin_src bash :tangle ./workflow/scripts/call_macs2_broad.sh
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8
# Check for parameters, return usage if empty
if [[ "$#" -ne 3 ]];
then
    printf "\n usage: call_macs2_broad <BAM FILE> <OUTPUT BASENAME> <OUTPUT DIRECTORY>
    \n Wrapper function for calling broad beaks from ATAC-seq data with MACS2
    \n "
elif
    [[ ! -f "${1}.bai" ]]; then echo "No index for $1"
else
    macs2 callpeak \
          --broad \
          --broad-cutoff 0.05 \
          --format BAMPE \
          --gsize mm \
          --keep-dup all \
          --name $2 \
          --outdir $3 \
          --treatment $1
fi
#+end_src
- Function- Broadpeak as in  cite:corces2018 and cite:hendrickson2017
**** DONE Peak calling, all samples                                   :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    input:
        expand(config["bam_dir"] + "/{library_id}_{{bam_process}}_tn5.bam", library_id = LIBRARY_IDS)
    params:
        script = config["atac_scripts_dir"] + "/select_window_size.R",
	groups_str = "ir48h ir48h sham sham"
    output:
        norm_counts_rse = config["data_dir"] + "/csaw/norm_counts_rse_{bam_process}.rds",
        dge = config["data_dir"] + "/csaw/dge_{bam_process}.rds",
    log:
        config["log_dir"] + "/make_peak_counts_{bam_process}.log",
    shell:
        """
        Rscript {params.script} \
        "{input}" \
        {config[threads]} \
        {output.norm_counts_rse} \
        {output.dge} \
        {params.groups_str} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/select_window_size.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/select_window_size.R

#############################################################################
###            Script for csaw ATAC-seq local peak calling                ###
#############################################################################

# Setup

## Test arguements
## groups_str = "ir48h ir48h sham sham"
## library_ids_str = "/home/jeszyman/repos/atac-seq/test/bam/atac1_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac2_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac3_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac4_open_tn5.bam"
## out_rse_rds = "/home/jeszyman/repos/atac-seq/test/csaw/norm_counts_rse.rds"
## out_dge_rds = "/home/jeszyman/repos/atac-seq/test/csaw/dge.rds"
## threads = 4

## Command line arguements
args = commandArgs(trailingOnly = TRUE)
library_ids_str = args[1]
threads = args[2]
out_rse_rds = args[3]
out_dge_rds = args[4]
groups_str = args[5]

## Load packages
library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

# Specify csaw window parameters
surrounds = 2000
autosomes <- paste0("chr", c(1:19)) # only use autosomes
param = readParam(max.frag=1000, pe="both", restrict=autosomes)

# Make bam file list
bam_list = unlist(strsplit(library_ids_str, " "))
names(bam_list) = gsub("^.*/","",bam_list)

# Filter per Reske JJ, et al. 2021. https://doi.org/10.1186/s13072-020-00342-y

## Choose window width by fragment size distribution
csaw_choose_window = function(bam_list){
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

# Remove dimnames to avoid SummarizedExperiment error in window filtering
dimnames(wider) = NULL
dimnames(counts) = NULL

filter_stat = filterWindowsLocal(counts, wider, assay.data = "counts")

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

# Return library names
colnames(filtered_counts) = names(bam_list)
colnames(background) = names(bam_list)

filtered_counts = normFactors(background, se.out = filtered_counts)

y = asDGEList(filtered_counts)
colnames(y$counts) = colnames(filtered_counts)
rownames(y$samples) = colnames(filtered_counts)

groups = as.factor(unlist(strsplit(groups_str, " ")))
y$samples$group = groups

# Save outputs
saveRDS(object = filtered_counts,
        file = out_rse_rds)
saveRDS(object = y,
        file = out_dge_rds)
#+end_src
**** DONE Percent of genome open
- Snakemake
  #+begin_src snakemake
rule open_genome:
    input:
        config["data_dir"] + "/bam/{library_id}_open_tn5.bam",
    params:
        genome_bed = "resources/mm10.bed",
    output:
        config["data_dir"] + "/open_chrom/{library_id}_open_chrom.txt"
    shell:
        """
        bedmap --echo --bases-uniq --delim '\t' {params.genome_bed} {input} | awk 'BEGIN {{ genome_length = 0; masked_length = 0; }} {{ genome_length += ($3 - $2); masked_length += $4; }} END {{ print (masked_length / genome_length); }}' > {output}
        """
#+end_src
- https://www.biostars.org/p/219099/
  #+begin_src bash
singularity shell --help
singularity shell --bind /mnt/:/mnt/ ~/sing_containers/atac.sif

fract(){
    bedmap --echo --bases-uniq --delim '\t' ~/repos/atac-seq/resources/mm10.bed $1 | awk 'BEGIN { genome_length = 0; masked_length = 0; } { genome_length += ($3 - $2); masked_length += $4; } END { print (masked_length / genome_length); }'
}

if [ -f /mnt/ris/jschwarz/cardiac-radiobiology/atac/fract_open.txt ]; then
    \rm -rf /mnt/ris/jschwarz/cardiac-radiobiology/atac/fract_open.txt
fi

touch /mnt/ris/jschwarz/cardiac-radiobiology/atac/fract_open.txt

for file in /mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2/lib*open*narrowPeak; do
    echo "$(basename $file) $(fract $file)" >> /mnt/ris/jschwarz/cardiac-radiobiology/atac/fract_open.txt
done

head /mnt/ris/jschwarz/cardiac-radiobiology/atac/frac_open.txt

cp /mnt/ris/jschwarz/cardiac-radiobiology/atac/frac_open.txt
#+end_src
*** Development                                                         :dev:
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
do this one as agg rule
bamfile.labels <- gsub(".bam", "", basename(bamfile))
fragSize = fragSizeDist(bamfile, bamfile.labels)
fragsize = data.frame(len=, cnt


**** TODO MultiQC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule multiqc:
    input:
    output:
    shell:
        """
        scripts/multiqc.sh
        """
#+end_src
- [[file:./workflow/scripts/multiqc.sh][Base script]]
  #+begin_src bash
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

# Snakemake variables
# Function
# Run command
#########1#########2#########3#########4#########5#########6#########7#########8
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

#+end_src
** README
currently only for mouse for macs2
*** Prerequisites to run repository local integration testing
- Singularity container built from https://github.com/jeszyman/atac-seq/blob/master/config/atac_Dockerfile
- Local snakemake
- Local snakemake configuration YAML
*** Changelog
- [2022-08-29 Mon] Initial pre-processing, peak calling, and normalization validated.
** Reference
- [[https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt][reske csaw workflow]]
- [[id:271b4d5f-727e-496e-b835-8fe9f8655655][biopipe module]]
- [[id:22e31d06-f5df-427e-bd70-3a2ccd3f47ec][ATAC-seq]]
