* ATAC-seq                                                          :biopipe:
:PROPERTIES:
:header-args:bash: :tangle-mode (identity #o555)
:header-args:snakemake: :tangle-mode (identity #o555)
:header-args+h: :noweb yes
:logging: nil
:ID:       55813fe4-d3bb-476e-a021-141bf02efadc
:END:
** Setup
*** Bash preamble
#+name: bash_preamble
#+begin_src bash

#  Note: This script is tangled from code blocks in the Emacs Org-mode file at
#  https://github.com/jeszyman/atac-seq/blob/master/atac-seq.org. Changes
#  made directly to this file will be overwritten upon tangle from Org-mode.

#+end_src
*** [[id:57458bd3-005f-4342-ada7-58c55a74d7d0][ATAC-seq docker]]
*** Integration testing Snakemake YAML
:PROPERTIES:
:header-args:bash: :tangle ./config/int_test.yaml
:END:
#+begin_src bash

# Common names across repositories and snakefiles
datadir: "test"
fasta: "test/inputs/chr19.fa"
logdir: "test/logs"
threads: 4

# Repository and snakefile-specific names
container:
  atac: "~/sing_containers/atac.1.1.0.sif"
scriptdir:
  atac: "workflow/scripts"

keep_bed: "resources/keep.bed"

gtf: "test/inputs/chr19.gtf"
#+end_src
*** Integration testing inputs setup
- Sample sheet
  | library | basename          |
  |---------+-------------------|
  | lib001  | atac1_R1.fastq.gz |
  | lib002  | atac2_R1.fastq.gz |
  | lib003  | atac3_R1.fastq.gz |
  | lib004  | atac4_R1.fastq.gz |
- Make reference fasta from mm10 chr 19
  #+begin_src bash
mkdir -p "test/inputs"

wget --directory-prefix="test/inputs/" "https://hgdownload.soe.ucsc.edu/goldenPath/mm10/chromosomes/chr19.fa.gz"

zcat "test/inputs/chr9.fa.gz" | grep -A 200000 chr9 > test/inputs/chr9.fa

mkdir -p "test/inputs/ucsc_mm10_chr19"

chmod -R 777  "test/inputs/ucsc_mm10_chr19"

singularity shell ~/sing_containers/atac.sif

zcat "test/inputs/chr19.fa.gz" > test/inputs/chr19.fa


\rm /home/jeszyman/repos/atac-seq/test/inputs/chr19.fa

#+end_src
- Make reference gtf
  #+begin_src bash
wget --directory-prefix test/inputs https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/genes/mm10.ensGene.gtf.gz
zcat test/inputs/mm10.ensGene.gtf.gz | grep chr19 > test/inputs/chr19.gtf
\rm test/inputs/mm10.ensGene.gtf.gz
#+end_src
- Make reference chromosome bed file
  https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/mm10.chrom.sizes
  | chr1  | 1 | 195471971 |
  | chr2  | 1 | 182113224 |
  | chr3  | 1 | 160039680 |
  | chr4  | 1 | 156508116 |
  | chr5  | 1 | 151834684 |
  | chr6  | 1 | 149736546 |
  | chr7  | 1 | 145441459 |
  | chr10 | 1 | 130694993 |
  | chr8  | 1 | 129401213 |
  | chr14 | 1 | 124902244 |
  | chr9  | 1 | 124595110 |
  | chr11 | 1 | 122082543 |
  | chr13 | 1 | 120421639 |
  | chr12 | 1 | 120129022 |
  | chr15 | 1 | 104043685 |
  | chr16 | 1 |  98207768 |
  | chr17 | 1 |  94987271 |
  | chr18 | 1 |  90702639 |
  | chr19 | 1 |  61431566 |
- Get sample fastqs
  #+begin_src bash
zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib008_R1.fastq.gz | head -n 1500000 > /home/jeszyman/repos/atac-seq/test/inputs/atac1_R1.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib008_R2.fastq.gz | head -n 1500000 > test/inputs/atac1_R2.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib009_R1.fastq.gz | head -n 1500000 > test/inputs/atac2_R1.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib009_R2.fastq.gz | head -n 1500000 > test/inputs/atac2_R2.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib015_R1.fastq.gz | head -n 1500000 > test/inputs/atac3_R1.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib015_R2.fastq.gz | head -n 1500000 > test/inputs/atac3_R2.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib016_R1.fastq.gz | head -n 1500000 > test/inputs/atac4_R1.fastq

zcat /mnt/ris/jschwarz/cardiac-radiobiology/atac/fastq/lib016_R2.fastq.gz | head -n 1500000 > test/inputs/atac4_R2.fastq

for file in "test/inputs/*.fastq"; do gzip -f $file; done

#+end_src
** ATAC-seq :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/atac.smk
:END:
*** ATAC-seq read processing and alignment
**** Description
Sequencing read adapters were removed and reads were quality trimmed using flexbar.

Processed reads were aligned to mm10 using bowtie2.

PCR duplicate reads were removed using samtools. Reads were then filtered and processed for ATAC-seq analysis as follows. Only paired reads aligning to mm10 autosomes were retained. Read pairs were also removed if they overlapped known problematic regions from the ENCODE blacklist supercite:amemiya2019. Finally, alignments were shifted on the forward strand by +4 bp and on the reverse strand by âˆ’5 bp to account for the 9-bp duplication introduced by Tn5.
**** Read trimming                                                 :smk_rule:
- Snakemake
  #+begin_src snakemake
# Uses flexbar to trim and quality-filter fastq reads
rule trim:
    container:
        atac_container,
    input:
        r1 = atac_fastq_raw + "/{library}_R1.fastq.gz",
        r2 = atac_fastq_raw + "/{library}_R2.fastq.gz",
    log:
        config["logdir"] + "/{library}_atac_trim.log",
    output:
        atac_fastq_proc + "/{library}_flex_1.fastq.gz",
        atac_fastq_proc + "/{library}_flex_2.fastq.gz",
    params:
        outdir = atac_fastq_proc,
        script = config["scriptdir"]["atac"] + "/trim.sh",
        threads = config["threads"],
    resources:
        mem_mb=5000,
    shell:
        """
        {params.script} \
        {input.r1} \
        {input.r2} \
        {params.outdir} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:./workflow/scripts/trim.sh][Shell script]]
  #+begin_src bash :tangle ./workflow/scripts/trim.sh
#!/usr/bin/env bash

# Function for flexbar processing
flexbar_atac() {
    base=$(basename -s _R1.fastq.gz $1)
    flexbar \
        --adapter-pair-overlap ON \
        --adapter-preset Nextera \
        --pre-trim-right 1 \
        --reads "${1}" \
        --reads2 "${2}" \
        --target "${3}/${base}_flex" \
        --threads ${4} \
        --zip-output GZ
}

# Snakemake parameters
input_r1="$1"
input_r2="$2"
params_outdir="$3"
params_threads="$4"

# Run
flexbar_atac "${input_r1}" "${input_r2}" "${params_outdir}" "${params_threads}"

#+end_src
**** DONE Make bowtie2 index                                          :smk_rule:
- Snakemake
  #+begin_src snakemake
# Make bowtie2 index
rule atac_index:
    input:
        config["fasta"]
    params:
        base = atac_bowtie2_index,
        script = config["scriptdir"]["atac"] + "/index.sh",
    output:
        directory(atac_bowtie2_dir),
	atac_bowtie2_index + ".1.bt2",
    log:
        config["logdir"] + "/atac_index.log",
    container:
        atac_container,
    shell:
        """
        {params.script} \
        {input} \
        {params.base} \
        {output} &> {log}
        """
#+end_src
- [[file:./workflow/scripts/index.sh][Shell script]]
  #+begin_src bash :tangle ./workflow/scripts/index.sh
#!/usr/bin/env bash
reference=$1
bt2_index_base=$2
output=$3

mkdir -p $output
bowtie2-build \
    $reference \
    $bt2_index_base

#+end_src

**** DONE Align trimmed reads using bowtie2                           :smk_rule:
- Snakemake
  #+begin_src snakemake
rule align_bt2:
    container:
        atac_container,
    input:
        r1 = atac_fastq_proc + "/{library}_flex_1.fastq.gz",
        r2 = atac_fastq_proc + "/{library}_flex_2.fastq.gz",
        index = atac_bowtie2_index + ".1.bt2",
    log:
        config["logdir"] + "/{library}_align_bt2.log",
    params:
        prefix = atac_bowtie2_index,
        script = config["scriptdir"]["atac"] + "/align_bt2.sh",
        threads = config["threads"],
    output:
        atac_bam_raw + "/{library}.bam",
    shell:
        """
        {params.script} \
        {input.r1} \
        {input.r2} \
        {params.prefix} \
        {params.threads} \
        {output}
        """
#+end_src
- [[file:./workflow/scripts/align_bt2.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/align_bt2.sh

# Function
bt2_align(){
    bowtie2 --maxins 2000 --threads $1 --very-sensitive -x $2 -1 $3 -2 $4 |
        samtools view -@ $4 -f 2 -F 524 -q 40 -o -b |
        samtools sort -@ $4 -o $5 -
    samtools index -@ $4 $5
}

# Snakemake variables
input_r1="$1"
input_r2="$2"
params_prefix="$3"
params_threads="$4"
output_bam="$5"

# Run
bt2_align "$params_threads" "$params_prefix" "$input_r1" "$input_r2" "$output_bam"
samtools index $output_bam
#+end_src

- Notes
  - Fragment length 2000 per cite:corces2017
  - Very sensitive per cite:reske2020
  - Initial quality filtering from ENCODE ATAC-seq pipeline version 1
**** DONE De-duplicate alignments                                     :smk_rule:
- Snakemake
  #+begin_src snakemake
# De-duplicate alignments
rule dedup:
    container:
        atac_container,
    input:
        atac_bam_raw + "/{library}.bam",
    log:
        config["logdir"] + "/{library}_atac_dedup.log",
    output:
        atac_bam_dedup + "/{library}_dedup.bam",
    params:
        script = config["scriptdir"]["atac"] + "/dedup.sh",
	threads = config["threads"],
    resources:
        mem_mb=5000
    shell:
        """
        {params.script} \
        {input} \
        {params.threads} \
        {output} &> {log}
        """
#+end_src
- [[file:workflow/scripts/dedup.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/dedup.sh
raw_bam="${1}"
threads="${2}"
dedup_bam="${3}"
samtools sort -@ $threads -n -o - $raw_bam |
    samtools fixmate -m - - |
    samtools sort -@ $threads -o - - |
    samtools markdup -@ $threads -r - $dedup_bam
samtools index $dedup_bam
#+end_src

**** DONE Filter de-duplicated alignments                             :smk_rule:
- Snakemake
  #+begin_src snakemake
# Filter alignments by quality and reference position
rule filter_bam:
    container:
        atac_container,
    input:
        atac_bam_dedup + "/{library}_dedup.bam",
    log:
        config["logdir"] + "/{library}_atac_filter_bam.log",
    output:
        atac_bam_filt + "/{library}_filt.bam",
    params:
        keep_bed = atac_keep_bed,
        script = config["scriptdir"]["atac"] + "/filter_bam.sh",
	threads = config["threads"],
    shell:
        """
        {params.script} \
        {input} \
        {output} \
        {params.keep_bed} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:./workflow/scripts/filter_bam.sh][Shell script]]
  #+begin_src bash :tangle ./workflow/scripts/filter_bam.sh
#!/usr/bin/env bash

inbam="${1}"
outbam="${2}"
bed="${3}"
threads="${4}"
samtools view -@ $threads -b -f 3 -h -L $bed -M -q 20 -o $outbam $inbam
samtools index $outbam

#+end_src
**** DONE Tn5 shift filtered alignments                               :smk_rule:
- Snakemake
  #+begin_src snakemake
rule tn5_shift:
    container:
        atac_container,
    input:
        atac_bam_filt + "/{library}_filt.bam",
    log:
        config["logdir"] + "/{library}_tn5_shift.log",
    output:
        tmp = temp(atac_bam_tn5 + "/{library}_tn5_tmp.bam"),
        tn5 =      atac_bam_tn5 + "/{library}_tn5.bam",
    params:
        script = config["scriptdir"]["atac"] + "/tn5_shift.sh",
        threads = config["threads"],
    shell:
        """
        {params.script} \
        {input} \
        {output.tmp} \
        {output.tn5} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:./workflow/scripts/todo_tn5_shift.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/tn5_shift.sh
inbam=$1
outtmp=$2
outbam=$3
threads=$4

alignmentSieve --ATACshift --bam "$1" --numberOfProcessors $4 --outFile "$2"

samtools sort -@ $4 -o $3 $2
samtools index -@ $4 $3
#+end_src
**** DONE Get Tn5-shifted alignments to open chromatin                :smk_rule:
- Snakemake
  #+begin_src snakemake
rule open_chrom:
    container:
        atac_container,
    input:
        atac_bam_tn5 + "/{library}_tn5.bam",
    log:
        config["logdir"] + "/{library}_open_chrom.log",
    output:
        tmp = temp(atac_bam_open + "/{library}_open_tmp.bam"),
        open = atac_bam_open + "/{library}_open.bam",
    params:
        script = config["scriptdir"]["atac"] + "/open_chrom.sh",
        threads = config["threads"],
    shell:
        """
        {params.script} \
        {input} \
        {output.tmp} \
        {output.open} \
        {params.threads} &> {log}
        """
#+end_src
- [[file:workflow/scripts/open_chrom.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/open_chrom.sh
  input=$1
    tmp=$2
   open=$3
threads=$4

alignmentSieve --bam $input \
               --maxFragmentLength 150 \
               --numberOfProcessors $threads \
               --outFile $tmp
samtools sort -@ $threads -o $open $tmp
samtools index -@ $threads $open
#+end_src
*** Quality control
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/atac.smk
:END:
**** DONE Make R txdb database                                        :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_txdb:
    container:
        atac_container,
    log:
        config["logdir"] + "/make_txdb.log",
    output:
        config["datadir"] + "/ref/txdb",
    params:
        gtf = config["gtf"],
        script = config["scriptdir"]["atac"] + "/make_txdb.R",
    shell:
        """
        Rscript {params.script} \
        {params.gtf} \
        {output} \
        > {log} 2>&1
        """
#+end_src
- [[file:./workflow/scripts/make_txdb.R][Rscript]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_txdb.R
#!/usr/bin/env Rscript
args = commandArgs(trailingOnly = TRUE)
gtf_file = args[1]
txdb_file = args[2]

library(GenomicFeatures)

txdb = makeTxDbFromGFF(gtf_file,
                       format = "gtf")

saveDb(txdb, file = txdb_file)
#+end_src
**** DONE ATAC-seq QC                                                 :smk_rule:
- Snakemake
  #+begin_src snakemake
rule atacseq_qc:
    container:
        atac_container,
    input:
        dup_bams = expand(atac_bam_raw + "/{library}.bam", library = ATAC_LIBRARIES),
        processed_bams = expand(atac_bam_tn5 + "/{library}_tn5.bam", library = ATAC_LIBRARIES),
        txdb = config["datadir"] + "/ref/txdb",
    log:
        config["logdir"] + "/atacseq_qc.log",
    output:
        config["datadir"] + "/qc/atac_qc.rdata",
    params:
        script = config["scriptdir"]["atac"] + "/atacseq_qc.R",
    shell:
        """
        Rscript {params.script} \
        "{input.dup_bams}" \
        "{input.processed_bams}" \
        {input.txdb} \
        {output} > {log} 2>&1
        """
#+end_src
- [[file:workflow/scripts/atac-seq_qc.R][Rscript]]
#+begin_src R :tangle ./workflow/scripts/atacseq_qc.R
#!/usr/bin/env Rscript
args = commandArgs(trailingOnly = TRUE)
dup_bam_str = args[1]
proc_bam_str = args[2]
txdb_file = args[3]
atac_qc_file = args[4]

library(ATACseqQC)
library(tidyverse)
library(AnnotationDbi)

txdb = loadDb(txdb_file)

split_filename_str = function(filename_str){
  vect = strsplit(filename_str, " ")[[1]]
  return(vect)
}

dup_bam_vect = split_filename_str(dup_bam_str)
proc_bam_vect = split_filename_str(proc_bam_str)
bam_vect = data.frame(
  dup = dup_bam_vect,
  proc = proc_bam_vect
)

atacqc = function(dup_bam, proc_bam, txdb){
  freq = readsDupFreq(dup_bam)
  libcomp = estimateLibComplexity(freq)
  txs = transcripts(txdb)
  gal = readBamFile(proc_bam)
  tsse_list = TSSEscore(gal, txs)
  tsse_df = data.frame(
    tsse = tsse_list[1],
    distance = 100*(-9:10-.5)
  )
  tsse = tsse_list[2]
  atac = list(libcomp, tsse, tsse_df)
  names(atac) = c("libcomp_df", "tsse", "tsse_df")
  return(atac)
}

atac_qc_out = mapply(atacqc, dup_bam_vect, proc_bam_vect, MoreArgs = list(txdb = txdb))

save(atac_qc_out, file = atac_qc_file)
#+end_src
**** DONE FastQC :smk_rule:                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
# <DESCRIPTIVE COMMENT>
rule fastqc:
    container:
        atac_container,
    input:
        raw = atac_fastq_raw + "/{library}_R{read}.fastq.gz",
        filt = atac_fastq_proc + "/{library}_flex_{read}.fastq.gz",
    log:
        config["logdir"] + "/{library}_R{read}_atac_fastqc.log",
    output:
        raw = config["datadir"] + "/qc/{library}_R{read}_fastqc.html",
        filt = config["datadir"] + "/qc/{library}_flex_{read}_fastqc.html",
    params:
        outdir = config["datadir"] + "/qc",
    shell:
        """
        fastqc --outdir {params.outdir} --quiet --threads {config[threads]} {input.raw}
        fastqc --outdir {params.outdir} --quiet --threads {config[threads]} {input.filt}
        """
#+end_src


**** DONE Samstats                                                    :smk_rule:
- Snakemake
  #+begin_src snakemake
rule samstats:
    container:
        atac_container,
    input:
        atac_bam_filt + "/{library}_filt.bam",
    output:
        stat = config["datadir"] + "/qc/{library}_filt_stat.txt",
        flagstat = config["datadir"] + "/qc/{library}_filt_flagstat.txt",
    log:
        config["logdir"] + "/{library}_samstats.log",
    shell:
        """
        workflow/scripts/samstats.sh {config[threads]} {input} {output.stat} {output.flagstat} 2>&1 >> {log}
        """
#+end_src
- [[file:./workflow/scripts/samstats.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/samstats.sh
samtools stats -@ $1 $2 > $3
samtools flagstat -@ $1 $2 > $4
#+end_src

** INPROCESS Integration testing :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/int_test.smk :tangle-mode (identity #o555)
:END:
*** Preamble, variable naming, etc
#+begin_src snakemake
atac_fastq_raw =     config["datadir"] + "/fastq_atac_raw"
atac_fastq_proc =    config["datadir"] + "/fastq_atac_proc"
logdir =             config["logdir"]
atac_container =     config["container"]["atac"]
atac_bowtie2_index = config["datadir"] + "/ref/ucsc_mm10_chr19/ucsc_mm10_chr19"
atac_bowtie2_dir =   config["datadir"] + "/ref/ucsc_mm10_chr19"
atac_bam_raw =       config["datadir"] + "/bam_atac_raw"
atac_bam_dedup =     config["datadir"] + "/bam_atac_dedup"
atac_bam_filt =      config["datadir"] + "/bam_atac_filt"
atac_keep_bed =      config["datadir"] + "/inputs/mm10chrs.bed"
atac_bam_tn5 =       config["datadir"] + "/bam_atac_tn5"
atac_bam_open =      config["datadir"] + "/bam_atac_open"

import pandas as pd
import re
import numpy as np

libraries = pd.read_table("test/inputs/libraries.tsv")
libraries["r1_path"]="test/inputs/" + libraries["basename"]

readable = []
for x in libraries.r1_path:
    readable.append(os.access(x, os.R_OK))
libraries['readable']=readable

libraries = libraries[libraries.readable == True]

library_indict = libraries["library"].tolist()
file_indict = libraries["r1_path"].tolist()
lib_dict = dict(zip(library_indict, file_indict))

ATAC_LIBRARIES = list(lib_dict.keys())
#+end_src
*** All rule
#+begin_src snakemake

rule all:
    input:
        expand(atac_fastq_raw + "/{library}_R1.fastq.gz", library = ATAC_LIBRARIES),
        expand(atac_fastq_raw + "/{library}_R2.fastq.gz", library = ATAC_LIBRARIES),
        expand(atac_fastq_proc + "/{library}_flex_1.fastq.gz", library = ATAC_LIBRARIES),
        expand(atac_fastq_proc + "/{library}_flex_2.fastq.gz", library = ATAC_LIBRARIES),
	atac_bowtie2_dir,
        expand(atac_bam_raw + "/{library}.bam",	library = ATAC_LIBRARIES),
        expand(atac_bam_dedup + "/{library}_dedup.bam", library = ATAC_LIBRARIES),
        expand(atac_bam_filt + "/{library}_filt.bam", library = ATAC_LIBRARIES),
        expand(atac_bam_tn5 + "/{library}_tn5.bam", library = ATAC_LIBRARIES),
        expand(atac_bam_open + "/{library}_open.bam", library = ATAC_LIBRARIES),
        config["datadir"] + "/ref/txdb",
        config["datadir"] + "/qc/atac_qc.rdata",
        expand(config["datadir"] + "/qc/{library}_R{read}_fastqc.html", library = ATAC_LIBRARIES, read=["1","2"]),
        expand(config["datadir"] + "/qc/{library}_flex_{read}_fastqc.html", library = ATAC_LIBRARIES, read=["1","2"]),
        expand(config["datadir"] + "/qc/{library}_filt_stat.txt", library = ATAC_LIBRARIES),
        expand(config["datadir"] + "/qc/{library}_filt_flagstat.txt", library = ATAC_LIBRARIES),

        #expand(config["qc_dir"] + "/{library_id}_{read}_fastqc.html", library_id = LIBRARY_IDS, read = ["R1", "R2"]),
        #expand(config["qc_dir"] + "/{library_id}_stat.txt", library_id = LIBRARY_IDS),
        #expand(config["qc_dir"] + "/{library_id}_flagstat.txt", library_id = LIBRARY_IDS),
        #expand(config["data_dir"] + "/macs2/{library_id}_{bam_process}_{macs_broad}", library_id = LIBRARY_IDS, bam_process = ["open", "regfilt"], macs_broad = MACS_BROAD_EXT),
        #expand(config["data_dir"] + "/macs2/{library_id}_{bam_process}_{macs_narrow}", library_id = LIBRARY_IDS, bam_process = ["open", "regfilt"], macs_narrow = MACS_NARROW_EXT),
        #expand(config["data_dir"] + "/csaw/background_counts_all_{bam_process}_rse.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/csaw/counts_all_{bam_process}_rse.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/open_chrom/{library_id}_open_chrom.txt", library_id = LIBRARY_IDS),
	#expand(config["data_dir"] + "/csaw/norm_counts_rse_{bam_process}.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/csaw/dge_{bam_process}.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/dca/dca_granges_{bam_process}.rds", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/dca/{bam_process}_dca.csv", bam_process = BAM_PROCESS),
        #expand(config["data_dir"] + "/dca/{bam_process}_chipseek.rds", bam_process = BAM_PROCESS),
#+end_src

*** Symlink input fastqs                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
rule symlink:
    container:
        atac_container,
    input:
        lambda wildcards: lib_dict[wildcards.library],
    output:
        r1 = atac_fastq_raw + "/{library}_R1.fastq.gz",
        r2 = atac_fastq_raw + "/{library}_R2.fastq.gz",
    shell:
        """
        r2=$(echo {input} | sed "s/_R1/_R2/g")
        ln -sf --relative {input} {output.r1}
        ln -sf --relative $r2 {output.r2}
        """
#+end_src

*** Includes statements
#+begin_src snakemake

include: "atac.smk"

#+end_src
** :dev:
:PROPERTIES:
:header-args:snakemake: :tangle no
:header-args:bash: :tangle no
:END:
- https://www.biostars.org/p/442760/
- [ ] bowtie to version 2.4.5 for multithreading build
- normailzed read density in frag size distribution
  - https://www.biostars.org/p/220132/
  - https://www.biostars.org/p/219679/#219835
  - https://www.biostars.org/p/442760/
- FRIP
  - https://www.biostars.org/p/337872/
- upgrade to fastp https://workflowhub.eu/workflows/224https://community.brave.com/t/how-to-block-specific-websites/55961/8
- add flexbar files to multiqc
- ? cp /mnt/ris/jschwarz/cardiac-radiobiology/ref/keep.bed resources/keep.bed
*** Peak annotation
**** TODO Peak annotation
- Snakemake
  #+begin_src snakemake
rule peak_annotation:
    input:
        config["data_dir"] + "/atac/dca.rds"
    params:
        script = config["repo"] + "/workflow/scripts/peak_annotation.R"
    output:
        annotated_counts = config["data_dir"] + "/atac/annotated_counts.rds",
    log:
        config["data_dir"] + "/logs/peak_annotation.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output.annot} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/peak_annotation.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/peak_annotation.R
<<r_smk_preabmle>>

#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to annotate csaw peaks   ###
###

args = commandArgs(trailingOnly = TRUE)
peaks_rds = args[1]
annotation_file = args[2]

peaks = readRDS(peaks_rds)

library(ChIPseeker)
library(csaw)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
library(tidyverse)

txdb = TxDb.Mmusculus.UCSC.mm10.ensGene

peak_loc = peaks

chipseek = annotatePeak(peak_loc, TxDb = txdb, annoDb = "org.Mm.eg.db")

annotation = as_tibble(as.data.frame(chipseek))

write.csv(annotation, row.names = F, file = annotation_file)
#+end_src
***** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
***** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
****** Make backgroud bins                                         :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_backgroud_bins:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/make_backgroud_bins.R"
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
    output:
    log:
        config["data_dir"] + "/logs/make_backgroud_bins.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_backgroud_bins.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_backgroud_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to make background bins for csaw TMM normalization   ###
###

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
window_file =  args[1]
bam_dir = args[2]
bam_pattern = args[3]
filt_libs_str = args[4]
rse = args[4]
bk = args[5]

filt_libs = unlist(strsplit(filt_libs_str, " "))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

#+end_src
****** d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src

******* edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./workflow/scripts/edger.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/edger.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src
*** Differential accessibility                                     :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TEST"       [2022-03-31 Thu 14:33]
:END:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/differential_accessibility.R
<<r_smk_preamble>>
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to generate differential accessibility model with EdgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
load(data_model)
background = readRDS(background_rds)

counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design <- model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src
- Reference
  -   https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt

*** Peak annotation of DE                                          :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TEST"       [2022-03-31 Thu 14:46]
:END:

#+begin_src R
args = commandArgs(trailingOnly = TRUE)
granges_rds = args[1]
annotation_csv = args[2]
chipseek_file = args[3]

peaks = readRDS(granges_rds)

library(ChIPseeker)
library(csaw)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
library(tidyverse)

txdb = TxDb.Mmusculus.UCSC.mm10.ensGene

chipseek = annotatePeak(peaks, TxDb = txdb, annoDb = "org.Mm.eg.db")

annotation = as_tibble(as.data.frame(chipseek))

write.csv(annotation, row.names = F, file = annotation_csv)

saveRDS(object = chipseek,
        file = chipseek_file)
#+end_src

- Snakemake
  #+begin_src snakemake
rule peak_annotation:
    input:
        config["data_dir"] + "/atac/dca.rds"
    params:
        script = config["repo"] + "/workflow/scripts/peak_annotation.R"
    output:
        annotated_counts = config["data_dir"] + "/atac/annotated_counts.rds",
    log:
        config["data_dir"] + "/logs/peak_annotation.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output.annot} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/peak_annotation.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/peak_annotation.R
<<r_smk_preabmle>>

#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to annotate csaw peaks   ###
###

args = commandArgs(trailingOnly = TRUE)
peaks_rds = args[1]
annotation_file = args[2]

peaks = readRDS(peaks_rds)

library(ChIPseeker)
library(csaw)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
library(tidyverse)

txdb = TxDb.Mmusculus.UCSC.mm10.ensGene

peak_loc = peaks

chipseek = annotatePeak(peak_loc, TxDb = txdb, annoDb = "org.Mm.eg.db")

annotation = as_tibble(as.data.frame(chipseek))

write.csv(annotation, row.names = F, file = annotation_file)
#+end_src

**** Peak annotation
- is granges or rowRanges of a RSE
#+begin_src R
test=readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_counts.rds")
test
head(assays(test))
head(rowData(test))
head(rowRanges(test))
#+end_src
*** Motif analysis
- Get gene list- Takes annotated edger results as table
  #+begin_src R
library(tidyverse)
test = as_tibble(read.csv("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_de.csv", header = T))

motifs_down_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC < 0) %>%
  pull(geneId)

motifs_up_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC > 0) %>%
  pull(geneId)

writeLines(as.character(motifs_down_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt")
writeLines(as.character(motifs_up_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_up.txt")

#+end_src

- Find motifs
  #+begin_src bash
mkdir -p /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/

nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/ -fdr 10 -p 12

# try



Number of CPUs to use ("-p <#>", default 1)
HOMER is now multicore compliant.  It's not perfectly parallelized, however, certain types of analysis can benefit.  In general, the longer the length of the motif, the better the speed-up you'll see.

Number of motifs to find ("-S <#>", default 25)
Specifies the number of motifs of each length to find.  25 is already quite a bit.  If anything, I'd recommend reducing this number, particularly for long motifs to reduce the total execution time.
perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src

- Extract gene names
  #+begin_src bash

#+end_src


**** Snakefile :smk:noexport:
:PROPERTIES:
:header-args:snakemake:  :tangle ./workflow/motifs.smk
:END:
***** Smk preamble
#+begin_src snakemake :noweb yes
<<smk_preamble>>
#+end_src
***** All rule
#+begin_src snakemake
rule all:
    input:
#+end_src
***** Extract gene list :smk_rule:

extract ensembl ID lists from csaw-EdgeR DCA workflow

- Snakemake
  #+begin_src snakemake
rule extract_gene_list:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/extract_gene_list.R"
    output:
    log:
        config["data_dir"] + "/logs/extract_gene_list.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/extract_gene_list.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/extract_gene_list.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###    SCRIPT TITLE   ###
###

args = commandArgs(trailingOnly = TRUE)
dca_tbl = args[1]

#+end_src
***** Find motifs for gene list promoters
- Find motifs by gene list
  #+begin_src bash
# TODO install homer w/ mouse-p promoter set

source ~/repos/cardradbio-atac/config/${HOSTNAME}.sh

# Fake gene list from peak annotation output, is ensembl IDs
#

# Install mouse homer promotor set
perl /home/jeszyman/homer/.//configureHomer.pl -install mouse-p

mkdir -p /tmp/out

findMotifs.pl /tmp/test.txt mouse /tmp/out

perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src
**** Description :ignore:

*** Nearest feature of ensembl genes with bedops
https://bedops.readthedocs.io/en/latest/content/reference/set-operations/closest-features.html
- Convert DESeq2 results to bedfile
  #+begin_src bash
cat /tmp/rt_up.tsv | sed 's/\t.*//g' | sed 's/\./\t/g' | sed 's\chr\\g'> /tmp/rt_up.bed
cat /tmp/ctrl_up.tsv | sed 's/\t.*//g' | sed 's/\./\t/g' | sed 's\chr\\g' > /tmp/ctrl_up.bed
#+end_src
- annotate nearest protein coding genes and return lists for sham and post-RT state
  #+begin_src bash
sort-bed $data_dir/ref/mm10_ens_gene.bed > /tmp/mm10_sort.bed
#########1#########2#########3#########4#########5#########6#########7#########8

sort-bed /tmp/ctrl_up.bed > /tmp/ctrl_up_sort.bed
sort-bed /tmp/rt_up.bed > /tmp/rt_up_sort.bed


#########1#########2#########3#########4#########5#########6#########7#########8

closest-features --closest /tmp/ctrl_up_sort.bed /tmp/mm10_sort.bed | sed 's/^.*gene_name..//g' | sed 's/".*$//g' | sort -u > /tmp/ctrl_up_genes

closest-features --closest /tmp/rt_up_sort.bed /tmp/mm10_sort.bed | sed 's/^.*gene_name..//g' | sed 's/".*$//g' | sort -u > /tmp/rt_up_genes

diff /tmp/rt_up_genes /tmp/ctrl_up_genes | grep '^<' | cut -c 3- > /tmp/diff
wc -l /tmp/diff

#+end_src





*** [[file:workflow/int_test_peaks.smk][Peak calling and differential accessibility]]
#+begin_src snakemake :tangle ./workflow/int_test_peaks.smk


rule all:
    input:


#+end_src

#+begin_src snakemake :tangle ./workflow/int_test_peaks.smk
container: config["container"]

MACS_BROAD_EXT = ["peaks.broadPeak", "peaks.gappedPeak", "peaks.xls"]

MACS_NARROW_EXT = ["peaks.narrowPeak", "summits.bed"]

LIBRARY_IDS = ["atac1","atac2","atac3","atac4"]

BAM_PROCESS = ["regfilt", "open"]

rule all:
    input:
        expand(config["data_dir"] + "/macs2/{library_id}_{bam_process}_{macs_broad}", library_id = LIBRARY_IDS, bam_process = ["open", "regfilt"], macs_broad = MACS_BROAD_EXT),
        expand(config["data_dir"] + "/macs2/{library_id}_{bam_process}_{macs_narrow}", library_id = LIBRARY_IDS, bam_process = ["open", "regfilt"], macs_narrow = MACS_NARROW_EXT),
        expand(config["data_dir"] + "/csaw/background_counts_all_{bam_process}_rse.rds", bam_process = BAM_PROCESS),
        expand(config["data_dir"] + "/csaw/counts_all_{bam_process}_rse.rds", bam_process = BAM_PROCESS),

include: "peak_call_and_dif.smk"
#+end_src


*** [[file:workflow/qc.smk][Quality control]]                                                     :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/qc.smk
:END:
**** Smk preamble
#+begin_src snakemake
RUNSAMPLES =  ["lib001", "lib002", "lib003", "lib004", "lib005", "lib006", "lib007", "lib008", "lib009", "lib010", "lib011", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib024", "lib025"]
#+end_src
**** Smk rules
***** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["data_dir"] + "/qc/{library_id}_stat.txt", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/qc/{library_id}_flagstat.txt", library_id=RUNSAMPLES),
#+end_src
- add rules with smk.rule
***** Samstats:smk_rule:
- Snakemake
  #+begin_src snakemake
rule samstats:
    input:
        bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
    output:
        stat = config["data_dir"] + "/qc/{library_id}_stat.txt",
        flagstat = config["data_dir"] + "/qc/{library_id}_flagstat.txt",
    log:
        config["data_dir"] + "/logs/{library_id}_samstats.log",
    shell:
        """
        "workflow/scripts/samstats.sh" {config[threads]} {input.bam} {output.stat} {output.flagstat} 2>&1 >> {log}
        """
#+end_src
- [[file:./workflow/scripts/samstats.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/samstats.sh
#########1#########2#########3#########4#########5#########6#########7#########8
samtools stats -@ $1 $2 > $3
samtools flagstat -@ $1 $2 > $4
#+end_src
***** FastQC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule fastqc:
    input:
    output:
    shell:
        """
        scripts/fastqc.sh
        """
#+end_src
- [[file:./workflow/scripts/fastqc.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/fastqc.sh
# Snakemake variables
# Function
# Run command
for file in $data_dir}/atac/atac-fastq/*.fastq.gz;
do
    fastqc --outdir=$data_dir}/results/qc $file &>> "$data_dir}/log/fastqc_log.txt"
done


#+end_src
***** MultiQC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule multiqc:
    input:
    output:
    shell:
        """
        scripts/multiqc.sh
        """
#+end_src
- [[file:./workflow/scripts/multiqc.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/multiqc.sh
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

# Snakemake variables
# Function
# Run command
#########1#########2#########3#########4#########5#########6#########7#########8
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

#+end_src
***** ATAC-seq QC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule atac-seq_qc:
    input:
    params:
        script = config["repo"] + "workflow/scripts/atac-seq_qc.R"
    output:
    log:
        config["data_dir"] + "/logs/atac-seq_qc.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/atac-seq_qc.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/atac-seq_qc.R
#########1#########2#########3#########4#########5#########6#########7#########8

###
###   / SCRIPT TITLE   ###
###

#+end_src

****** Transcription start sites occupancy
:PROPERTIES:
:CREATED:  [2021-09-15 Wed 10:09]
:ID:       eecd41c6-4f32-4d79-b7d5-40d666b8f85b
:END:
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#setwd("/home/jeszyman/repos/card-rad-bio")
#source("./src/setup.R")
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                                "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                                "TC", "UQ"),
                 "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                               "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                               "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                               "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                               "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                     param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

save(gal_lib051,
     gal_lib052,
     gal_lib053,
     gal_lib054,
     gal_lib055,
     gal_lib057,
     file = file.path(data_dir,"atac/gal.RData"))


#########1#########2#########3#########4#########5#########6#########7#########8
tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+begin_src R
#TODO LOAD gals
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
txs <- transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)

tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+caption: CAPTION label:fig-atac-nuc-position
[[file:results/imgs/atac_nuc_position.pdf][file:results/imgs/atac_nuc_position.pdf]]



- Post-atacseqqc
#+end_src

BiocManager::install("diffloop")

library(diffloop)
library(TxDb.Mmusculus.UCSC.mm10.knownGene)

seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = scanBam(bam_list[1])
class(test)
>>>>>>> 9b786365ee566b1a63eb65edb3a6fa94e4ad8e97

bamTop100 <- scanBam(BamFile(bam_list[1], yieldSize = 100))
bam_list[1]
bamTag(bamTop100)



gal = readBamFile(bam_list[1], tags = tags, which = which, asMates = T, bigFile=T)

gal
param = ScanBamParam(tag))

which
test = rmchr(which)
test
test = renameSeqlevels(which, c("chr1"="1"))
test


test=rmchr(which)
head(which)


gal
## Promotor / transcript score
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
pt = PTscore(gal, txs)

## Nucleosome free regions score
nfr = NFRscore(gal, txs)

## Transcription start site enrichment
tsse = TSSEscore(gal, txs)

# Ideas
## Adjust start sites
#+end_src
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
- lib complexity w/ preseq http://smithlabresearch.org/software/preseq/ https://github.com/smithlabcode/preseq


TSSEs
ir01 - 2.75


#+caption: CAPTION label:fig-atac-tss
[[file:results/imgs/atac_tss.pdf]]

****** Aggregate
:PROPERTIES:
:CREATED:  [2021-09-21 Tue 07:29]
:ID:       a9426a9b-16e8-4356-8d98-314b4c7f8ec5
:END:
****** notes
:PROPERTIES:
:ID:       06f9345e-a489-4b5e-9f68-82e22e468096
:END:
- run on server, run launch_atac to load docker with ATACseqQC package
- do not run R docker through docker_interactive function- unknown error
- cite:liu2021 https://www.sciencedirect.com/science/article/pii/S1672022921001479

***** RUN Library complexity:smk_rule:
- Snakemake
  #+begin_src snakemake
rule library_complexity:
input:
    bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
params:
    script = config["repo"] + "/workflow/scripts/library_complexity.R",
output:
    bam = config["data_dir"] + "/qc/{library_id}_libcomplex.rds",
log:
    config["data_dir"] + "/logs/{library_id}_library_complexity.log",
shell:
    """
    Rscript {params.script} \
    {input.bam} \
    {output.bam} \
    >& {log}
    """
#+end_src
- [[file:./workflow/scripts/library_complexity.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/library_complexity.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to assess ATAC-seq library complexity by fragment length   ###
###

args = commandArgs(trailingOnly = TRUE)
bam = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

libCompWrap = function(dup_bam){
  estimateLibComplexity(readsDupFreq(dup_bam))
}

complex = libCompWrap("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5469_MGI2048/lc-08.TCGTGATCAG-ACACTACGTA/lc-08.TCGTGATCAG-ACACTACGTA.genome_accepted_hits.bam")

saveRDS(object = complex,
        file = rds)

#+end_src
- Reference
  - https://github.com/smithlabcode/preseq
  - lib complexity w/ preseq http://smithlabresearch.org/software/preseq/
  - Old code
    #+begin_src R
  load(file.path(repo,"/results/rdata/library_complexity_raw.RData"))
  ls()
  head(library_complexity_raw)

  test = as.data.frame(library_complexity_raw)

  lib_complex_plot =
    as.data.frame(library_complexity_raw) %>%
    pivot_longer(cols = ends_with("values"), names_to = "library_id", values_to = "pred") %>%
    pivot_longer(cols = ends_with("reads"), names_to = "library_id2", values_to = "reads") %>%
    select(!(ends_with("relative.size"))) %>%
    mutate(library_id = substr(library_id, 1, 6)) %>%
    select(library_id, pred, reads) %>%
    filter(library_id != "lib056") %>%
    ggplot(., aes(x = reads, y = pred, group = library_id)) + geom_smooth(se = FALSE) +
     xlab("Total molecules") + ylab("Unique molecules")
  save_plot("./results/imgs/lib_complex.pdf", lib_complex_plot)

  #+end_src

    #+begin_src R

  load("./results/rdata/library_complexity_raw.RData")
  load("./data/data_model.RData")

  atac_multiqc_general_raw =
    as_tibble(
      read.table(
        file.path(repo,"results/qc/atac_qc_data/multiqc_general_stats.txt"),
        header = T,
        sep = '\t',
        fill = T))

  atac_multiqc_general_raw


  ## Modify atac multiqc df
  atac_multiqc_general_mod =
    atac_multiqc_general_raw %>%
    mutate(library_id = gsub("^.....", "", Sample)) %>%
    mutate(library_id = gsub("_.*$", "", library_id)) %>%
    mutate(total_reads = FastQC_mqc.generalstats.fastqc.total_sequences) %>%
    mutate(aligned_reads = Samtools_mqc.generalstats.samtools.mapped_passed) %>%
    mutate(processing = ifelse(grepl("_R1", Sample), "raw",
                        ifelse(grepl("ddp_flagstat", Sample), "processed",
                               ifelse(grepl("ddp_open_flagstat", Sample), "open", "other")))) %>%
    filter(processing != "other") %>%
    filter(!grepl("_R2", Sample)) %>%
    filter(!grepl("flex", Sample)) %>%
    filter(!is.na(total_reads) | !is.na(aligned_reads)) %>%
    mutate(read_prs = ifelse(!is.na(total_reads), total_reads, aligned_reads)) %>%
    select(library_id, processing, read_prs) %>%
    pivot_wider(names_from = processing, values_from = read_prs) %>%
    mutate(p_proc = processed/raw*100) %>%
    mutate(p_open = open/raw*100)
  atac_multiqc_general_mod

  library_complexity_mod = as_tibble(data.frame(lib051 = library_complexity_raw[[1]],
                                      lib052 = library_complexity_raw[[2]],
                                      lib053 = library_complexity_raw[[3]],
                                      lib054 = library_complexity_raw[[4]],
                                      lib055 = library_complexity_raw[[5]],
                                      lib056 = library_complexity_raw[[6]],
                                      lib057 = library_complexity_raw[[7]])) %>%
    mutate(rel_size = lib051.relative.size) %>%
    select(!ends_with("relative.size")) %>%
    pivot_longer(cols = starts_with("lib"), names_to = "label", values_to = "count") %>%
    mutate(library_id = substr(label, 1, 6)) %>%
    mutate(label = gsub("^.*\\.","",label)) %>%
    pivot_wider(names_from = label, values_from = count) %>%
    left_join(libraries, by = "library_id")
  library_complexity_mod

  library_complexity =
    library_complexity_mod %>%
    left_join(atac_multiqc_general_mod, by = "library_id") %>%
    filter(p_proc > 25)

  library_complexity_plot =
    library_complexity %>%
    ggplot(., aes(x = values, y = reads)) + geom_smooth()
  library_complexity_plot

  save_plot("./results/imgs/lib_complex.pdf", library_complexity_plot)

  #+end_src
***** RUN Make frag distribution mat:smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_frag_distribution_mat:
    input:
        bam_dir = config["data_dir"] + "/atac/bam",
    params:
        script = config["repo"] + "/workflow/scripts/make_frag_distribution_mat.R",
    output:
        frag_dist = config["data_dir"] + "/qc/frag_dist.rds",
    log:
        config["data_dir"] + "/logs/make_frag_distribution_mat.log"
    shell:
        """
        Rscript {params.script} \
	{input.bam} \
	{output.frag_dist}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_frag_distribution_mat.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_frag_distribution_mat.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make fragment size distribution matrix   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)

bam_files = list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = TRUE)

bam_file_names = gsub("_dedup.bam", "", bam_files = list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = FALSE))

frag_dist = fragSizeDist(bam_files, bam_file_names)

saveRDS(object = frag_dist,
        file  = rds)
#+end_src
- Old code
  #+begin_src R



class(test)


names(test)

class(test[[1]])

head(test[[1]])
data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

pdf("/tmp/test.pdf")
lib051_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib051_aut_blk_ddp.bam", bamFiles.labels = "lib051")
lib052_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib052_aut_blk_ddp.bam", bamFiles.labels = "lib052")
lib053_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib053_aut_blk_ddp.bam", bamFiles.labels = "lib053")
lib054_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib054_aut_blk_ddp.bam", bamFiles.labels = "lib054")
lib055_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib055_aut_blk_ddp.bam", bamFiles.labels = "lib055")
lib056_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib056_aut_blk_ddp.bam", bamFiles.labels = "lib056")
lib057_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib057_aut_blk_ddp.bam", bamFiles.labels = "lib057")
dev.off()

save(lib051_frag,lib052_frag,lib053_frag,lib054_frag,lib055_frag,lib056_frag,lib057_frag, file = "~/repos/card-rad-bio/results/qc/frag.RData")

#########1#########2#########3#########4#########5#########6#########7#########8
load("./results/qc/frag.RData")
getwd()
#+end_src
  #+begin_src R
load("/mnt/ris/jschwarz/cardiac-radiobiology/atac/fragsize.RData")

ls()

fragsize_ct01
#+end_src
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#
load(file.path(data_dir,"/atac/fragsize.RData"))

# Rename old frag size files
fragsize_lib051 = fragsize_ct01
fragsize_lib052 = fragsize_ct02
fragsize_lib053 = fragsize_ir01
fragsize_lib054 = fragsize_ir02
fragsize_lib055 = fragsize_ir03
fragsize_lib056 = fragsize_ir04
fragsize_lib057 = fragsize_ct03

# create df
fragsize = data.frame(
  length = as.numeric(names(head(fragsize_lib051[[1]], n = 1000))),
  lib051 = as.vector(head(fragsize_lib051[[1]], n = 1000)),
  lib052 = as.vector(head(fragsize_lib052[[1]], n = 1000)),
  lib053 = as.vector(head(fragsize_lib053[[1]], n = 1000)),
  lib054 = as.vector(head(fragsize_lib054[[1]], n = 1000)),
  lib055 = as.vector(head(fragsize_lib055[[1]], n = 1000)),
  lib057 = as.vector(head(fragsize_lib057[[1]], n = 1000)))
fragsize = as_tibble(fragsize)

# save df
save(fragsize, file = file.path(repo,"/results/rdata/atac_fragsize.RData"))

# make plot
fragsize %>%
  pivot_longer(cols = !length, names_to = "library_id", values_to = "count") %>%
  ggplot(., aes(x = length, y = count, group = library_id)) + geom_line() + xlim()

+ geom_bar(stat = "identity")

#+end_src


***** Make nucleosome positioning alignments
:PROPERTIES:
:CREATED:  [2021-09-02 Thu 11:22]
:ID:       5acea857-b98c-473b-9b23-d430665cbb4d
:END:
:LOGBOOK:
- State "RUN"        from "DONE"       [2021-09-22 Wed 10:09]
- State "DONE"       from "CANCELED"   [2021-09-22 Wed 10:09]
CLOCK: [2021-09-15 Wed 09:35]--[2021-09-15 Wed 10:53] =>  1:18
:END:
#+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                              "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                              "TC", "UQ"),
               "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                             "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                             "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                             "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                             "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                   param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

save(gal_lib051,
   gal_lib052,
   gal_lib053,
   gal_lib054,
   gal_lib055,
   gal_lib057,
   file = file.path(data_dir,"atac/gal.RData"))

#+end_src
- Reference
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
**** Ideas
  - full log to catch this error
    - - https://www.biostars.org/p/396538/
    - note- log didn't work [[file:/mnt/ris/jschwarz/cardiac-radiobiology/log/fastqc_log.txt]]
    - #TODO how to add log file to find "$data_dir}/atac/atac-fastq" -name "*.fastq.gz" | parallel fastqc --outdir="$data_dir}/qc" }
  - preamble
    #+begin_src bash :noweb yes :tangle ./src/qc.sh
  #!/bin/bash
  #########1#########2#########3#########4#########5#########6#########7#########8
  #
  ### Quality control for ATAC-seq data ###
  #


  #+end_src
*** [[file:workflow/nuc_rna.smk][Nuclear bulk RNA-seq]]                                                :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/nuc_rna.smk
:END:
**** Smk preamble
#+begin_src snakemake

#+end_src
**** Smk rules
***** All rule
#+begin_src snakemake
rule all:
    input:
        config["data_dir"] + "/ms_nuc_rna/nuc_deseq.rdata",
        config["data_dir"] + "/ms_nuc_rna/nuc_full_deseq.rdata",
        nuc_res = config["data_dir"] + "/ms_nuc_rna/nuc_res.csv",
#+end_src

***** Make txdb                                                    :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_txdb:
    output:
        txdb = config["data_dir"] + "/ref/ucsc_mm10_txdb.rds"
    script:
        "scripts/make_txdb.R"
#+end_src
- [[file:./workflow/scripts/make_txdb.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_txdb.R
#########1#########2#########3#########4#########5#########6#########7#########8

library(TxDb.Mmusculus.UCSC.mm10.ensGene)

# Create gene-transcript index as tx2gene object from a txdb
make_index = function(txdb){
  k <- keys(txdb, keytype = "TXNAME")
  tx2gene <- AnnotationDbi::select(txdb, k, "GENEID", "TXNAME")
}

tx2gene = make_index(TxDb.Mmusculus.UCSC.mm10.ensGene)

saveRDS(tx2gene, file = snakemake@output[["txdb"]])
#+end_src
***** Make counts                                                  :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_counts:
    input:
        txdb = config["data_dir"] + "/ref/ucsc_mm10_txdb.rds",
        salmon_5469 = config["data_dir"] + "/inputs/Rentschler_s5469_MGI2048",
        salmon_5708 = config["data_dir"] + "/inputs/Rentschler_s5708_MGI2548",
    output:
        nuc_gene_cnts = config["data_dir"] + "/ms_nuc_rna/nuc_gene_cnts.rds"
    script:
        "scripts/make_counts.R"
#+end_src
- [[file:./workflow/scripts/make_counts.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_counts.R
#########1#########2#########3#########4#########5#########6#########7#########8

source(snakemake@config[["r_libs"]])

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

salmon_paths_4630 = list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s4630_MGI0042",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = TRUE)

(salmon_paths_4630_alt_ids = gsub("\\..*$",
                                             "",
                                             list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s4630_MGI0042",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = FALSE)
                                         ))

salmon_paths_4730 = list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s4730_MGI0070",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = TRUE)

(salmon_paths_4730_alt_ids = gsub("\\..*$","", list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s4730_MGI0070",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = FALSE)))

salmon_paths_5469 = list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5469_MGI2048",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = TRUE)

salmon_paths_5469_alt_ids = gsub("-","_",gsub("^","sample.",substr(list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5469_MGI2048",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = FALSE), 1, 5)))

names(salmon_paths_5469) = as.character(data.frame(alt_lib_id = salmon_paths_5469_alt_ids) %>%
  left_join(libraries, by = "alt_lib_id") %>%
  pull(library_id))

salmon_paths_5708 = list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5708_MGI2548",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = TRUE)

salmon_paths_5708_alt_ids = paste0("sample.",substr(list.files("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5708_MGI2548",
                                         pattern = "\\.sf$",
                                         recursive = TRUE,
                                         full.names = FALSE), 1, 4))

salmon_paths = c(salmon_paths_4630,
                 salmon_paths_4730,
                 salmon_paths_5469,
                 salmon_paths_5708)

alt_ids_salmon_paths = c(salmon_paths_4630_alt_ids,
                         salmon_paths_4730_alt_ids,
                         salmon_paths_5469_alt_ids,
                         salmon_paths_5708_alt_ids)

names(salmon_paths) =
as.character(data.frame(alt_lib_id = alt_ids_salmon_paths) %>%
  left_join(libraries, by = "alt_lib_id") %>% pull(library_id))


txdb = readRDS(snakemake@input[["txdb"]])

txi_nuc = tximport(salmon_paths,
                   type = "salmon",
                   tx2gene = txdb)

saveRDS(txi_nuc, file = snakemake@output[["nuc_gene_cnts"]])
#+end_src

***** Make full nuc DESeq2 object:smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_full_nuc_deseq2_object:
    input:
        data_model = config["data_dir"] + "/data_model/data_model.RData",
        txi = config["data_dir"] + "/ms_nuc_rna/nuc_gene_cnts.rds",
    params:
        script = config["repo"] + "/workflow/scripts/make_full_nuc_deseq2_object.R"
    output:
        nuc_deseq = config["data_dir"] + "/ms_nuc_rna/nuc_full_deseq.rdata",
    log:
        config["data_dir"] + "/logs/make_full_nuc_deseq2_object.log"
    shell:
        """
        Rscript {params.script} \
	{input.data_model} \
	{input.txi} \
	{output.nuc_deseq} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_full_nuc_deseq2_object.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_full_nuc_deseq2_object.R
#########1#########2#########3#########4#########5#########6#########7#########8

###############################################################################
###    Script to make a custom DESeq2 object for QC-filtered nuclear bulk   ###
###    RNA-seq data  WITHOUT FILTERING                                      ###
###############################################################################

args = commandArgs(trailingOnly = TRUE)
data_model = args[1]
txi_counts = readRDS(args[2])
nuc_deseq = args[3]

load(data_model)
library(tidyverse)
library(DESeq2)
library(EnsDb.Mmusculus.v79)
edb = EnsDb.Mmusculus.v79

deseq_column_data =
  data.frame(library_id = colnames(txi_counts$counts)) %>%
  left_join(libraries_full, by = "library_id") %>%
  dplyr::select(run_id,flow_date,cohort_id, lib_typ) %>%
  mutate(flow_date = replace_na(as.character(flow_date), "noflow")) %>%
  mutate(sampletype = paste(run_id,flow_date,cohort_id,lib_typ, sep = "_"))

dds = DESeqDataSetFromTximport(txi = txi_counts,
                               colData = deseq_column_data,
                               design = ~ cohort_id + run_id)
dds$cohort_id = factor(dds$cohort_id, levels = c("sham", "ir24h", "ir2w", "ir6w"))

nuc = dds[ ,dds$lib_typ == "nuc_rna"]
nuc$lib_typ = droplevels(nuc$lib_typ)
nuc$cohort_id = droplevels(nuc$cohort_id)
design(nuc) = ~ cohort_id

full_nuc_vsd <- vst(nuc)
full_nuc_rld = rlog(nuc)

save(full_nuc_vsd,
     full_nuc_rld,
     file = nuc_deseq)

#+end_src
- [[file:/mnt/ris/jschwarz/cardiac-radiobiology/logs/make_full_nuc_deseq2_object.log][Log]]
***** Make nuc DESeq2 object                                       :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_nuc_deseq2_object:
    input:
        data_model = config["data_dir"] + "/data_model/data_model.RData",
        txi = config["data_dir"] + "/ms_nuc_rna/nuc_gene_cnts.rds",
    params:
        script = config["repo"] + "/workflow/scripts/make_nuc_deseq2_object.R"
    output:
        nuc_deseq = config["data_dir"] + "/ms_nuc_rna/nuc_deseq.rdata",
        nuc_res = config["data_dir"] + "/ms_nuc_rna/nuc_res.csv",
    log:
        config["data_dir"] + "/logs/make_nuc_deseq2_object.log"
    shell:
        """
        Rscript {params.script} \
	{input.data_model} \
	{input.txi} \
	{output.nuc_deseq} \
	{output.nuc_res}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_nuc_deseq2_object.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_nuc_deseq2_object.R
#########1#########2#########3#########4#########5#########6#########7#########8

###############################################################################
###    Script to make a custom DESeq2 object for QC-filtered nuclear bulk   ###
###    RNA-seq data                                                         ###
###############################################################################

args = commandArgs(trailingOnly = TRUE)
data_model = args[1]
txi_counts = readRDS(args[2])
nuc_deseq = args[3]
nuc_res_csv = args[4]

load(data_model)
library(tidyverse)
library(DESeq2)
library(EnsDb.Mmusculus.v79)
edb = EnsDb.Mmusculus.v79

deseq_column_data =
  data.frame(library_id = colnames(txi_counts$counts)) %>%
  left_join(libraries_full, by = "library_id") %>%
  dplyr::select(run_id,flow_date,cohort_id, lib_typ) %>%
  mutate(flow_date = replace_na(as.character(flow_date), "noflow")) %>%
  mutate(sampletype = paste(run_id,flow_date,cohort_id,lib_typ, sep = "_"))

dds = DESeqDataSetFromTximport(txi = txi_counts,
                               colData = deseq_column_data,
                               design = ~ cohort_id + run_id)
dds$cohort_id = factor(dds$cohort_id, levels = c("sham", "ir24h", "ir2w", "ir6w"))

nuc = dds[ ,dds$lib_typ == "nuc_rna"]
nuc = nuc[ ,!(colnames(nuc) %in% c("lib033",
                                   "lib031",
                                   "lib030",
                                   "lib027",
                                   "lib045",
                                   "lib042"))]
nuc$lib_typ = droplevels(nuc$lib_typ)
nuc$cohort_id = droplevels(nuc$cohort_id)
design(nuc) = ~ cohort_id

nuc_vsd <- vst(nuc)
nuc_dds = DESeq(nuc)
nuc_res = results(nuc_dds, name = "cohort_id_ir6w_vs_sham")

res_genes = mapIds(edb, keys=rownames(nuc_res), column="GENENAME", keytype="GENEID", multiVals = 'first')

name_index = data.frame(name = res_genes,
                        ensembl_id = names(res_genes))

nuc_res_anno = as_tibble(as.data.frame(nuc_res)) %>%
  mutate(ensembl_id = row.names(nuc_res)) %>%
  left_join(name_index, by = "ensembl_id") %>%
  arrange(padj)

save(nuc_vsd,
     nuc_dds,
     nuc_res,
     nuc_res_anno,
     file = nuc_deseq)

write.csv(nuc_res_anno, file = nuc_res_csv, row.names = F)
#+end_src
- [[file:/mnt/ris/jschwarz/cardiac-radiobiology/logs/make_nuc_deseq2_object.log][Log]]
**** Reference
- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4700052/
- https://mail.google.com/mail/u/0/#inbox/FMfcgzGmtXGvSlSLSqqngftGtkgJvksw
- Nuclear RNA-seq expectations and limitations
  - supercite:mitchell2012
  - Whole cell / nuc rna correlation will be poor
  - Nuc rna requires different alignment to account for introns
  - More stability in the long nincodings
- nuclear RNA-seq from cardiac tissue cite:gilsbach2018
  - Nuc rna harbors unique possibly useful info?
**** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:ID:       f581d62d-0501-494e-9c00-f768a6bb1e5c
:END:
***** Nuclear RNA GSEA
#+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8

#Install packages
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("fgsea")
BiocManager::install("msigdbr")

# Load packages
library(msigdbr)
library(fgsea)
library(tidyverse)

# Get msigdb lists of interest
##
## Generate all msigdb mouse hallmark gene sets as list of lists
msigdbr_df <- msigdbr(species = "mouse", category = "H")
ms_path_list = split(x = msigdbr_df$ensembl_gene, f = msigdbr_df$gs_name)

# Get deseq2 results as numeric vectors
load("~/repos/card-rad-bio/data/mouse-hrt-deseq.RData")

stat6wk = res_rna_6wk_ctrl$stat
names(stat6wk)=res_rna_6wk_ctrl$rna
stat2wk = res_rna_2wk_ctrl$stat
names(stat2wk)=res_rna_2wk_ctrl$rna

pv6wk = res_rna_6wk_ctrl$pvalue
names(pv6wk) = res_rna_6wk_ctrl$rna
pv2wk = res_rna_2wk_ctrl$pvalue
names(pv2wk) = res_rna_2wk_ctrl$rna

#
gsea_6wk = fgseaMultilevel(ms_path_list, stat6wk, maxSize = 500)
gsea_2wk = fgseaMultilevel(ms_path_list, stat2wk, maxSize = 500)


#########1#########2#########3#########4#########5#########6#########7#########8
## Hallmark gene sets of interest
###
### Cell cycle group
cell_cycle_paths = c("HALLMARK_P53_PATHWAY",
                     "HALLMARK_E2F_TARGETS",
                     "HALLMARK_G2M_CHECKPOINT",
                     "HALLMARK_MITOTIC_SPINDLE")

### Lipogenic
lipogenic_paths = c("HALLMARK_PI3K_AKT_MTOR_SIGNALING",
                    "HALLMARK_CHOLESTEROL_HOMEOSTASIS")

### Wnt/Bcatenin
wnt_path = "HALLMARK_WNT_BETA_CATENIN_SIGNALING"

### Inflammatory
inflam_path = "HALLMARK_INFLAMMATORY_RESPONSE"

### ROS
ros_path = "HALLMARK_REACTIVE_OXYGEN_SPECIES_PATHWAY"

### Full list
(interest_paths = c(cell_cycle_paths, lipogenic_paths, wnt_path, inflam_path, ros_path))

## Subset gene sets
interest_path_genes = ms_path_list[which(names(ms_path_list) %in% interest_paths)]

# Make table of per-pathway results
gsea_path_tbl = function(pathname,stat){
  #
  annot = msigdbr_df[msigdbr_df$gs_name==pathname, ]
  ranks = sort(stat, decreasing = T)
  path = unlist(unname(ms_path_list[names(ms_path_list) == pathname]))
  gsea = calcGseaStat(ranks, na.omit(match(path, names(ranks))), returnLeadingEdge = T)
  #
  df = data.frame(ensmbl = path,
                  index = match(path, names(ranks)))
  df =
    df %>%
    filter(df$index %in% gsea$leadingEdge) %>%
    left_join(annot, by = c("ensmbl" = "ensembl_gene")) %>%
    left_join(res_rna_6wk_ctrl, by = c("ensmbl" = "rna")) %>%
    select(gene_symbol, log2FoldChange, padj)
  return(df)
}


gsea_leading_6wk = lapply(interest_paths, gsea_path_tbl, stat6wk)
names(gsea_leading_6wk) = interest_paths


gsea_leading_2wk = lapply(interest_paths, gsea_path_tbl, stat2wk)
names(gsea_leading_2wk) = interest_paths


#########1#########2#########3#########4#########5#########6#########7#########8

save(gsea_6wk,
     gsea_2wk,
     gsea_leading_6wk,
     gsea_leading_2wk,
     file = "/mnt/ris/jschwarz/cardiac-radiobiology/ms_hrt_gsea.RData")
#+end_src

***** Measure DE with EdgeR
:PROPERTIES:
:CREATED:  [2021-10-06 Wed 12:34]
:ID:       e51bfb9c-c923-4ba6-b92c-eab353ec4052
:END:
#+begin_src R
library(edgeR)

#########1#########2#########3#########4#########5#########6#########7#########8
source(paste0("./config/",as.character(Sys.info()["nodename"]),".R"))
load(file.path(data_dir,"mouse_hrt_rt_de/txi_mm10_ens.RData"))

cts = txi_mm10_ens$counts
# c5 outlier
cts = cts[,c(1:10,12)]

normMat = txi_mm10_ens$length
normMat = normMat[,c(1:10,12)]

# Obtaining per-observation scaling factors for length, adjusted to avoid
# changing the magnitude of the counts.
normMat <- normMat/exp(rowMeans(log(normMat)))
normCts <- cts/normMat

# Computing effective library sizes from scaled counts, to account for
# composition biases between samples.
eff.lib <- calcNormFactors(normCts) * colSums(normCts)

# Combining effective library sizes with the length factors, and calculating
# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)

fit <- glmFit(y, design)

lrt <- glmLRT(fit)

topTags(lrt)

summary(decideTests(lrt))

o <- order(lrt$table$PValue)
cpm(y)[o[1:10],]
#+end_src


#+begin_src R
sampleTable = data.frame(cohort_id = c(rep("ms_6wk", 6), rep("ms_sham", 6)))
rownames(sampleTable) = colnames(txi_mm10_ens$counts)

# Create the DESeq2 dataset from tximport-generated gene-level counts
dds = DESeqDataSetFromTximport(txi_mm10_ens, sampleTable, ~ cohort_id)
dds = DESeq(dds)

rld = rlog(dds)
mat = t(assay(rld))
pca = prcomp(mat)

# Get principle component 1 & 2 values
(pve_pc1=round(100*summary(pca)$importance[2,1]))
(pve_pc2=round(100*summary(pca)$importance[2,2]))

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "sample_id") %>%
  mutate(cohort_id = ifelse(grepl("a", sample_id), "ir", "sham")) %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4) +
  theme_cowplot() +
  xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
  ylab(paste("PC2, ", pve_pc2, "% variance explained", sep =""))
pca_plot


#+end_src

- Make tximport summarization from salmon files and UCSC ensemble genes
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
# Setup
##
## Config
if(file.exists(paste0("./config/",as.character(Sys.info()["nodename"]),".R")))
  source(paste0("./config/",as.character(Sys.info()["nodename"]),".R"))
} else
  stop("No config file found")
}

#########1#########2#########3#########4#########5#########6#########7#########8
source(paste0("./config/",as.character(Sys.info()["nodename"]),".R"))

# Create gene-transcript index as tx2gene object from a txdb
txdb = TxDb.Mmusculus.UCSC.mm10.ensGene
k <- keys(txdb, keytype = "TXNAME")
tx2gene <- AnnotationDbi::select(txdb, k, "GENEID", "TXNAME")

# Generate gene counts from salmon files
salmon_paths =
  list.files(
    file.path(data_dir,
              "/card-rad-bio/htcf.wustl.edu/files/NeA8Dxd2/Rentschler_s4730_MGI0070"),
    pattern = "\\.sf$",
    recursive = T,
    full.names = T)
salmon_paths = salmon_paths[!grepl("/a", salmon_paths)]
names(salmon_paths) = gsub("\\..*", "", gsub("^.*MGI0070/", "", salmon_paths))

txi_mm10_ens = tximport(salmon_paths, type = "salmon", tx2gene = tx2gene)
save(txi_mm10_ens, file = file.path(data_dir,"/mouse_hrt_rt_de/txi_mm10_ens.RData"))
#+end_src
- Make sample table
  - Test
    #+begin_src R
sampleTable = data.frame(cohort_id = c("ms_sham","ms_sham","ms_6wk","ms_6wk"),
                         )
rownames(sampleTable) = colnames(txi$counts)
#+end_src
  - Run
- edgeR for CPM and DE
- DESeq2 for DE
  #+begin_src R
dds=DESeqDataSetFromTximport(txi, sampleTable, ~cohort_id)
#+end_src

keep <- rowSums(counts(dds)) > 1
dds_counts <- dds[keep,]

##
#
# Summary
nrow(dds)
nrow(dds_counts)
nrow(dds_cibersort)
#
# Ideas for additional filtering:
## at least 3 samples with a count of 10 or higher
## keep <- rowSums(counts(dds) >= 10) >= 3
## dds <- dds[keep,]
## filter genes without cardiac muscle expression as highest of cell categories
## topcell=colnames(cibersort[,2:8])[apply(cibersort[,2:8], 1, which.max)
## cibersort$topcell=topcell
## head(cibersort)
## table(cibersort$topcell)
  #+end_src
***** Box and whisker phenotype confirmation
  - extract differential expression / accessibility
    - Scn5a ENSMUSG00000032511
    - gja1 ENSMUSG00000050953
  - plot
    #+begin_src R
load(file.path(data_dir,"mouse_cardmyo_nuc_rna/txi_mm10_ens.RData"))
(sampleTable = data.frame(cohort = factor(c(rep("ms_sham", 8), rep("ms_6wk", 8)))))
dds = DESeqDataSetFromTximport(txi_mm10_ens, sampleTable, ~cohort)

test=plotCounts(dds, gene = "ENSMUSG00000032511", intgroup="cohort", returnData=T)

test2 = test %>%
  rownames_to_column(var = "alt_id") %>%
  left_join(nuc_sort_day, by = "alt_id") %>%
  ggplot(.,aes(x = cohort, y = count, label = alt_id, shape = sort_day)) +
  geom_point()
save_plot("/tmp/test.pdf", test2)

test=plotCounts(dds, gene = "ENSMUSG00000050953", intgroup="cohort", returnData=T)

test2 = test %>%
  rownames_to_column(var = "alt_id") %>%
  left_join(nuc_sort_day, by = "alt_id") %>%
  ggplot(.,aes(x = cohort, y = count, label = alt_id, shape = sort_day)) +
  geom_point()
save_plot("/tmp/test.pdf", test2)

load(file.path(data_dir,"mouse_hrt_rt_de/txi_mm10_ens.RData"))
(sampleTable = data.frame(cohort = factor(c(rep("ms_6wk", 6), rep("ms_sham", 6)))))
dds = DESeqDataSetFromTximport(txi_mm10_ens, sampleTable, ~cohort)

test=plotCounts(dds, gene = "ENSMUSG00000032511", intgroup="cohort", returnData=T)
test

test2 = test %>%
  rownames_to_column(var = "alt_id") %>%
  ggplot(.,aes(x = cohort, y = count, label = alt_id)) +
  geom_point()
save_plot("/tmp/test.pdf", test2)


test=plotCounts(dds, gene = "ENSMUSG00000050953", intgroup="cohort", returnData=T)
test

test2 = test %>%
  rownames_to_column(var = "alt_id") %>%
  ggplot(.,aes(x = cohort, y = count, label = alt_id)) +
  geom_point()
save_plot("/tmp/test.pdf", test2)


#########1#########2#########3#########4#########5#########6#########7#########8
pdf("/tmp/test.pdf")
plotCounts(dds, gene = "ENSMUSG00000032511", intgroup="cohort")
dev.off()

load(file.path(data_dir,"atac/macs2_counts.RData"))
load(file.path(data_dir,"atac/anno.RData"))
nrow(assay(macs2_count_list_filt$counts_full_narrow_union))

names(anno_df)
head(anno_df$macs2_full_narrow_union_loess)

(coldata = data.frame(cohort = c("ms_sham","ms_sham","ms_6wk","ms_6wk","ms_6wk","ms_sham")))
row.names(coldata)=colnames(macs2_count_list_filt$counts_full_narrow_union)

dds = DESeqDataSetFromMatrix(countData = assay(macs2_count_list_filt$counts_full_narrow_union),
                             colData = coldata,
                             design = ~ cohort)

pdf("/tmp/test.pdf")
plotCounts(dds, gene = "ENSMUSG00000032511", intgroup="cohort")
dev.off()



class(assay(macs2_count_list_filt$counts_full_narrow_union))

head(macs2_count_list_filt$counts_full_narrow_union)
#+end_src







*** Normalize filtered csaw peaks                                  :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
*** [[file:workflow/chrom_access_opto.smk][Chromatin Accessibility Optimization]]                                :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/chrom_access_opto.smk
:END:
**** Smk preamble
#+begin_src snakemake
CHROM_FILT =  ["regfilt", "open"]
COHORT = ["sham", "ir48h", "ir6w"]
CONTRAST = ["all", "ir6w_sham", "ir48h_sham"]
JOIN = ["union", "intersect", "naive"]
IR48H_LIBS = ["lib008", "lib009", "lib010", "lib012"]
IR6W_LIBS = ["lib003", "lib004", "lib005", "lib006", "lib017", "lib019", "lib021", "lib023", "lib025"]
RUNSAMPLES =  ["lib001", "lib002", "lib003", "lib004", "lib005", "lib006", "lib007", "lib008", "lib009", "lib010", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib025"]
SHAM_LIBS = ["lib001", "lib002", "lib007", "lib013", "lib014", "lib015", "lib016", "lib018", "lib020", "lib022"]
SHAM_LIBS_FILT = ["lib013", "lib014", "lib015", "lib016", "lib018", "lib020", "lib022"]
IR6W_LIBS_FILT = ["lib017", "lib019", "lib021", "lib023", "lib025"]
WIDTH = ["broad", "narrow"]
FILTSAMPLES =  ["lib008", "lib009", "lib010", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib025"]
CALLER = ["csaw", "macs2"]
#+end_src
**** Smk rules
***** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5.bam", cohort = COHORT, chrom_filt = CHROM_FILT),
        expand(config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5_filt.bam", chrom_filt = CHROM_FILT),
        expand(config["data_dir"] + "/atac/bam/ir6w_{chrom_filt}_merged_tn5_filt.bam", chrom_filt = CHROM_FILT),
        expand(config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_filt_peaks.xls", cohort = ["sham", "ir6w"], chrom_filt = CHROM_FILT, width = WIDTH)
        expand(config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}_filt.bed", join=JOIN, chrom_filt=CHROM_FILT, width=WIDTH),
        expand(config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}_filt.bed", join=JOIN, chrom_filt=CHROM_FILT, width=WIDTH),
        expand(config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}_filt.bed",  join=JOIN, chrom_filt=CHROM_FILT, width=WIDTH),
        expand(config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}_filt.rds", contrast = CONTRAST, join=JOIN, chrom_filt=CHROM_FILT, width=WIDTH),
#+end_src
***** DONE Make merged bams                                        :smk_rule:
CLOSED: [2022-02-16 Wed 12:14]
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:14]
:END:
- Snakemake
#+begin_src snakemake
rule make_merged_bams:
    input:
        ir48h =     expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR48H_LIBS),
        ir6w =      expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR6W_LIBS),
        ir6w_filt = expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR6W_LIBS_FILT),
        sham =      expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = SHAM_LIBS),
        sham_filt = expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = SHAM_LIBS_FILT),
    output:
        ir48h = config["data_dir"] + "/atac/bam/ir48h_{chrom_filt}_merged_tn5.bam",
        ir6w = config["data_dir"] + "/atac/bam/ir6w_{chrom_filt}_merged_tn5.bam",
        ir6w_filt = config["data_dir"] + "/atac/bam/ir6w_{chrom_filt}_merged_tn5_filt.bam",
        sham = config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5.bam",
        sham_filt = config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5_filt.bam",
    shell:
        """
        samtools merge -@ {config[threads]} {output.sham} {input.sham}
        samtools merge -@ {config[threads]} {output.ir6w} {input.ir6w}
        samtools merge -@ {config[threads]} {output.ir48h} {input.ir48h}
        samtools merge -@ {config[threads]} {output.sham_filt} {input.sham_filt}
        samtools merge -@ {config[threads]} {output.ir6w_filt} {input.ir6w_filt}
        """
#+end_src

***** DONE MACS2 workflow
CLOSED: [2022-03-01 Tue 12:09]
:LOGBOOK:
- State "DONE"       from              [2022-03-01 Tue 12:09]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
****** DONE Call MACS2                                             :smk_rule:
CLOSED: [2022-02-16 Wed 12:18]
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:18]
:END:
- [[file:/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2]]
- Snakemake
  #+begin_src snakemake
rule call_macs2:
    input:
        config["data_dir"] + "/atac/bam/{library_id}_{chrom_filt}_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{library_id}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
- Reference
  - Function- Narrowpeak as in  cite:corces2018 and cite:hendrickson2017

****** DONE Call MACS2 merged                                      :smk_rule:
CLOSED: [2022-02-25 Fri 15:20]
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:20]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
****** DONE Make MACS2 union consensus peaks                       :smk_rule:
CLOSED: [2022-02-16 Wed 12:49]
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
	ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}.bed",
	ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir48h_{chrom_filt}_{width}.bed",
	ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir6w_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir48h} > {output.ir48h}
        bedops -m {input.ir6w} > {output.ir6w}
        """
#+end_src
****** DONE Make MACS2 intersect consensus peaks                   :smk_rule:
CLOSED: [2022-02-16 Wed 12:52]
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir6w_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir48h} > {output.ir48h}
        bedops --intersect {input.ir6w} > {output.ir6w}
        """
#+end_src

****** DONE Make MACS2 naive peaks                                 :smk_rule:
CLOSED: [2022-02-25 Fri 16:01]
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_peaks.{width}Peak",
	ir6w_merge = config["data_dir"] + "/atac/macs2/ir6w_{chrom_filt}_{width}_peaks.{width}Peak",
	ir48h_merge = config["data_dir"] + "/atac/macs2/ir48h_{chrom_filt}_{width}_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir6w_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir48h_merge} {input.ir48h} > {output.ir48h}
        bedops --element-of 50% {input.ir6w_merge} {input.ir6w} > {output.ir6w}
        """
#+end_src

****** DONE Make cross cohort consenus
CLOSED: [2022-02-25 Fri 16:02]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir6w_{chrom_filt}_{width}.bed",
    output:
        all = config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}.bed",
	ir6w_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}.bed",
	ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} {input.ir6w} > {output.all}
	bedops --merge {input.sham} {input.ir6w} > {output.ir6w_sham}
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
****** DONE BED to GRanges                                         :smk_rule:
CLOSED: [2022-02-25 Fri 16:02]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/{contrast}_{join}_{chrom_filt}_{width}.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/bed_to_granges.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src
***** Filtered bam workflow
****** DONE Call MACS2 merged filtered                             :smk_rule:
CLOSED: [2022-03-01 Tue 12:10]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:10]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged_filtered:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5_filt.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow_filt \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad_filt \
              --outdir {params.outdir}
        """
#+end_src
****** DONE Make MACS2 union filtered consensus peaks              :smk_rule:
CLOSED: [2022-03-01 Tue 12:12]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
	ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}_filt.bed",
	ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir6w} > {output.ir6w}
        """
#+end_src
****** DONE Make MACS2 intersect filtered consensus peaks          :smk_rule:
CLOSED: [2022-03-01 Tue 12:12]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir6w} > {output.ir6w}
        """
#+end_src

****** DONE Make MACS2 naive filtered peaks                        :smk_rule:
CLOSED: [2022-03-01 Tue 12:13]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:13]
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_filt_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_filt_peaks.{width}Peak",
	ir6w_merge = config["data_dir"] + "/atac/macs2/ir6w_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir6w_merge} {input.ir6w} > {output.ir6w}
        """
#+end_src

****** DONE Make cross cohort consenus
CLOSED: [2022-03-01 Tue 12:16]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:16]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_filt_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}_filt.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir6w_{chrom_filt}_{width}_filt.bed",
    output:
        all = config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}_filt.bed",
	ir6w_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}_filt.bed",
	ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}_filt.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} {input.ir6w} > {output.all}
	bedops --merge {input.sham} {input.ir6w} > {output.ir6w_sham}
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
****** DONE BED to GRanges:smk_rule:
CLOSED: [2022-03-01 Tue 12:45]
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:45]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges_filt:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/{contrast}_{join}_{chrom_filt}_{width}_filt.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}_filt.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/bed_to_granges.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src

****** Count from filtered MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_filtered_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}_filt.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/count_from_macs2_consensus.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src

****** Call csaw filtered local peaks                              :smk_rule:
- Library normalization is performed here, so need to re-run on subset
- Snakemake
  #+begin_src snakemake
rule call_csaw_filtered_local_peaks:
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
        filt_libs = "lib008,lib009,lib010,lib012,lib013,lib014,lib015,lib016,lib017,lib018,lib019,lib020,lib021,lib022,lib023,lib025"
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_filt_peaks_rse.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {params.filt_libs} \
        {output.rse} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/call_csaw_local_peaks.R
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
rse = args[4]

filt_libs = unlist(strsplit(filt_libs_str, ","))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
#+end_src
****** DONE Make filtered background bins
CLOSED: [2022-03-01 Tue 09:00]
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-01 Tue 09:00]
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- just need to filter to filt libs
#+begin_src R
library(SummarizedExperiment)

bkbin_open = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_rse.rds")

bkbin_regfilt = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_regfilt_rse.rds")

filt_libs = c("lib008", "lib009", "lib010", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib025")

bkbin_open_filt = bkbin_open[,colnames(bkbin_open) %in% filt_libs]

bkbin_regfilt_filt = bkbin_regfilt[,colnames(bkbin_regfilt) %in% filt_libs]

saveRDS(object = bkbin_open_filt,
        file = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

saveRDS(object = bkbin_regfilt_filt,
        file = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_regfilt_filt_rse.rds")
#+end_src

****** Normalize filtered csaw peaks                               :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
****** Normalize filtered macs2 peaks                              :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src

***** d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src
***** Count, normalize, and DE
****** Count from MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/count_from_macs2_consensus.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
****** Call csaw local peaks                                       :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_csaw_local_peaks:
    input:
        expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = RUNSAMPLES)
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/call_csaw_local_peaks.R
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse = args[3]
dge = args[4]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

edger_input <- asDGEList(filtered_counts)

colnames(edger_input$counts) = colnames(filtered_counts)
rownames(edger_input$samples) = colnames(filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
****** DONE Make background bins:smk_rule:
CLOSED: [2022-02-16 Wed 13:22]
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- Snakemake
#+begin_src snakemake
rule make_background_bins:
    params:
        script = config["repo"] + "/workflow/scripts/make_background_bins.R",
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds"
    log:
        config["data_dir"] + "/logs/make_background_bins_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_background_bins.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/make_background_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make background bins for TMM normalization   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse_file = args[3]

library(csaw)

standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)


bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))


binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

saveRDS(object = binned,
        file = rse_file)
#+end_src
****** Normalize                                                   :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-02-16 Wed 13:25] \\
  waiting for counts to finish
:END:
  #+begin_src R
#!/usr/bin/env Rscript
library(csaw)
library(edgeR)

peaks_rse = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds")

bk = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

tmm = normFactors(bk, se.out = peaks_rse)

loess = normOffsets(peaks_rse, se.out = TRUE)

#########1#########2#########3#########4#########5#########6#########7#########8

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

norm_tmm_logcpm = make_logcpm(tmm)
norm_loess_logcpm = make_logcpm(loess)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

make_pca = function(in_cpm){
  pca_out = prcomp(t(in_cpm))
}

pca_list = lapply(cpm_list, make_pca)

make_pca_plots = function(in_pca, full_libs){
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(full_libs, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")
  return(pca_plot)
}

pca_plot_list = lapply(pca_list, make_pca_plots, libraries_full)

legend = get_legend(pca_plot_list[[1]]+
                        guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom")
)

pre_pca_plot_grid = plot_grid(plotlist = pca_plots, labels = names(pca_list))
pre_pca_plot_grid

pca_plot_grid = plot_grid(pre_pca_plot_grid, legend, ncol = 1, rel_heights = c(1,.1))

save_plot("./results/imgs/cpm_pca.pdf", pca_plot_grid,
          base_height = 20, base_width = 20)

#+end_src

- Snakemake
  #+begin_src snakemake
rule normalize:
    input:
        counts = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        bk = config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_tmm_rse.rds",
        loess = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_loess_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_macs2_{join}_{chrom_filt}_{width}_norm.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/normalize.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Normalize peak counts   ###
###

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

in_counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/macs2_all_intersect_open_broad_peaks_rse.rds")

test =make_logcpm(in_counts)

in_norm = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_intersect_open_broad_tmm_rse.rds")

dge = asDGEList(in_norm)

in_norm

head(assays(in_norm)$counts)

colnames(dge) = colnames(in_norm)

# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)



tmm_logcpm = make_logcpm(tmm)



loess_logcpm = make_logcpm(loess)

head(tmm_logcpm)

colnames(tmm)
colnames(test2) = colnames(norm)

pca = prcomp(t(test2))

summary(pca)


saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
***** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./workflow/scripts/edger.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/edger.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src
***** Reference
- https://mail.google.com/mail/u/0/#inbox/FMfcgzGlkPSkLCSSZzbsHgHQJfDzVHhN
- [[https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt][reske2020 scripts]]

***** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
****** Make MACS2 consensus peaks:smk_rule:
- Snakemake
#+begin_src snakemake
rule make_macs2_consensus_peaks:
    input:
	expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_granges.rds")
    params:
        script = config["repo"] + "/workflow/scripts/make_macs2_consensus_peaks.R"
    output:
    log:
        config["data_dir"] + "/logs/make_macs2_consensus_peaks.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_macs2_consensus_peaks.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/make_macs2_consensus_peaks.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Makes consensus peak sets from GRanges MACS2 peaks   ###
###

peaks = list.files(path = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2",
                   pattern = "regfilt_narrow.*rds$",
                   full.names = TRUE)
names(peaks) = gsub(".rds","",list.files(path = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2",
                   pattern = "regfilt_narrow.*rds$",
                   full.names = FALSE))

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

sham_libs =
 libraries_full %>%
 filter(lib_typ == "atac") %>%
 filter(cohort_id == "sham") %>%
 pull(library_id)
sham_peaks_list = grep(paste(sham_libs, collapse = "|"), peaks, value = TRUE)

sham_peaks_list = lapply(sham_peaks_list, readRDS)

library(GenomicRanges)

library(GenomicAlignments)

gr1 = sham_peaks_list[[1]]
gr2 = sham_peaks_list[[2]]

test = subsetByOverlaps(gr1, gr2, ignore.strand = TRUE)

test


test = GRangesList(unlist(sham_peaks_list))

test2 = summarizeOverlaps(gr1, test, mode = )

head(assays(test2)$counts, n = 100)

sham_peaks = GenomicRanges::union(unlist(sham_peaks_list))

test = c(sham_peaks_list[[1]], sham_peaks_list[[2]])

test = sham_peaks_list[1][sham_peaks_list[1] %over% sham_peaks_list[2]]

sham_peaks_list[[1]] %over% sham_peaks_list[[2]] %over% sham_peaks_list[[3]]

union(sham_peaks_list[[1]]

sham_peaks_list
sham_peaks = GenomicRanges::union(unlist(sham_peaks_list))

test = unlist(sham_peaks_list)

class(test)


head(test
     )
head(unlist(sham_peaks_list))

test = union(sham_peaks_list[[1]],sham_peaks_list[[2]])

test = for (i in sham_peaks_list) {union(i)}



test = for (i in 1:length(sham_peaks_list)) {union (sham_peaks_list[[i]])}

union(i )
length(sham_peaks_list)

ir6w_libs =
  libraries_full %>%
  filter(lib_typ == "atac") %>%
  filter(cohort_id == "ir6w") %>%
  pull(library_id)
ir6w_peaks = grep(paste(ir6w_libs, collapse = "|"), peaks, value = TRUE)

ir48h_libs =
  libraries_full %>%
  filter(lib_typ == "atac") %>%
  filter(cohort_id == "ir48h") %>%
  pull(library_id)
ir48h_peaks = grep(paste(ir48h_libs, collapse = "|"), peaks, value = TRUE)

#+end_src

**** Carry forward csaw and do sensitivity analysis with rna
For open vs total x loess vs tmm

Annotate, do sense vs rna
#+begin_src R
library(csaw)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

library(csaw)

standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)


bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))


binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)


library(GenomicRanges)

peaks = read.table("/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2_consensus_beds/all_intersect_open_broad.bed", sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)
granges


all.peaks = granges

pe.bams=c("/mnt/ris/jschwarz/cardiac-radiobiology/atac/bam/lib001_open_tn5.bam","/mnt/ris/jschwarz/cardiac-radiobiology/atac/bam/lib002_open_tn5.bam")

pe.bams =
  list.files("/mnt/ris/jschwarz/cardiac-radiobiology/atac/bam",
           pattern = "_open_tn5.bam$",
           full.names = T)

names(pe.bams) = gsub("_.*$","",  list.files("/mnt/ris/jschwarz/cardiac-radiobiology/atac/bam",
           pattern = "_open_tn5.bam$",
           full.names = F))

peak.counts <- regionCounts(pe.bams, all.peaks, param=param)

save(peak.counts, file = "/tmp/peak.counts.RData")
load("/tmp/peak.counts.RData")
peak.counts

colData(peak.counts)

library(DESeq2)

group =
  data.frame(library_id = colnames(peak.counts)) %>%
  left_join(libraries_full, by = "library_id") %>%
  pull(cohort_id)
group = as.character(group)

colData(peak.counts)$group = group

peakssub = subset(peak.counts, select = !(colnames(peak.counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))

dds = DESeqDataSet(peakssub, design = ~ group)

dds = DESeq(dds)

resultsNames(dds)

test = as.data.frame(DESeq2::results(dds, name = "group_sham_vs_ir48h"))

head(test)

summary(test$log2FoldChange)

summary(test$padj)

length(test$padj[test$padj < 0.1])

#########1#########2#########3#########4#########5#########6#########7#########8
##############################
# MACS2 peaks only: filter low abundance peaks
library("edgeR")
peak.abundances <- aveLogCPM(asDGEList(peak.counts))
peak.counts.filt <- peak.counts[peak.abundances > -3, ] # only use peaks logCPM > -3
# few or no peaks should be removed; modify as desired

##########################################
# NORMALIZATION

# method 1: MACS2 peaks only, TMM normalization based on binned counts
peak.counts.tmm <- peak.counts.filt
peak.counts.tmm <- normFactors(binned, se.out=peak.counts.tmm)
peak.counts.tmm

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
load("/tmp/working.windows.RData")
colData(working.windows)
colData(working.windows)$group = group

counts = working.windows
# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")
library(tidyverse)
# setup design matrix
# see edgeR manual for more information

colnames(y$counts) = names(counts$bam.files)
rownames(y$samples) = names(counts$bam.files)

groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups

colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 500)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = names(counts$bam.files)
rownames(y$samples) = names(counts$bam.files)

rownames(y$samples)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 100)

plotMDS(y, col = colors, top = 500)

(design <- model.matrix(~group, data=y$samples))

colnames(design) = levels(groups)
groups

groups = factor(groups, levels = c("sham", "ir48h", "ir6w"))
levels(groups)

design = model.matrix(~0 + groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

save(y, design, file = "/tmp/y.RData")

load("/tmp/y.RData")

library(edgeR)

if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("DEFormats")

library(DEFormats)
library(DESeq2)

dds = as.DESeqDataSet(y)

dds = DESeq(dds)

resultsNames(dds)

test = as.data.frame(DESeq2::results(dds))

head(test)

summary(test$log2FoldChange)

summary(test$padj)

length(test$padj[test$padj < 0.1])

res = as.data.frame(DESeq2::results(dds, contrast = c("group", "ir6wk", "sham")))

y
fit <- glmQLFit(y, design, robust=TRUE)

fit$design
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(groupir6w-(Intercept), levels=design))

# head(results$table)

library(GenomicRanges)
library(csaw)

head(results$table)
summary(results$table$logFC)
summary(results$table$PValue)
ggplot(results$table, aes(x = PValue)) + geom_density()
# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
summary(tab.best$logFC)
ggplot(tab.best
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)
#+end_src

*** [[file:workflow/peak_call_and_norm.smk][Peak calling and normalization]]                                      :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/peak_call_and_norm.smk
:END:
**** DONE Call MACS2 narrow                                           :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_macs2_narrow:
    input:
        config["data_dir"] + "/bam/{library_id}_{bam_process}_tn5.bam",
    output:
        expand(config["data_dir"] + "/macs2/{{library_id}}_{{bam_process}}_{ext}", ext = MACS_NARROW_EXT)
    shell:
        """
        base=$(echo $(basename {input}) | sed 's/_tn5.*$//g')
        workflow/scripts/call_macs2_narrow.sh {input} ${{base}} "{config[data_dir]}/macs2"
        """
#+end_src
- Script
  #+begin_src bash :tangle ./workflow/scripts/call_macs2_narrow.sh
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8
# Check for parameters, return usage if empty
if [[ "$#" -ne 3 ]];
then
    printf "\n usage: call_macs2_broad <BAM FILE> <OUTPUT BASENAME> <OUTPUT DIRECTORY>
    \n Wrapper function for calling broad beaks from ATAC-seq data with MACS2
    \n "
elif
    [[ ! -f "${1}.bai" ]]; then echo "No index for $1"
else
    macs2 callpeak \
          --bdg \
          --call-summits \
          --extsize 150 \
          --format BAMPE \
          --gsize mm \
          --keep-dup all \
          --name $2 \
          --nolambda \
          --nomodel \
          --outdir $3 \
          --SPMR \
          --treatment $1
fi
#+end_src
**** DONE Call MACS2 broad                                            :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_macs2_broad:
    input:
        config["data_dir"] + "/bam/{library_id}_{bam_process}_tn5.bam",
    output:
        expand(config["data_dir"] + "/macs2/{{library_id}}_{{bam_process}}_{ext}", ext = MACS_BROAD_EXT)
    shell:
        """
        base=$(echo $(basename {input}) | sed 's/_tn5.*$//g')
        workflow/scripts/call_macs2_broad.sh {input} ${{base}} "{config[data_dir]}/macs2"
        """
#+end_src
- [[file:workflow/scripts/call_macs2_broad.sh][Script]]
  #+begin_src bash :tangle ./workflow/scripts/call_macs2_broad.sh
#!/usr/bin/env bash
#########1#########2#########3#########4#########5#########6#########7#########8
# Check for parameters, return usage if empty
if [[ "$#" -ne 3 ]];
then
    printf "\n usage: call_macs2_broad <BAM FILE> <OUTPUT BASENAME> <OUTPUT DIRECTORY>
    \n Wrapper function for calling broad beaks from ATAC-seq data with MACS2
    \n "
elif
    [[ ! -f "${1}.bai" ]]; then echo "No index for $1"
else
    macs2 callpeak \
          --broad \
          --broad-cutoff 0.05 \
          --format BAMPE \
          --gsize mm \
          --keep-dup all \
          --name $2 \
          --outdir $3 \
          --treatment $1
fi
#+end_src
- Function- Broadpeak as in  cite:corces2018 and cite:hendrickson2017
**** DONE Peak calling, all samples                                   :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    input:
        expand(config["bam_dir"] + "/{library_id}_{{bam_process}}_tn5.bam", library_id = LIBRARY_IDS)
    params:
        script = config["atac_scripts_dir"] + "/select_window_size.R",
	groups_str = "ir48h ir48h sham sham"
    output:
        norm_counts_rse = config["data_dir"] + "/csaw/norm_counts_rse_{bam_process}.rds",
        dge = config["data_dir"] + "/csaw/dge_{bam_process}.rds",
    log:
        config["log_dir"] + "/make_peak_counts_{bam_process}.log",
    shell:
        """
        Rscript {params.script} \
        "{input}" \
        {config[threads]} \
        {output.norm_counts_rse} \
        {output.dge} \
        {params.groups_str} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/select_window_size.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/select_window_size.R

#############################################################################
###            Script for csaw ATAC-seq local peak calling                ###
#############################################################################

# Setup

## Test arguements
## groups_str = "ir48h ir48h sham sham"
## library_ids_str = "/home/jeszyman/repos/atac-seq/test/bam/atac1_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac2_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac3_open_tn5.bam /home/jeszyman/repos/atac-seq/test/bam/atac4_open_tn5.bam"
## out_rse_rds = "/home/jeszyman/repos/atac-seq/test/csaw/norm_counts_rse.rds"
## out_dge_rds = "/home/jeszyman/repos/atac-seq/test/csaw/dge.rds"
## threads = 4

## Command line arguements
args = commandArgs(trailingOnly = TRUE)
library_ids_str = args[1]
threads = args[2]
out_rse_rds = args[3]
out_dge_rds = args[4]
groups_str = args[5]

## Load packages
library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

# Specify csaw window parameters
surrounds = 2000
autosomes <- paste0("chr", c(1:19)) # only use autosomes
param = readParam(max.frag=1000, pe="both", restrict=autosomes)

# Make bam file list
bam_list = unlist(strsplit(library_ids_str, " "))
names(bam_list) = gsub("^.*/","",bam_list)

# Filter per Reske JJ, et al. 2021. https://doi.org/10.1186/s13072-020-00342-y

## Choose window width by fragment size distribution
csaw_choose_window = function(bam_list){
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

# Remove dimnames to avoid SummarizedExperiment error in window filtering
dimnames(wider) = NULL
dimnames(counts) = NULL

filter_stat = filterWindowsLocal(counts, wider, assay.data = "counts")

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

# Return library names
colnames(filtered_counts) = names(bam_list)
colnames(background) = names(bam_list)

filtered_counts = normFactors(background, se.out = filtered_counts)

y = asDGEList(filtered_counts)
colnames(y$counts) = colnames(filtered_counts)
rownames(y$samples) = colnames(filtered_counts)

groups = as.factor(unlist(strsplit(groups_str, " ")))
y$samples$group = groups

# Save outputs
saveRDS(object = filtered_counts,
        file = out_rse_rds)
saveRDS(object = y,
        file = out_dge_rds)
#+end_src
**** DONE Percent of genome open
- Snakemake
  #+begin_src snakemake
rule open_genome:
    input:
        config["data_dir"] + "/bam/{library_id}_open_tn5.bam",
    params:
        genome_bed = "resources/mm10.bed",
    output:
        config["data_dir"] + "/open_chrom/{library_id}_open_chrom.txt"
    shell:
        """
        bedmap --echo --bases-uniq --delim '\t' {params.genome_bed} {input} | awk 'BEGIN {{ genome_length = 0; masked_length = 0; }} {{ genome_length += ($3 - $2); masked_length += $4; }} END {{ print (masked_length / genome_length); }}' > {output}
        """
#+end_src
- https://www.biostars.org/p/219099/
  #+begin_src bash
singularity shell --help
singularity shell --bind /mnt/:/mnt/ ~/sing_containers/atac.sif

fract(){
    bedmap --echo --bases-uniq --delim '\t' ~/repos/atac-seq/resources/mm10.bed $1 | awk 'BEGIN { genome_length = 0; masked_length = 0; } { genome_length += ($3 - $2); masked_length += $4; } END { print (masked_length / genome_length); }'
}

if [ -f /mnt/ris/jschwarz/cardiac-radiobiology/atac/fract_open.txt ]; then
    \rm -rf /mnt/ris/jschwarz/cardiac-radiobiology/atac/fract_open.txt
fi

touch /mnt/ris/jschwarz/cardiac-radiobiology/atac/fract_open.txt

for file in /mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2/lib*open*narrowPeak; do
    echo "$(basename $file) $(fract $file)" >> /mnt/ris/jschwarz/cardiac-radiobiology/atac/fract_open.txt
done

head /mnt/ris/jschwarz/cardiac-radiobiology/atac/frac_open.txt

cp /mnt/ris/jschwarz/cardiac-radiobiology/atac/frac_open.txt
#+end_src
*** Development                                                         :dev:
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
do this one as agg rule
bamfile.labels <- gsub(".bam", "", basename(bamfile))
fragSize = fragSizeDist(bamfile, bamfile.labels)
fragsize = data.frame(len=, cnt


**** MultiQC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule multiqc:
    input:
    output:
    shell:
        """
        scripts/multiqc.sh
        """
#+end_src
- [[file:./workflow/scripts/multiqc.sh][Base script]]
  #+begin_src bash
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

# Snakemake variables
# Function
# Run command
#########1#########2#########3#########4#########5#########6#########7#########8
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

#+end_src
*** Filtered bam workflow
**** Call MACS2 merged filtered                                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:10]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged_filtered:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5_filt.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow_filt \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad_filt \
              --outdir {params.outdir}
        """
#+end_src
**** Make MACS2 union filtered consensus peaks                     :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
	ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}_filt.bed",
	ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir6w} > {output.ir6w}
        """
#+end_src
**** Make MACS2 intersect filtered consensus peaks                 :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir6w} > {output.ir6w}
        """
#+end_src

**** Make MACS2 naive filtered peaks                               :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:13]
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_filt_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_filt_peaks.{width}Peak",
	ir6w_merge = config["data_dir"] + "/atac/macs2/ir6w_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir6w_merge} {input.ir6w} > {output.ir6w}
        """
#+end_src

**** Make cross cohort consenus
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:16]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_filt_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}_filt.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir6w_{chrom_filt}_{width}_filt.bed",
    output:
        all = config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}_filt.bed",
	ir6w_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}_filt.bed",
	ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}_filt.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} {input.ir6w} > {output.all}
	bedops --merge {input.sham} {input.ir6w} > {output.ir6w_sham}
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
**** BED to GRanges:smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:45]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges_filt:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/{contrast}_{join}_{chrom_filt}_{width}_filt.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}_filt.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/bed_to_granges.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src

**** Count from filtered MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_filtered_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}_filt.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/count_from_macs2_consensus.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src

**** Call csaw filtered local peaks                                :smk_rule:
- Library normalization is performed here, so need to re-run on subset
- Snakemake
  #+begin_src snakemake
rule call_csaw_filtered_local_peaks:
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
        filt_libs = "lib008,lib009,lib010,lib012,lib013,lib014,lib015,lib016,lib017,lib018,lib019,lib020,lib021,lib022,lib023,lib025"
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_filt_peaks_rse.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {params.filt_libs} \
        {output.rse} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/call_csaw_local_peaks.R
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
rse = args[4]

filt_libs = unlist(strsplit(filt_libs_str, ","))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
#+end_src
**** Normalize filtered macs2 peaks                                :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src

*** Normalize                                                      :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-02-16 Wed 13:25] \\
  waiting for counts to finish
:END:
  #+begin_src R
#!/usr/bin/env Rscript
library(csaw)
library(edgeR)

peaks_rse = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds")

bk = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

tmm = normFactors(bk, se.out = peaks_rse)

loess = normOffsets(peaks_rse, se.out = TRUE)

#########1#########2#########3#########4#########5#########6#########7#########8

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

norm_tmm_logcpm = make_logcpm(tmm)
norm_loess_logcpm = make_logcpm(loess)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

make_pca = function(in_cpm){
  pca_out = prcomp(t(in_cpm))
}

pca_list = lapply(cpm_list, make_pca)

make_pca_plots = function(in_pca, full_libs){
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(full_libs, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")
  return(pca_plot)
}

pca_plot_list = lapply(pca_list, make_pca_plots, libraries_full)

legend = get_legend(pca_plot_list[[1]]+
                        guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom")
)

pre_pca_plot_grid = plot_grid(plotlist = pca_plots, labels = names(pca_list))
pre_pca_plot_grid

pca_plot_grid = plot_grid(pre_pca_plot_grid, legend, ncol = 1, rel_heights = c(1,.1))

save_plot("./results/imgs/cpm_pca.pdf", pca_plot_grid,
          base_height = 20, base_width = 20)

#+end_src

- Snakemake
  #+begin_src snakemake
rule normalize:
    input:
        counts = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        bk = config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_tmm_rse.rds",
        loess = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_loess_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_macs2_{join}_{chrom_filt}_{width}_norm.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/normalize.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Normalize peak counts   ###
###

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

in_counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/macs2_all_intersect_open_broad_peaks_rse.rds")

test =make_logcpm(in_counts)

in_norm = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_intersect_open_broad_tmm_rse.rds")

dge = asDGEList(in_norm)

in_norm

head(assays(in_norm)$counts)

colnames(dge) = colnames(in_norm)

# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)



tmm_logcpm = make_logcpm(tmm)



loess_logcpm = make_logcpm(loess)

head(tmm_logcpm)

colnames(tmm)
colnames(test2) = colnames(norm)

pca = prcomp(t(test2))

summary(pca)


saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
*** Make background bins:smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- Snakemake
#+begin_src snakemake
rule make_background_bins:
    params:
        script = config["repo"] + "/workflow/scripts/make_background_bins.R",
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds"
    log:
        config["data_dir"] + "/logs/make_background_bins_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_background_bins.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/make_background_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make background bins for TMM normalization   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse_file = args[3]

library(csaw)

standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)


bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))


binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

saveRDS(object = binned,
        file = rse_file)
#+end_src
*** Count from MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/count_from_macs2_consensus.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
*** Call csaw local peaks                                          :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_csaw_local_peaks:
    input:
        expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = RUNSAMPLES)
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/call_csaw_local_peaks.R
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse = args[3]
dge = args[4]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

edger_input <- asDGEList(filtered_counts)

colnames(edger_input$counts) = colnames(filtered_counts)
rownames(edger_input$samples) = colnames(filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
*** Make merged bams                                               :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:18]
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:16]
- State "DONE"       from              [2022-02-16 Wed 12:14]
:END:
- Snakemake
#+begin_src snakemake
rule make_merged_bams:
    input:
        ir48h =     expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR48H_LIBS),
        sham =      expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = SHAM_LIBS),
    output:
        ir48h = config["data_dir"] + "/atac/bam/ir48h_{chrom_filt}_merged_tn5.bam",
        sham = config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5.bam",
    shell:
        """
        samtools merge -@ {config[threads]} {output.sham} {input.sham}
        samtools merge -@ {config[threads]} {output.ir48h} {input.ir48h}
        """
#+end_src

*** Call MACS2                                                     :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:31]
- State "DONE"       from              [2022-02-16 Wed 12:18]
:END:
- [[file:/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2]]
- Snakemake
  #+begin_src snakemake
rule call_macs2:
    input:
        config["data_dir"] + "/atac/bam/{library_id}_{chrom_filt}_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{library_id}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
- Reference
  - Function- Narrowpeak as in  cite:corces2018 and cite:hendrickson2017
*** Call MACS2 merged                                              :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:20]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
*** Make MACS2 union consensus peaks                               :smk_rule:
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}.bed",
	ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir48h} > {output.ir48h}
        """
#+end_src
*** Make MACS2 intersect consensus peaks                           :smk_rule:
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir48h} > {output.ir48h}
        """
#+end_src

*** Make MACS2 naive peaks                                         :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_peaks.{width}Peak",
	ir48h_merge = config["data_dir"] + "/atac/macs2/ir48h_{chrom_filt}_{width}_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir48h_merge} {input.ir48h} > {output.ir48h}
        """
#+end_src

*** [#Y] Make cross cohort consenus
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
    output:
        ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
*** BED to GRanges                                                 :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/ir48h_sham_{join}_{chrom_filt}_{width}.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/bed_to_granges.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src



*** Pass config list test                                          :smk_rule:
- Snakemake
  #+begin_src snakemake
rule pass_config_list_test:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/pass_config_list_test.R",
        #thelist = expand("{sample}", sample = config["IR48H_V_SHAM"]),
        thelist = config["IR48H_V_SHAM"],
    output:
        config["data_dir"] + "/tmp/test.RData"
    log:
        config["data_dir"] + "/logs/pass_config_list_test.log"
    shell:
        """
        thevar="{params.thelist}"
        #echo "{params.thelist}" > {output}
        Rscript {params.script} \
        "${{thevar}}" \
        {output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/pass_config_list_test.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/pass_config_list_test.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###    SCRIPT TITLE   ###
###

args = commandArgs(trailingOnly = TRUE)
passed_list = args[1]
saveloc = args[2]


filt_libs_raw = passed_list
filt_libs = unlist(strsplit(filt_libs_raw, " "))
saveloc = "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/test.RData"

save(filt_libs_raw,
     file = saveloc)
#+end_src
*** Make MACS2 intersect consensus peaks                           :smk_rule:
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir48h} > {output.ir48h}
        """
#+end_src
*** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./workflow/scripts/edger.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/edger.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src

*** d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src
*** Make merged bams                                               :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:18]
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:16]
- State "DONE"       from              [2022-02-16 Wed 12:14]
:END:
- Snakemake
#+begin_src snakemake
rule make_merged_bams:
    input:
        ir48h =     expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = IR48H_LIBS),
        sham =      expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = SHAM_LIBS),
    output:
        ir48h = config["data_dir"] + "/atac/bam/ir48h_{chrom_filt}_merged_tn5.bam",
        sham = config["data_dir"] + "/atac/bam/sham_{chrom_filt}_merged_tn5.bam",
    shell:
        """
        samtools merge -@ {config[threads]} {output.sham} {input.sham}
        samtools merge -@ {config[threads]} {output.ir48h} {input.ir48h}
        """
#+end_src

*** Call MACS2                                                     :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-10 Thu 11:31]
- State "DONE"       from              [2022-02-16 Wed 12:18]
:END:
- [[file:/mnt/ris/jschwarz/cardiac-radiobiology/atac/macs2]]
- Snakemake
  #+begin_src snakemake
rule call_macs2:
    input:
        config["data_dir"] + "/atac/bam/{library_id}_{chrom_filt}_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{library_id}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.library_id}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
- Reference
  - Function- Narrowpeak as in  cite:corces2018 and cite:hendrickson2017
*** Call MACS2 merged                                              :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:20]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_peaks.xls",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad \
              --outdir {params.outdir}
        """
#+end_src
*** Make MACS2 union consensus peaks                               :smk_rule:
:LOGBOOK:
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}.bed",
	ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir48h} > {output.ir48h}
        """
#+end_src
*** Make MACS2 naive peaks                                         :smk_rule:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS),
        ir48h = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR48H_LIBS),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_peaks.{width}Peak",
	ir48h_merge = config["data_dir"] + "/atac/macs2/ir48h_{chrom_filt}_{width}_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir48h_{chrom_filt}_{width}.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir48h_merge} {input.ir48h} > {output.ir48h}
        """
#+end_src

*** Make cross cohort consenus
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
    output:
        ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
*** BED to GRanges                                                 :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/ir48h_sham_{join}_{chrom_filt}_{width}.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/bed_to_granges.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src


*** Count, normalize, and DE
**** Count from MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/count_from_macs2_consensus.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
**** Call csaw local peaks                                         :smk_rule:
- Snakemake
  #+begin_src snakemake
rule call_csaw_local_peaks:
    input:
        expand(config["data_dir"] + "/atac/bam/{library_id}_{{chrom_filt}}_tn5.bam", library_id = RUNSAMPLES)
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_local_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_rse.rds",
        dge = config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_csaw_peaks_dge.rds",
    log:
        config["data_dir"] + "/logs/call_csaw_local_peaks_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/call_csaw_local_peaks.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/call_csaw_local_peaks.R
#########1#########2#########3#########4#########5#########6#########7#########8

#######################################################################
###    Script to call ATAC-seq peaks using local windows in csaw    ###
#######################################################################

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse = args[3]
dge = args[4]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list, width = window, param = param)

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list, regions = neighbor, param = param)

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list, bin=TRUE, width=10000, param = param)

filtered_counts = normFactors(background, se.out = filtered_counts)

edger_input <- asDGEList(filtered_counts)

colnames(edger_input$counts) = colnames(filtered_counts)
rownames(edger_input$samples) = colnames(filtered_counts)

saveRDS(object = filtered_counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src
**** Make background bins:smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- Snakemake
#+begin_src snakemake
rule make_background_bins:
    params:
        script = config["repo"] + "/workflow/scripts/make_background_bins.R",
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds"
    log:
        config["data_dir"] + "/logs/make_background_bins_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_background_bins.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/make_background_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make background bins for TMM normalization   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
rse_file = args[3]

library(csaw)

standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)


bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))


binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

saveRDS(object = binned,
        file = rse_file)
#+end_src
**** Normalize                                                     :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-02-16 Wed 13:25] \\
  waiting for counts to finish
:END:
  #+begin_src R
#!/usr/bin/env Rscript
library(csaw)
library(edgeR)

peaks_rse = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds")

bk = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

tmm = normFactors(bk, se.out = peaks_rse)

loess = normOffsets(peaks_rse, se.out = TRUE)

#########1#########2#########3#########4#########5#########6#########7#########8

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

norm_tmm_logcpm = make_logcpm(tmm)
norm_loess_logcpm = make_logcpm(loess)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

make_pca = function(in_cpm){
  pca_out = prcomp(t(in_cpm))
}

pca_list = lapply(cpm_list, make_pca)

make_pca_plots = function(in_pca, full_libs){
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(full_libs, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")
  return(pca_plot)
}

pca_plot_list = lapply(pca_list, make_pca_plots, libraries_full)

legend = get_legend(pca_plot_list[[1]]+
                        guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom")
)

pre_pca_plot_grid = plot_grid(plotlist = pca_plots, labels = names(pca_list))
pre_pca_plot_grid

pca_plot_grid = plot_grid(pre_pca_plot_grid, legend, ncol = 1, rel_heights = c(1,.1))

save_plot("./results/imgs/cpm_pca.pdf", pca_plot_grid,
          base_height = 20, base_width = 20)

#+end_src

- Snakemake
  #+begin_src snakemake
rule normalize:
    input:
        counts = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        bk = config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_tmm_rse.rds",
        loess = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_loess_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_macs2_{join}_{chrom_filt}_{width}_norm.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/normalize.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Normalize peak counts   ###
###

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

in_counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/macs2_all_intersect_open_broad_peaks_rse.rds")

test =make_logcpm(in_counts)

in_norm = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_intersect_open_broad_tmm_rse.rds")

dge = asDGEList(in_norm)

in_norm

head(assays(in_norm)$counts)

colnames(dge) = colnames(in_norm)

# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)



tmm_logcpm = make_logcpm(tmm)



loess_logcpm = make_logcpm(loess)

head(tmm_logcpm)

colnames(tmm)
colnames(test2) = colnames(norm)

pca = prcomp(t(test2))

summary(pca)


saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
*** Filtered bam workflow
**** Call MACS2 merged filtered                                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:10]
:END:
- Snakemake
#+begin_src snakemake
rule call_macs2_merged_filtered:
    input:
        config["data_dir"] + "/atac/bam/{cohort}_{chrom_filt}_merged_tn5_filt.bam",
    params:
        outdir = config["data_dir"] + "/atac/macs2"
    output:
        config["data_dir"] + "/atac/macs2/{cohort}_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    shell:
        """
        macs2 callpeak --treatment {input} \
              --bdg \
              --call-summits \
              --extsize 150 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_narrow_filt \
              --nolambda \
              --nomodel \
              --outdir {params.outdir} \
              --SPMR
        #
        macs2 callpeak --treatment {input} \
              --broad \
              --broad-cutoff 0.05 \
              --format BAMPE \
              --gsize mm \
              --keep-dup all \
              --name {wildcards.cohort}_{wildcards.chrom_filt}_broad_filt \
              --outdir {params.outdir}
        """
#+end_src
**** Make MACS2 union filtered consensus peaks                     :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:49]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_union_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
	ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/union_sham_{chrom_filt}_{width}_filt.bed",
	ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/union_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops -m {input.sham} > {output.sham}
        bedops -m {input.ir6w} > {output.ir6w}
        """
#+end_src
**** Make MACS2 intersect filtered consensus peaks                 :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:12]
- State "DONE"       from              [2022-02-16 Wed 12:52]
:END:
- Snakemake
#+begin_src snakemake
rule make_macs2_intersect_filtered_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/intersect_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --intersect {input.sham} > {output.sham}
        bedops --intersect {input.ir6w} > {output.ir6w}
        """
#+end_src

**** Make MACS2 naive filtered peaks                               :smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:13]
- State "DONE"       from "TODO"       [2022-02-25 Fri 16:01]
- State "DONE"       from "INPROCESS"  [2022-02-25 Fri 15:35]
- State "WAITING"    from              [2022-02-16 Wed 12:52] \\
  waiting on macs2 of merged bams
:END:
- Snakemake
  #+begin_src snakemake
rule make_macs2_naive_filt_consensus_peaks:
    input:
        sham = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = SHAM_LIBS_FILT),
        ir6w = expand(config["data_dir"] + "/atac/macs2/{library_id}_{{chrom_filt}}_{{width}}_peaks.{{width}}Peak", library_id = IR6W_LIBS_FILT),
	sham_merge = config["data_dir"] + "/atac/macs2/sham_{chrom_filt}_{width}_filt_peaks.{width}Peak",
	ir6w_merge = config["data_dir"] + "/atac/macs2/ir6w_{chrom_filt}_{width}_filt_peaks.{width}Peak",
    output:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/naive_sham_{chrom_filt}_{width}_filt.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/naive_ir6w_{chrom_filt}_{width}_filt.bed",
    shell:
        """
        bedops --element-of 50% {input.sham_merge} {input.sham} > {output.sham}
        bedops --element-of 50% {input.ir6w_merge} {input.ir6w} > {output.ir6w}
        """
#+end_src

**** Make cross cohort consenus
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:16]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule make_cross_cohort_filt_consensus:
    input:
        sham = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_sham_{chrom_filt}_{width}_filt.bed",
        ir48h = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir48h_{chrom_filt}_{width}.bed",
        ir6w = config["data_dir"] + "/atac/macs2_consensus_beds/{join}_ir6w_{chrom_filt}_{width}_filt.bed",
    output:
        all = config["data_dir"] + "/atac/macs2_consensus_beds/all_{join}_{chrom_filt}_{width}_filt.bed",
	ir6w_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir6w_sham_{join}_{chrom_filt}_{width}_filt.bed",
	ir48h_sham = config["data_dir"] + "/atac/macs2_consensus_beds/ir48h_sham_{join}_{chrom_filt}_{width}_filt.bed",
    shell:
        """
	bedops --merge {input.sham} {input.ir48h} {input.ir6w} > {output.all}
	bedops --merge {input.sham} {input.ir6w} > {output.ir6w_sham}
	bedops --merge {input.sham} {input.ir48h} > {output.ir48h_sham}
        """
#+end_src
**** BED to GRanges:smk_rule:
:LOGBOOK:
- State "DONE"       from "RUN"        [2022-03-01 Tue 12:45]
- State "DONE"       from "RUN"        [2022-02-25 Fri 16:02]
:END:
- Snakemake
  #+begin_src snakemake
rule bed_to_granges_filt:
    input:
        config["data_dir"] + "/atac/macs2_consensus_beds/{contrast}_{join}_{chrom_filt}_{width}_filt.bed",
    params:
        script = config["repo"] + "/workflow/scripts/bed_to_granges.R"
    output:
        config["data_dir"] + "/atac/macs2_consensus_granges/{contrast}_{join}_{chrom_filt}_{width}_filt.rds",
    log:
        config["data_dir"] + "/logs/bed_to_granges_{contrast}_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/bed_to_granges.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/bed_to_granges.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

##################################################
###    Converts BED files to GRanges objects   ###
##################################################

args = commandArgs(trailingOnly = TRUE)
bed = args[1]
granges_file = args[2]

library(GenomicRanges)

peaks = read.table(bed, sep = "\t")[,1:3]

colnames(peaks) = c("chrom", "start", "end")

granges = GRanges(peaks)

saveRDS(object = granges, file = granges_file)

#+end_src

**** Count from filtered MACS2 consensus:smk_rule:
- Snakemake
  #+begin_src snakemake
rule count_from_filtered_macs2_consensus:
    input:
        consensus_file = config["data_dir"] + "/atac/macs2_consensus_granges/all_{join}_{chrom_filt}_{width}_filt.rds",
    params:
        script = config["repo"] + "/workflow/scripts/count_from_macs2_consensus.R",
	bam_dir = config["data_dir"] + "/atac/bam",
	bam_pattern = "_{chrom_filt}_tn5.bam$",
    output:
        rse = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_rse.rds",
        dge = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_filt_dge.rds",
    log:
        config["data_dir"] + "/logs/count_from_macs2_consensus_{join}_{chrom_filt}_{width}_filt.log"
    shell:
        """
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        {input.consensus_file} \
        {output.rse} \
        {output.dge} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/count_from_macs2_consensus.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/count_from_macs2_consensus.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

#############################################################################
###   Counts reads overlapping MACS2 consenses peaks as GRanges objects   ###
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
peaks = args[3]
rse = args[4]
dge = args[5]

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

peaks = readRDS(peaks)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

unfilt = regionCounts(bam_list, peaks, param = param)

abundance = aveLogCPM(asDGEList(unfilt))

counts = unfilt[abundance > -3, ]

edger_input = asDGEList(counts)

saveRDS(object = counts,
        file = rse)
saveRDS(object = edger_input,
        file = dge)
#+end_src

**** Make filtered background bins
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-03-01 Tue 09:00]
- State "DONE"       from "INPROCESS"  [2022-02-16 Wed 13:22]
:END:
- just need to filter to filt libs
#+begin_src R
library(SummarizedExperiment)

bkbin_open = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_rse.rds")

bkbin_regfilt = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_regfilt_rse.rds")

filt_libs = c("lib008", "lib009", "lib010", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib025")

bkbin_open_filt = bkbin_open[,colnames(bkbin_open) %in% filt_libs]

bkbin_regfilt_filt = bkbin_regfilt[,colnames(bkbin_regfilt) %in% filt_libs]

saveRDS(object = bkbin_open_filt,
        file = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

saveRDS(object = bkbin_regfilt_filt,
        file = "/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_regfilt_filt_rse.rds")
#+end_src

**** Normalize filtered csaw peaks                                 :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/counts/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src
**** Normalize filtered macs2 peaks                                :smk_rule:
- Snakemake
  #+begin_src snakemake
# Normalize each library-filtered count matrix by tmm and loess
#
rule normalize_filt:
    input:
        counts = config["data_dir"] + "/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds",
        bk =     config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_filt_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm =    config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
        loess =  config["data_dir"] + "/atac/norm/csaw_all_csaw_{chrom_filt}_filt_tmm_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_filt_csaw_{chrom_filt}.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8

######################################
###   Normalize csaw peak counts   ###
######################################

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src


*** check pca norms vs 48h using csaw counts
#+begin_src R
library(csaw)
library(edgeR)
library(tidyverse)
library(ggrepel)

peaks_rse = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/csaw_all_csaw_open_csaw_peaks_filt_rse.rds")

bk = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/bkbin_open_filt_rse.rds")

keep_libs = c("lib008", "lib013", "lib009", "lib010", "lib015", "lib011", "lib012", "lib016", "lib018", "lib020", "lib022", "lib024")

peaks_rse = peaks_rse[, colnames(peaks_rse) %in% keep_libs]
bk = bk[,colnames(bk) %in% keep_libs]
bk = bk[,colnames(bk) != "lib022"]

tmm = normFactors(bk, se.out = peaks_rse)

loess = normOffsets(peaks_rse, se.out = TRUE)

#########1#########2#########3#########4#########5#########6#########7#########8

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

norm_tmm_logcpm = make_logcpm(tmm)
norm_loess_logcpm = make_logcpm(loess)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

make_pca = function(in_cpm){
  pca_out = prcomp(t(in_cpm))
}

tmm_pca = make_pca(norm_tmm_logcpm)

make_pca_plots = function(in_pca, full_libs){
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(full_libs, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel() +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")
  return(pca_plot)
}

pca_plot = make_pca_plots(tmm_pca, libraries_full)

pca_plot
pca_plot_list = lapply(pca_list, make_pca_plots, libraries_full)

legend = get_legend(pca_plot_list[[1]]+
                        guides(color = guide_legend(nrow = 1)) +
    theme(legend.position = "bottom")
)

pre_pca_plot_grid = plot_grid(plotlist = pca_plots, labels = names(pca_list))
pre_pca_plot_grid

pca_plot_grid = plot_grid(pre_pca_plot_grid, legend, ncol = 1, rel_heights = c(1,.1))

save_plot("./results/imgs/cpm_pca.pdf", pca_plot_grid,
          base_height = 20, base_width = 20)

#+end_src

- Snakemake
  #+begin_src snakemake
rule normalize:
    input:
        counts = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_peaks_rse.rds",
        bk = config["data_dir"] + "/atac/counts/bkbin_{chrom_filt}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/normalize.R"
    output:
        tmm = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_tmm_rse.rds",
        loess = config["data_dir"] + "/atac/counts/macs2_all_{join}_{chrom_filt}_{width}_loess_rse.rds",
    log:
        config["data_dir"] + "/logs/normalize_macs2_{join}_{chrom_filt}_{width}_norm.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.bk} \
        {output.tmm} \
        {output.loess} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/normalize.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/normalize.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Normalize peak counts   ###
###

args = commandArgs(trailingOnly = TRUE)
rse_file = args[1]
bk_filt = args[2]
tmm_file = args[3]
loess_file = args[4]

rse = readRDS(rse_file)
bk = readRDS(bk_filt)

library(csaw)
library(edgeR)

tmm = normFactors(bk, se.out = rse)
loess = normOffsets(rse, se.out = TRUE)

# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

in_counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/counts/macs2_all_intersect_open_broad_peaks_rse.rds")

test =make_logcpm(in_counts)

in_norm = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_intersect_open_broad_tmm_rse.rds")

dge = asDGEList(in_norm)

in_norm

head(assays(in_norm)$counts)

colnames(dge) = colnames(in_norm)

# offsets for a log-link GLM.
normMat <- sweep(normMat, 2, eff.lib, "*")
normMat <- log(normMat)

# Creating a DGEList object for use in edgeR.
y <- DGEList(cts, group = factor(c(rep("ms_6wk",6), rep("ms_sham", 5))))

y <- scaleOffset(y, normMat)

# filtering
keep <- filterByExpr(y)
## Warning in filterByExpr.DGEList(y): All samples appear to belong to the same
## group.
y <- y[keep, ]
# y is now ready for estimate dispersion functions see edgeR User's Guide

y = calcNormFactors(y)

design <- model.matrix(~0+group, data=y$samples)

y = estimateDisp(y, design, robust = T)



tmm_logcpm = make_logcpm(tmm)



loess_logcpm = make_logcpm(loess)

head(tmm_logcpm)

colnames(tmm)
colnames(test2) = colnames(norm)

pca = prcomp(t(test2))

summary(pca)


saveRDS(object = tmm,
        file = tmm_file)
saveRDS(object = loess,
        file = loess_file)
#+end_src


*** ideas
- cite:liu2021 https://www.sciencedirect.com/science/article/pii/S1672022921001479
- for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
- lib complexity w/ preseq http://smithlabresearch.org/software/preseq/ https://github.com/smithlabcode/preseq

- common
  #+begin_src bash


CHROM_FILT:
  - "open"
  - "regfilt"

JOIN:
  - "union"
  - "intersect"
  - "naive"

WIDTH:
  - "broad"
  - "narrow"

#+end_src
#+begin_src bash
git add -A
git commit -m "feat: initial dev"
git push origin master

git branch dev_initial
git checkout dev_initial
git push origin dev_initial
#+end_src

#+begin_src bash
git init
git add -A
git commit -am "First commit"
git branch -M master

#
git remote add origin git@github.com:jeszyman/atac-seq.git
git branch -M master
git push -u origin master

cp basecamp/src/pre-commit src/precommit_git_hook
ln -s src/precommit_git_hook .git/hooks/precommit
chmod 777 .git/hooks/precommit
#+end_src

- startup script
  #+begin_src bash
#!/usr/bin/env bash
repo=$1
mntpt=$2
sif_dir=$3

# Check for parameters, return usage if empty
if [ $# -ne 3 ];
then
    printf "\n usage: repo_startup.sh <REPO PATH> <RIS MOUNT PT> <SINGULARITY CONTAINER DIR>
    \n ATAC-seq repo development helper script
    \n "
else

    # Check git file hook is read-able
    if [ -r "${repo}/.git/hooks/precommit" ]; then
        echo "Git size check is read-able"
    else
        echo
        "Git size check is not read-able"
        exit 1
    fi

    # Check mount point
    if grep -qs $mntpt /proc/mounts; then
        echo "RIS storage mounted."
    else
        echo "RIS storage NOT mounted, exiting."
        exit 1
    fi

    # Check singularity container
    if [ -r $sif_dir/atac.sif ]; then
        echo "Local SIF file present"
    else
        echo "No local SIF file found"
        exit 1
    fi

    # Check singularity container up-to-date
    if [ /mnt/ris/jschwarz/cardiac-radiobiology/atac.sif -nt $sif_dir/atac.sif ]; then
        echo "Local SIF is out of date. Updating ..."
        cp /mnt/ris/jschwarz/cardiac-radiobiology/atac.sif $sif_dir/atac.sif
    else
        echo "Local SIF file is up to date"
    fi

    cur_branch=$(git branch | head -n 1)
    echo "Current branch is $cur_branch"
fi
#+end_src




- [ ] https://github.com/snakemake-workflows/rna-seq-star-deseq2/blob/master/workflow/rules/common.smk


#+begin_src python
import pandas as pd
import re

libraries = (
    pd.read_csv("/home/jeszyman/repos/atac-seq/test/inputs/full_libraries.tsv", sep="\t",
		dtype={"library_id": str})
    .set_index("library_id", drop=False)
    .sort_index()
)

read1str=pd.Series(libraries.library_fq_r1_basename, dtype="string")

libraries["library_fq_r2_basename"] = [re.sub("R1.fastq.gz","R2.fastq.gz", x) for x in read1str]

#+end_src

libraries = (
    pd.read_csv("/home/jeszyman/repos/atac-seq/test/inputs/full_libraries.tsv", sep="\t",
		dtype={"library_id": str})
    .set_index("library_id", drop=False)
    .sort_index()
)


- add tablular sample input https://github.com/snakemake-workflows/rna-seq-star-deseq2
:header-args: :tangle no
- transcription factor sites
- homer superenhancers http://homer.ucsd.edu/homer/ngs/peaks.html

**** Make keep bed                                                 :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_keep_bed:
    input:
        autosome_bed = config["data_dir"] + "/ref/grcm38_primary_assembly_chr.bed",
        blacklist_bed = config["data_dir"] + "/ref/mm10-blacklist.v2_ENSEMBL_chr.bed",
    output:
        keep_bed = config["data_dir"] + "/ref/keep.bed",
    shell:
        """
        bedtools subtract -a {input.autosome_bed} -b {input.blacklist_bed} > {output.keep_bed}
        """
#+end_src
**** ATAC-seq peak calling and chromating accessibility on subsets
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-03-31 Thu 14:25]
:END:
  - [-] run 48h
    #+begin_src bash
lib_str="lib008 lib009 lib010 lib011 lib012 lib013 lib014 lib015 lib016"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
      "_open_tn5.bam$" \
      "${lib_str}" \
      16 \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_open_background_counts.rds \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_open_counts.rds

#+end_src
  - [ ] run 6wk
  - [-] run 48h
    #+begin_src bash
lib_str="lib008 lib009 lib010 lib011 lib012 lib013 lib014 lib015 lib016"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
      "_regfilt_tn5.bam$" \
      "${lib_str}" \
      16 \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_regfilt_background_counts.rds \
      /mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48h_regfilt_counts.rds

#+end_src
  - [ ] run 6wk

- run ir48h vs sham
- run ir6w vs sham

***** Peak annotation
- Snakemake
  #+begin_src snakemake
rule peak_annotation:
    input:
        config["data_dir"] + "/atac/dca.rds"
    params:
        script = config["repo"] + "/workflow/scripts/peak_annotation.R"
    output:
        annotated_counts = config["data_dir"] + "/atac/annotated_counts.rds",
    log:
        config["data_dir"] + "/logs/peak_annotation.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output.annot} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/peak_annotation.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/peak_annotation.R
<<r_smk_preabmle>>

#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to annotate csaw peaks   ###
###

args = commandArgs(trailingOnly = TRUE)
peaks_rds = args[1]
annotation_file = args[2]

peaks = readRDS(peaks_rds)

library(ChIPseeker)
library(csaw)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
library(tidyverse)

txdb = TxDb.Mmusculus.UCSC.mm10.ensGene

peak_loc = peaks

chipseek = annotatePeak(peak_loc, TxDb = txdb, annoDb = "org.Mm.eg.db")

annotation = as_tibble(as.data.frame(chipseek))

write.csv(annotation, row.names = F, file = annotation_file)
#+end_src
****** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
****** Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
******* Make backgroud bins                                        :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_backgroud_bins:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/make_backgroud_bins.R"
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
    output:
    log:
        config["data_dir"] + "/logs/make_backgroud_bins.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_backgroud_bins.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_backgroud_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to make background bins for csaw TMM normalization   ###
###

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
window_file =  args[1]
bam_dir = args[2]
bam_pattern = args[3]
filt_libs_str = args[4]
rse = args[4]
bk = args[5]

filt_libs = unlist(strsplit(filt_libs_str, " "))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

#+end_src
******* d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src

******** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./workflow/scripts/edger.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/edger.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src
**** Ideas
  - full log to catch this error
    - - https://www.biostars.org/p/396538/
    - note- log didn't work [[file:/mnt/ris/jschwarz/cardiac-radiobiology/log/fastqc_log.txt]]
    - #TODO how to add log file to find "$data_dir}/atac/atac-fastq" -name "*.fastq.gz" | parallel fastqc --outdir="$data_dir}/qc" }
  - preamble


***** Reference
- [[https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt][reske csaw workflow]]
***** Hold and dev
:PROPERTIES:
header-args:snakemake: :tangle no
:END:
***** Ideas
:PROPERTIES:
header-args:snakemake: :tangle no
:END:
**** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:

***** [#Y] Make nucleosome positioning alignments
:PROPERTIES:
:CREATED:  [2021-09-02 Thu 11:22]
:ID:       5acea857-b98c-473b-9b23-d430665cbb4d
:END:
:LOGBOOK:
- State "RUN"        from "DONE"       [2021-09-22 Wed 10:09]
- State "DONE"       from "CANCELED"   [2021-09-22 Wed 10:09]
CLOCK: [2021-09-15 Wed 09:35]--[2021-09-15 Wed 10:53] =>  1:18
:END:
#+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                              "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                              "TC", "UQ"),
               "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                             "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                             "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                             "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                             "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                   param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
tag = tags,
which = which,
asMates = TRUE,
bigFile = FALSE))

save(gal_lib051,
   gal_lib052,
   gal_lib053,
   gal_lib054,
   gal_lib055,
   gal_lib057,
   file = file.path(data_dir,"atac/gal.RData"))

#+end_src
- Reference
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
***** ATAC-seq QC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule atac-seq_qc:
    input:
    params:
        script = config["repo"] + "workflow/scripts/atac-seq_qc.R"
    output:
    log:
        config["data_dir"] + "/logs/atac-seq_qc.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/atac-seq_qc.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/atac-seq_qc.R
#########1#########2#########3#########4#########5#########6#########7#########8

###
###   / SCRIPT TITLE   ###
###

#+end_src

****** Transcription start sites occupancy
:PROPERTIES:
:CREATED:  [2021-09-15 Wed 10:09]
:ID:       eecd41c6-4f32-4d79-b7d5-40d666b8f85b
:END:
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#setwd("/home/jeszyman/repos/card-rad-bio")
#source("./src/setup.R")
library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

# GAlignment-input analysis
# bamfile tags to be read in
possibleTag <- list("integer"=c("AM", "AS", "CM", "CP", "FI", "H0", "H1", "H2",
                                "HI", "IH", "MQ", "NH", "NM", "OP", "PQ", "SM",
                                "TC", "UQ"),
                 "character"=c("BC", "BQ", "BZ", "CB", "CC", "CO", "CQ", "CR",
                               "CS", "CT", "CY", "E2", "FS", "LB", "MC", "MD",
                               "MI", "OA", "OC", "OQ", "OX", "PG", "PT", "PU",
                               "Q2", "QT", "QX", "R2", "RG", "RX", "SA", "TS",
                               "U2"))

bamTop100 <- scanBam(BamFile(file.path(data_dir,"/atac/atac-bam/lib051_aut_blk_ddp.bam"), yieldSize = 100),
                     param = ScanBamParam(tag=unlist(possibleTag)))[[1]]$tag

tags <- names(bamTop100)[lengths(bamTop100)>0]
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")

gal_lib051 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib051_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

gal_lib052 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib052_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib053 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib053_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib054 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib054_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib055 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib055_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))
gal_lib057 = shiftGAlignmentsList(readBamFile(
  file.path(data_dir,"atac/atac-bam/lib057_aut_blk_ddp.bam"),
  tag = tags,
  which = which,
  asMates = TRUE,
  bigFile = FALSE))

save(gal_lib051,
     gal_lib052,
     gal_lib053,
     gal_lib054,
     gal_lib055,
     gal_lib057,
     file = file.path(data_dir,"atac/gal.RData"))


#########1#########2#########3#########4#########5#########6#########7#########8
tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+begin_src R
#TODO LOAD gals
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
txs <- transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)

tsse = TSSEscore(gal_ct01, txs)
summary(tsse$TSSEscore)

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(100*(-9:10-.5), tsse$values, type="b",
     xlab="distance to TSS",
     ylab="aggregate TSS score")
dev.off()
#########1#########2#########3#########4#########5#########6#########7#########8
objs = splitGAlignmentsByCut(gal_ct01, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")

library(ChIPpeakAnno)

outPath = file.path("/mnt/ris/jschwarz/cardiac-radiobiology/atac")

bamfiles <- file.path(outPath,
                     c("NucleosomeFree.bam",
                     "mononucleosome.bam",
                     "dinucleosome.bam",
                     "trinucleosome.bam"))

TSS <- promoters(txs, upstream=0, downstream=1)
TSS <- unique(TSS)
## estimate the library size for normalization
(librarySize <- estLibSize(bamfiles))


NTILE <- 101
dws <- ups <- 1010
sigs <- enrichedFragments(gal=objs[c("NucleosomeFree",
                                     "mononucleosome",
                                     "dinucleosome",
                                     "trinucleosome")],
                          TSS=TSS,
                          librarySize=librarySize,
                          TSS.filter=0.5,
                          n.tile = NTILE,
                          upstream = ups,
                          downstream = dws)

## log2 transformed signals
sigs.log2 <- lapply(sigs, function(.ele) log2(.ele+1))

#plot heatmap
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
featureAlignedHeatmap(sigs.log2, reCenterPeaks(TSS, width=ups+dws),
                      zeroAt=.5, n.tile=NTILE)
dev.off()


## get signals normalized for nucleosome-free and nucleosome-bound regions.
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
out <- featureAlignedDistribution(sigs,
                                  reCenterPeaks(TSS, width=ups+dws),
                                  zeroAt=.5, n.tile=NTILE, type="l",
                                  ylab="Averaged coverage")
dev.off()

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
range01 <- function(x)(x-min(x))/(max(x)-min(x))}
out <- apply(out, 2, range01)
matplot(out, type="l", xaxt="n",
        xlab="Position (bp)",
        ylab="Fraction of signal")
axis(1, at=seq(0, 100, by=10)+1,
     labels=c("-1K", seq(-800, 800, by=200), "1K"), las=2)
abline(v=seq(0, 100, by=10)+1, lty=2, col="gray")
dev.off()

#########1#########2#########3#########4#########5#########6#########7#########8
## TODO MOTIF DB
## foot prints
library(MotifDb)
CTCF <- query(MotifDb, c("CTCF"))
CTCF <- as.list(CTCF)
print(CTCF[[1]], digits=2)

class(gal1[[1]])
metadata(gal1)$file
length(gal1)

gal1[2]

objs = splitGAlignmentsByCut(gal1, txs=txs, outPath = "/mnt/ris/jschwarz/cardiac-radiobiology/atac")



names(gal1)

##
## Construct GAlignment
seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = renameSeqlevels(which, c("chr1"="1"))
test

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")


BiocManager::install("ATACseqQC")

library(ATACseqQC)

test=estimateLibComplexity(readsDupFreq(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam")))

head(test)

libComplex=test

fragSize = fragSizeDist(file.path("/mnt/ris/jschwarz/cardiac-radiobiology/bam/HLV7WDSXY_TCCTGAGCAT-ACAGAGTAGA_L003_autosome_blk_sorted.bam"), "test")

class(fragSize)
head(fragSize)

if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("TxDb.Mmusculus.UCSC.mm10.knownGene")

library("TxDb.Mmusculus.UCSC.mm10.knownGene")

txs = transcripts(TxDb.Mmusculus.UCSC.mm10.knownGene)

pt = PTscore()

save(libComplex,
     fragSize,
     file = "~/repos/card-rad-bio/atac_test.Rdata")

class(test)

pt = PTscore(gal1, txs)

pt

pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(pt$log2meanCoverage, pt$PT_score,
     xlab="log2 mean coverage",
     ylab="Promoter vs Transcript")
dev.off()

nfr <- NFRscore(gal1, txs)
pdf("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test.pdf")
plot(nfr$log2meanCoverage, nfr$NFR_score,
     xlab="log2 mean coverage",
     ylab="Nucleosome Free Regions score",
     main="NFRscore for 200bp flanking TSSs",
     xlim=c(-10, 0), ylim=c(-5, 5))
dev.off()
#+end_src

#+caption: CAPTION label:fig-atac-nuc-position
[[file:results/imgs/atac_nuc_position.pdf][file:results/imgs/atac_nuc_position.pdf]]



- Post-atacseqqc
#+end_src

BiocManager::install("diffloop")

library(diffloop)
library(TxDb.Mmusculus.UCSC.mm10.knownGene)

seqinformation <- seqinfo(TxDb.Mmusculus.UCSC.mm10.ensGene)
which <- as(seqinformation, "GRanges")
test = scanBam(bam_list[1])
class(test)
>>>>>>> 9b786365ee566b1a63eb65edb3a6fa94e4ad8e97

bamTop100 <- scanBam(BamFile(bam_list[1], yieldSize = 100))
bam_list[1]
bamTag(bamTop100)



gal = readBamFile(bam_list[1], tags = tags, which = which, asMates = T, bigFile=T)

gal
param = ScanBamParam(tag))

which
test = rmchr(which)
test
test = renameSeqlevels(which, c("chr1"="1"))
test


test=rmchr(which)
head(which)


gal
## Promotor / transcript score
txs = transcripts(TxDb.Mmusculus.UCSC.mm10.ensGene)
pt = PTscore(gal, txs)

## Nucleosome free regions score
nfr = NFRscore(gal, txs)

## Transcription start site enrichment
tsse = TSSEscore(gal, txs)

# Ideas
## Adjust start sites
#+end_src
  - for split alignment conservation https://support.bioconductor.org/p/96226/ (works in docker)
- lib complexity w/ preseq http://smithlabresearch.org/software/preseq/ https://github.com/smithlabcode/preseq


TSSEs
ir01 - 2.75


#+caption: CAPTION label:fig-atac-tss
[[file:results/imgs/atac_tss.pdf]]

****** Aggregate
:PROPERTIES:
:CREATED:  [2021-09-21 Tue 07:29]
:ID:       a9426a9b-16e8-4356-8d98-314b4c7f8ec5
:END:
****** notes
:PROPERTIES:
:ID:       06f9345e-a489-4b5e-9f68-82e22e468096
:END:
- run on server, run launch_atac to load docker with ATACseqQC package
- do not run R docker through docker_interactive function- unknown error
- cite:liu2021 https://www.sciencedirect.com/science/article/pii/S1672022921001479

***** MultiQC:smk_rule:
- Snakemake
  #+begin_src snakemake
rule multiqc:
    input:
    output:
    shell:
        """
        scripts/multiqc.sh
        """
#+end_src
- [[file:./workflow/scripts/multiqc.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/multiqc.sh
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

# Snakemake variables
# Function
# Run command
#########1#########2#########3#########4#########5#########6#########7#########8
multiqc_wrap()
    # Check for parameters, return usage if empty
    if [[ $# -eq 0 ]] || [[ multiqc_wrap == "h" ]] ; then
    printf "\n usage: multiqc_wrap input_dir output_dir output_prefix
           \n Wrapper for multiqc, see options in function
           \n $1 = input_dir
           \n $2 = output_dir
           \n $3 = output_dir_prefix
           \n "
    else
        multiqc $1 \
        --force \
        --dirs \
        --dirs-depth 1 \
        --outdir $2 \
        --filename atac_qc
    fi
}

#+end_src
***** Make frag distribution mat:smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_frag_distribution_mat:
    input:
        bam_dir = config["data_dir"] + "/atac/bam",
    params:
        script = config["repo"] + "/workflow/scripts/make_frag_distribution_mat.R",
    output:
        frag_dist = config["data_dir"] + "/qc/frag_dist.rds",
    log:
        config["data_dir"] + "/logs/make_frag_distribution_mat.log"
    shell:
        """
        Rscript {params.script} \
	{input.bam_dir} \
	{output.frag_dist}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_frag_distribution_mat.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_frag_distribution_mat.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to make fragment size distribution matrix   ###
###

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)

bam_files = list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = TRUE)

names(bam_files) = gsub("_dedup.bam", "", list.files(path = bam_dir,
                       pattern = "_dedup.bam$",
                       full.names = FALSE))

#' @title fragment size distribution
#' @description estimate the fragment size of bams
#' @param bamFiles A vector of characters indicates the file names of bams.
#' @param index The names of the index file of the 'BAM' file being processed;
#'        This is given without the '.bai' extension.
#' @param bamFiles.labels labels of the bam files, used for pdf file naming.
#' @param ylim numeric(2). ylim of the histogram.
#' @param logYlim numeric(2). ylim of log-transformed histogram for the insert.
#' @return Invisible fragment length distribution list.
#' @importFrom Rsamtools ScanBamParam scanBamFlag scanBam idxstatsBam
#' @importFrom graphics axis par
#' @import GenomicRanges
#' @export
#' @author Jianhong Ou
#' @examples
#' bamFiles <- dir(system.file("extdata", package="ATACseqQC"), "GL.*.bam$", full.names=TRUE)
#' bamFiles.labels <- sub(".bam", "", basename(bamFiles))
#' fragSizeDist(bamFiles, bamFiles.labels)

fragSizeDist <- function(bamFiles, bamFiles.labels, index=bamFiles, ylim=NULL,
                         logYlim=NULL){
  opar <- par(c("fig", "mar"))
  on.exit(par(opar))
  pe <- mapply(testPairedEndBam, bamFiles, index)
  if(any(!pe)){
    stop(paste(bamFiles[!pe], collapse = ", "),
         "is not Paired-End file.")
  }
  summaryFunction <- function(seqname, seqlength, bamFile, ind, ...) {
    param <-
      ScanBamParam(what=c('isize'),
                   which=GRanges(seqname, IRanges(1, seqlength)),
                   flag=scanBamFlag(isSecondaryAlignment = FALSE,
                                    isUnmappedQuery=FALSE,
                                    isNotPassingQualityControls = FALSE))
    table(abs(unlist(sapply(scanBam(bamFile, index=ind, ..., param=param),
                            `[[`, "isize"), use.names = FALSE)))
  }
}

idxstats <- unique(do.call(rbind, mapply(function(.ele, .ind)
    idxstatsBam(.ele, index = .ind)[, c("seqnames", "seqlength")], bamFiles, index, SIMPLIFY=FALSE)))
  seqnames <- as.character(idxstats[, "seqnames"])
  seqlen <- as.numeric(idxstats[, "seqlength"])
  fragment.len <- mapply(function(bamFile, ind) summaryFunction(seqname=seqnames, seqlength=seqlen, bamFile, ind),
                         bamFiles, index, SIMPLIFY=FALSE)

  names(fragment.len) <- bamFiles.labels

  ## minor.ticks.axis <- function(ax,n=9,t.ratio=0.5,mn,mx,...){

  ##   lims <- par("usr")
  ##   lims <- if(ax %in% c(1,3)) lims[1:2] else lims[3:4]

  ##   major.ticks <- pretty(lims,n=5)
  ##   if(missing(mn)) mn <- min(major.ticks)
  ##   if(missing(mx)) mx <- max(major.ticks)

  ##   major.ticks <- major.ticks[major.ticks >= mn & major.ticks <= mx]

  ##   labels <- sapply(major.ticks,function(i)
  ##     as.expression(bquote(10^ .(i)))
  ##   )
  ##   axis(ax,at=major.ticks,labels=labels,
  ##        las=ifelse(ax %in% c(2, 4), 2, 1), ...)

  ##   n <- n+2
  ##   minors <- log10(pretty(10^major.ticks[1:2],n))-major.ticks[1]
  ##   minors <- minors[-c(1,n)]

  ##   minor.ticks = c(outer(minors,major.ticks,`+`))
  ##   minor.ticks <- minor.ticks[minor.ticks > mn & minor.ticks < mx]


  ##   axis(ax,at=minor.ticks,tcl=par("tcl")*t.ratio,labels=FALSE)
  ## }

  ## null <- mapply(function(frag.len, frag.name){
  ##   x <- 1:1010
  ##   frag.len <- frag.len[match(x, names(frag.len))]
  ##   frag.len[is.na(frag.len)] <- 0
  ##   y <- frag.len / sum(frag.len)
  ##   y <- as.numeric(y)
  ##   names(y) <- x
  ##   par(mar=c(5, 5, 4, 2) +.1)
  ##   plot(x, y*10^3, main=paste(frag.name, "fragment sizes"),
  ##        xlim=c(0, 1010), ylim=ylim,
  ##        xlab="Fragment length (bp)",
  ##        ylab=expression(Normalized ~ read ~ density ~ x ~ 10^-3),
  ##        type="l")
  ##   par(fig=c(.4, .95, .4, .95), new=TRUE)
  ##   plot(x, log10(y), xlim=c(0, 1010), ylim=logYlim,
  ##        xlab="Fragment length (bp)", ylab="Norm. read density",
  ##        type="l", yaxt="n")
  ##   minor.ticks.axis(2)
  ##   par(opar)
  ## }, fragment.len, names(fragment.len))

  #return(invisible(fragment.len))
}

frag_dist = fragSizeDist(bam_files, names(bam_files))

saveRDS(object = frag_dist,
        file  = rds)
#+end_src
- Old code
  #+begin_src R



class(test)


names(test)

class(test[[1]])

head(test[[1]])
data_dir = file.path("/mnt/ris/jschwarz/cardiac-radiobiology")

pdf("/tmp/test.pdf")
lib051_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib051_aut_blk_ddp.bam", bamFiles.labels = "lib051")
lib052_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib052_aut_blk_ddp.bam", bamFiles.labels = "lib052")
lib053_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib053_aut_blk_ddp.bam", bamFiles.labels = "lib053")
lib054_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib054_aut_blk_ddp.bam", bamFiles.labels = "lib054")
lib055_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib055_aut_blk_ddp.bam", bamFiles.labels = "lib055")
lib056_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib056_aut_blk_ddp.bam", bamFiles.labels = "lib056")
lib057_frag = fragSizeDist(bamFiles="/mnt/ris/jschwarz/cardiac-radiobiology/atac/atac-bam/lib057_aut_blk_ddp.bam", bamFiles.labels = "lib057")
dev.off()

save(lib051_frag,lib052_frag,lib053_frag,lib054_frag,lib055_frag,lib056_frag,lib057_frag, file = "~/repos/card-rad-bio/results/qc/frag.RData")

#########1#########2#########3#########4#########5#########6#########7#########8
load("./results/qc/frag.RData")
getwd()
#+end_src
  #+begin_src R
load("/mnt/ris/jschwarz/cardiac-radiobiology/atac/fragsize.RData")

ls()

fragsize_ct01
#+end_src
  #+begin_src R
#########1#########2#########3#########4#########5#########6#########7#########8
#
load(file.path(data_dir,"/atac/fragsize.RData"))

# Rename old frag size files
fragsize_lib051 = fragsize_ct01
fragsize_lib052 = fragsize_ct02
fragsize_lib053 = fragsize_ir01
fragsize_lib054 = fragsize_ir02
fragsize_lib055 = fragsize_ir03
fragsize_lib056 = fragsize_ir04
fragsize_lib057 = fragsize_ct03

# create df
fragsize = data.frame(
  length = as.numeric(names(head(fragsize_lib051[[1]], n = 1000))),
  lib051 = as.vector(head(fragsize_lib051[[1]], n = 1000)),
  lib052 = as.vector(head(fragsize_lib052[[1]], n = 1000)),
  lib053 = as.vector(head(fragsize_lib053[[1]], n = 1000)),
  lib054 = as.vector(head(fragsize_lib054[[1]], n = 1000)),
  lib055 = as.vector(head(fragsize_lib055[[1]], n = 1000)),
  lib057 = as.vector(head(fragsize_lib057[[1]], n = 1000)))
fragsize = as_tibble(fragsize)

# save df
save(fragsize, file = file.path(repo,"/results/rdata/atac_fragsize.RData"))

# make plot
fragsize %>%
  pivot_longer(cols = !length, names_to = "library_id", values_to = "count") %>%
  ggplot(., aes(x = length, y = count, group = library_id)) + geom_line() + xlim()

+ geom_bar(stat = "identity")

#+end_src


**** Library complexity:smk_rule:
- Snakemake
  #+begin_src snakemake
rule library_complexity:
    input:
        config["bam_dir"] + "/{library_id}.bam",
    params:
        script = config["atac_scripts_dir"] + "/library_complexity.R",
    output:
        config["qc_dir"] + "/{library_id}_libcomplex.rds",
    log:
        config["log_dir"] + "/{library_id}_library_complexity.log",
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/library_complexity.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/library_complexity.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   R Script to assess ATAC-seq library complexity by fragment length   ###
###

args = commandArgs(trailingOnly = TRUE)
bam = args[1]
rds = args[2]

library(preseqR)
library(ATACseqQC)
library(Rsamtools)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)

libCompWrap = function(dup_bam){
  estimateLibComplexity(readsDupFreq(dup_bam))
}

complex = libCompWrap("/mnt/ris/jschwarz/cardiac-radiobiology/inputs/Rentschler_s5469_MGI2048/lc-08.TCGTGATCAG-ACACTACGTA/lc-08.TCGTGATCAG-ACACTACGTA.genome_accepted_hits.bam")

saveRDS(object = complex,
        file = rds)

#+end_src
- Reference
  - https://github.com/smithlabcode/preseq
  - lib complexity w/ preseq http://smithlabresearch.org/software/preseq/
  - Old code
    #+begin_src R
  load(file.path(repo,"/results/rdata/library_complexity_raw.RData"))
  ls()
  head(library_complexity_raw)

  test = as.data.frame(library_complexity_raw)

  lib_complex_plot =
    as.data.frame(library_complexity_raw) %>%
    pivot_longer(cols = ends_with("values"), names_to = "library_id", values_to = "pred") %>%
    pivot_longer(cols = ends_with("reads"), names_to = "library_id2", values_to = "reads") %>%
    select(!(ends_with("relative.size"))) %>%
    mutate(library_id = substr(library_id, 1, 6)) %>%
    select(library_id, pred, reads) %>%
    filter(library_id != "lib056") %>%
    ggplot(., aes(x = reads, y = pred, group = library_id)) + geom_smooth(se = FALSE) +
     xlab("Total molecules") + ylab("Unique molecules")
  save_plot("./results/imgs/lib_complex.pdf", lib_complex_plot)

  #+end_src

    #+begin_src R

  load("./results/rdata/library_complexity_raw.RData")
  load("./data/data_model.RData")

  atac_multiqc_general_raw =
    as_tibble(
      read.table(
        file.path(repo,"results/qc/atac_qc_data/multiqc_general_stats.txt"),
        header = T,
        sep = '\t',
        fill = T))

  atac_multiqc_general_raw


  ## Modify atac multiqc df
  atac_multiqc_general_mod =
    atac_multiqc_general_raw %>%
    mutate(library_id = gsub("^.....", "", Sample)) %>%
    mutate(library_id = gsub("_.*$", "", library_id)) %>%
    mutate(total_reads = FastQC_mqc.generalstats.fastqc.total_sequences) %>%
    mutate(aligned_reads = Samtools_mqc.generalstats.samtools.mapped_passed) %>%
    mutate(processing = ifelse(grepl("_R1", Sample), "raw",
                        ifelse(grepl("ddp_flagstat", Sample), "processed",
                               ifelse(grepl("ddp_open_flagstat", Sample), "open", "other")))) %>%
    filter(processing != "other") %>%
    filter(!grepl("_R2", Sample)) %>%
    filter(!grepl("flex", Sample)) %>%
    filter(!is.na(total_reads) | !is.na(aligned_reads)) %>%
    mutate(read_prs = ifelse(!is.na(total_reads), total_reads, aligned_reads)) %>%
    select(library_id, processing, read_prs) %>%
    pivot_wider(names_from = processing, values_from = read_prs) %>%
    mutate(p_proc = processed/raw*100) %>%
    mutate(p_open = open/raw*100)
  atac_multiqc_general_mod

  library_complexity_mod = as_tibble(data.frame(lib051 = library_complexity_raw[[1]],
                                      lib052 = library_complexity_raw[[2]],
                                      lib053 = library_complexity_raw[[3]],
                                      lib054 = library_complexity_raw[[4]],
                                      lib055 = library_complexity_raw[[5]],
                                      lib056 = library_complexity_raw[[6]],
                                      lib057 = library_complexity_raw[[7]])) %>%
    mutate(rel_size = lib051.relative.size) %>%
    select(!ends_with("relative.size")) %>%
    pivot_longer(cols = starts_with("lib"), names_to = "label", values_to = "count") %>%
    mutate(library_id = substr(label, 1, 6)) %>%
    mutate(label = gsub("^.*\\.","",label)) %>%
    pivot_wider(names_from = label, values_from = count) %>%
    left_join(libraries, by = "library_id")
  library_complexity_mod

  library_complexity =
    library_complexity_mod %>%
    left_join(atac_multiqc_general_mod, by = "library_id") %>%
    filter(p_proc > 25)

  library_complexity_plot =
    library_complexity %>%
    ggplot(., aes(x = values, y = reads)) + geom_smooth()
  library_complexity_plot

  save_plot("./results/imgs/lib_complex.pdf", library_complexity_plot)

  #+end_src
**** Make fastq input symlinks
#+begin_src snakemake
rule symlink_fastqs:
    params:
        fastq = lambda w: libraries[libraries.library_id == w.library_id].fq_basename.tolist()
    output:
        r1 = config["fq_sym_dir"] + "/{library_id}_R1.fastq.gz",
        r2 = config["fq_sym_dir"] + "/{library_id}_R2.fastq.gz",
    shell:
        """
        ln -sf --relative {config[fq_src_dir]}/{params.fastq}_R1.fastq.gz {output.r1}
        ln -sf --relative {config[fq_src_dir]}/{params.fastq}_R2.fastq.gz {output.r2}
        """
#+end_src
**** Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/differential_accessibility.R
#!/usr/env R

#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
### Script to generate ATAC-seq differential accessibility model with EdgeR  ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8

# Setup

## Command line arguements
args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

## Load libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Load data
counts = readRDS(counts_rds)
background = readRDS(background_rds)
load(data_model)

# Run EdgeR workflow
counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design = model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src

***** Differential accessibility 6wk vs. sham                      :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/differential_accessibility.R
<<r_smk_preamble>>
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to generate differential accessibility model with EdgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
load(data_model)
background = readRDS(background_rds)

counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design <- model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src

***** Differential accessibility 48h vs. sham                      :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/differential_accessibility.R

# needs to be part of counts step
colnames(counts) = c("lib001","lib002","lib003","lib004")


#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
###   Script to generate differential accessibility model with EdgeR         ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8

args = commandArgs(trailingOnly = TRUE)

counts_rds = "~/repos/atac-seq/test/csaw/counts_all_regfilt_rse.rds"
background_rds = "~/repos/atac-seq/test/csaw/background_counts_all_regfilt_rse.rds"
groups = as.factor(c("ir48h","ir48h","sham","sham"))
contrast = "ir48h-sham"

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
background = readRDS(background_rds)
counts = normFactors(background, se.out = counts)
y = asDGEList(counts)
colnames(y$counts) = colnames(counts)
rownames(y$samples) = colnames(counts)
y$samples$group = groups
design = model.matrix(~0 + groups, data=y$samples)
colnames(design) = levels(groups)
y = estimateDisp(y, design)
fit = glmQLFit(y, design, robust=TRUE)
results <- glmQLFTest(fit, contrast=makeContrasts(contrast, levels=design))
# combine GRanges rowdata with DA statistics
rowData(counts) = cbind(rowData(counts), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
#merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
#merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)


# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src
***** Peak annotation
- is granges or rowRanges of a RSE
#+begin_src R
test=readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_counts.rds")
test
head(assays(test))
head(rowData(test))
head(rowRanges(test))
#+end_src
**** Pathway analysis
- GSEA
  #+begin_src R
library(msigdbr)
library(fgsea)

## Generate all msigdb mouse hallmark gene sets as list of lists
msigdbr_df <- msigdbr(species = "mouse", category = "H")
ms_path_list = split(x = msigdbr_df$ensembl_gene, f = msigdbr_df$gs_name)

test = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/dca_ir84_sham_annot.RDS")

str(annotation)


sign = sign(annotation$logFC)
logP = -log10(annotation$PValue)
rank = logP/sign

names(rank) = annotation$ENSEMBL

gsea = as_tibble(fgseaMultilevel(ms_path_list, rank, maxSize = 500))

min(gsea$padj, na.rm = T)

gsea %>% arrange(pval)

gsea = gsea[,1:7]

gsea = as.data.frame(gsea)

gsea
write.csv(file = "/tmp/test.csv", gsea)

#########1#########2#########3#########4#########5#########6#########7#########8

# Promoter only

promoters = annotation %>%
  filter(grepl("Promoter", annotation))

nrow(promoters)

sign = sign(promoters$logFC)
logP = -log10(promoters$PValue)
rank = logP/sign

names(rank) = promoters$ENSEMBL

gsea = as_tibble(fgseaMultilevel(ms_path_list, rank, maxSize = 500))

min(gsea$padj, na.rm = T)

gsea %>% arrange(pval)


#########1#########2#########3#########4#########5#########6#########7#########8

str(annotation)

annotation$pos = as.character(annotation$annotation)

annotation %>% filter(FDR < 0.05, logFC > 1) %>% dplyr::select(pos)


test =annotation %>% filter(FDR < 0.05, logFC < -1, grepl("Promoter", annotation)) %>% pull(SYMBOL)

cat(test, file = "~/down.txt")
annotation %>% filter()

#########1#########2#########3#########4#########5#########6#########7#########8
library(biomaRt)


ensembl <- useEnsembl(biomart = "ensembl")

datasets <- listDatasets(ensembl)

searchDatasets(mart = ensembl, pattern = "mmusculus")

ensembl <- useDataset(dataset = "mmusculus_gene_ensembl", mart = ensembl)


grep("entrez", filters, ignore.case = T, value = T)

values = test$ENTREZID


values = values[!is.na(values)]

index = getBM(attributes = c('ensembl_gene_id','entrezgene_id'),
              filters = 'entrezgene_id',
              values = values,
              mart = ensembl, useCache = F)

nrow(index
index$entrezgene_id = as.character(index$entrezgene_id)

library(tidyverse)


test2 = test %>% left_join(index, by = c("ENTREZID" = "entrezgene_id"))
test2 = test2[!is.na(test2$ensembl_gene_id),]
test2 = test2[grepl("Promoter", test2$annotation), ]
#########1#########2#########3#########4#########5#########6#########7#########8

#enricher lists
test = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/dca_ir48_sham.RDS")

head(test)
res = as.data.frame(test)
ggplot(res, aes(x = logFC))+geom_density()

ls()

res %>% filter(rep.logFC > 2)
str(res)
#+end_src
#+begin_src R
annotation

annotation %>% filter(logFC > 2)
#+end_src

***** Transcription factors
***** Mouse Ventricle Radiation-induced Chromatin Remodeling at 48 Hours :sci_rep:
:PROPERTIES:
:export_latex_class: paper
:export_latex_header: \usepackage{./latex/tex/report}
:export_title: Mouse Ventricle Radiation-induced Chromatin Remodeling at 48 Hours
:export_options: tags:nil todo:nil toc:2 \n:t ^:nil
:export_file_name: ./results/reports/szymanski_ms_atac_48_report.pdf
:ID:       70d78969-3820-4def-b6f3-ab3c7c3e5d87
:END:
****** LaTeX settings                                              :noexport:
[[file:results/reports/szymanski_ms_atac_48_report.tex]]
[[file:~/repos/latex/tex/report.sty]]
\usepackage[T1]{fontenc}
\usepackage{tgbonum}
****** LaTeX Preamble                                                :ignore:
\setcounter{secnumdepth}{0}
\vspace{5mm}
\hfill Last compiled {{{time(%Y-%m-%d)}}}.
\newpage
****** Discussion
Expect immune infiltrate at > 1 week supercite:colman2015
****** References                                                    :ignore:
\printbibliography
****** External files
***** ATAC-seq peak calling and chromatin accessibility run 1 for PCAs
Error in env[[as.character(i)]] <- value :
  wrong args for environment subassignment
Calls: regionCounts ... bploop -> bploop.iterate -> <Anonymous> -> add_inorder
Execution halted


install.packages("tidyverse")
library(tidyverse)

- base rscript
  #+begin_src R :noweb yes :tangle ./workflow/scripts/csaw_peak.R

#############################################################################
###              Script for csaw ATAC-seq local peak calling
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
threads = args[4]
background_rds = args[5]
counts_rds = args[6]

filt_libs = unlist(strsplit(filt_libs_str, " "))

library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)
names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))
bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

dimnames(wider) = c()
dimnames(counts) = c()

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

colnames(filtered_counts) = names(bam_list)

saveRDS(object = filtered_counts,
file = counts_rds)

colnames(background) = names(bam_list)

saveRDS(object = background,
file = background_rds)
#+end_src
- [X] run test
  #+begin_src bash
lib_str="lib001 lib002"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
        "_regfilt_tn5.bam$" \
        "${lib_str}" \
        8 \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_background_counts.rds \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_counts.rds
#+end_src
- [X] run for open
  #+begin_src bash
lib_str="lib001 lib002 lib003 lib004 lib005 lib006 lib007 lib008 lib009 lib010 lib011 lib012 lib013 lib015 lib016 lib017 lib018 lib019 lib020 lib021 lib022 lib023 lib024 lib025"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
        "_open_tn5.bam$" \
        "${lib_str}" \
        4 \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_open_background_counts.rds \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_open_counts.rds
#+end_src
- [-] run for full
  #+begin_src bash
lib_str="lib001 lib002 lib003 lib004 lib005 lib006 lib007 lib008 lib009 lib010 lib011 lib012 lib013 lib015 lib016 lib017 lib018 lib019 lib020 lib021 lib022 lib023 lib024 lib025"

nohup Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/csaw_peak.R \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/bam \
        "_regfilt_tn5.bam$" \
        "${lib_str}" \
        8 \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_regfilt_background_counts.rds \
        /mnt/ris/jschwarz/cardiac-radiobiology/atac/all_regfilt_counts.rds
#+end_src



****** Ideas and dev
******* Description                                                  :ignore:
ATAC-seq peaks were counted by /de novo/ enriched local windows using csaw. Peak counts were normalized by the trimmed mean of M values method in EdgeR. Normalized peak counts were used to test differential chromatin accessibility in EdgeR.

Peaks were annotated from the UCSC mm10 ensGene table using ChIPseeker.

******* ATAC-seq peak calling and chromatin accessibility, 6wks
******** [[file:workflow/peak_calling.smk][Snakefile]]         :smk:noexport:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/peak_calling.smk
:END:
********* Smk preamble
#+begin_src snakemake :noweb yes
<<smk_preamble>>
#+end_src
********* All rule
#+begin_src snakemake
rule all:
    input:
        config["data_dir"] + "/atac/bk_rse.rds",
        config["data_dir"] + "/atac/counts_rse.rds",
#+end_src

********* TEST Make peak counts                                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-03-11 Fri 12:20]
:END:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    params:
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = {lib_str}

        expand(config["data_dir"] + "/atac/bam/{library_id}.bam", library_id=RUNSAMPLES),

        lib_str = config["IR48H_V_SHAM"],
        script = config["repo"] + "/workflow/scripts/make_peak_counts.R",
    output:
        background_counts = config["data_dir"] + "/atac/{c}background_counts_rse.rds"
        counts_rse = config["data_dir"] + "/atac/counts_rse.rds"
    log:
        config["data_dir"] + "/logs/make_peak_counts.log",
    shell:
        """
        lib_str="{params.lib_str}"
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        "${{lib_str}}" \
        {config.threads} \
        {output.background_counts} \
        {output.counts_rse} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/select_window_size.R][Base script]]


********* TEST Make peak counts                                    :smk_rule:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-03-11 Fri 12:20]
:END:
- Snakemake
  #+begin_src snakemake
rule make_peak_counts:
    params:
        bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
        script = config["repo"] + "/workflow/scripts/make_peak_counts.R",
    output:
        background_counts = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rse = config["data_dir"] + "/atac/counts_rse.rds"
	window_size = config["data_dir"] + "/atac/window_size.rds",
    log:
        config["data_dir"] + "/logs/make_peak_counts.log",
    shell:
        """
        lib_str="{params.lib_str}"
        Rscript {params.script} \
        {params.bam_dir} \
        {params.bam_pattern} \
        "${{lib_str}}" \
        {config.threads} \
        {output.background_counts} \
        {output.counts_rse} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/select_window_size.R][Base script]]
  #+begin_src R :noweb yes
<<r_smk_preamble>>

#############################################################################
###              Script for csaw ATAC-seq local peak calling
#############################################################################

args = commandArgs(trailingOnly = TRUE)
bam_dir = args[1]
bam_pattern = args[2]
filt_libs_str = args[3]
threads = args[4]
background_rds = args[5]
rse_rds = args[6]

filt_libs = unlist(strsplit(filt_libs_str, " "))

library(BiocParallel)
library(csaw)
library(edgeR)
library(tidyverse)

surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                      pattern = bam_pattern,
                      full.names = TRUE)
names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))
bam_list = bam_list[names(bam_list) %in% filt_libs]

## Script-local functions
csaw_choose_window = function(bam_list){
  # Choose window width by fragment size distribution
  frag_size = lapply(bam_list, getPESizes)
  all_bam_frag_vect = frag_size %>% map(1) %>% as_vector()
  frag_vect_summary = summary(all_bam_frag_vect)
  thirdq = frag_vect_summary[[5]]
  return(thirdq)
}

window = csaw_choose_window(bam_list)

counts = windowCounts(bam_list,
                      width = window,
                      param = param,
                      BPPARAM = MulticoreParam(workers=threads))

neighbor = suppressWarnings(resize(rowRanges(counts),
                                   surrounds, fix = "center"))

wider = regionCounts(bam_list,
                     regions = neighbor,
                     param = param,
                     BPPARAM = MulticoreParam(workers=threads))

filter_stat = filterWindowsLocal(counts, wider)

filtered_counts = counts[filter_stat$filter > log2(3),]

background = windowCounts(bam_list,
                          bin = TRUE,
                          width = 10000,
                          param = param,
                          BPPARAM = MulticoreParam(workers=threads))

saveRDS(object = filtered_counts,
file = counts_rds)

saveRDS(object = background,
file = background_rds)
#+end_src
********* TEST Differential accessibility                          :smk_rule:
- Snakemake
  #+begin_src snakemake
rule differential_accessibility:
    input:
        background_rds = config["data_dir"] + "/atac/background_counts_rse.rds"
        counts_rds = config["data_dir"] + "/atac/counts_rse.rds",
        data_model = config["data_dir"] + "/data_model/data_model.RData",
    params:
        script = config["repo"] + "/workflow/scripts/differential_accessibility.R",
    output:
        config["data_dir"] + "/atac/dca.rds",
    log:
        config["data_dir"] + "/logs/differential_accessibility.log"
    shell:
        """
        Rscript {params.script} \
        {input.counts} \
        {input.background} \
	{input.data_model} \
	{output}
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/differential_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/differential_accessibility.R
<<r_smk_preamble>>
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to generate differential accessibility model with EdgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
data_model = args[3]
dca_granges_file = args[4]

library(csaw)
library(edgeR)
library(tidyverse)

counts = readRDS(counts_rds)
load(data_model)
background = readRDS(background_rds)

counts = normFactors(background, se.out = counts)

y <- asDGEList(counts)
colnames(y$counts) <- colnames(counts)
rownames(y$samples) <- colnames(counts)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")

y$samples$group = groups

design <- model.matrix(~0 + groups, data=y$samples)

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)

fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))


# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)
#working.windows@rowRanges

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
merged.peaks <- mergeWindows(rowRanges(filtered_counts), tol=500L, max.width=5000L)

# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)


# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_grange_file)

#+end_src
********* TEST Peak annotation                                     :smk_rule:
- Snakemake
  #+begin_src snakemake
rule peak_annotation:
    input:
        config["data_dir"] + "/atac/dca.rds"
    params:
        script = config["repo"] + "/workflow/scripts/peak_annotation.R"
    output:
        annotated_counts = config["data_dir"] + "/atac/annotated_counts.rds",
    log:
        config["data_dir"] + "/logs/peak_annotation.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output.annot} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/peak_annotation.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/peak_annotation.R
<<r_smk_preabmle>>

#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to annotate csaw peaks   ###
###

args = commandArgs(trailingOnly = TRUE)
peaks_rds = args[1]
annotation_file = args[2]

peaks = readRDS(peaks_rds)

library(ChIPseeker)
library(csaw)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
library(tidyverse)

txdb = TxDb.Mmusculus.UCSC.mm10.ensGene

peak_loc = peaks

chipseek = annotatePeak(peak_loc, TxDb = txdb, annoDb = "org.Mm.eg.db")

annotation = as_tibble(as.data.frame(chipseek))

write.csv(annotation, row.names = F, file = annotation_file)
#+end_src
********* Dev
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
********* Ideas
:PROPERTIES:
:header-args:snakemake: :tangle no
:END:
********** Make backgroud bins                                     :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_backgroud_bins:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/make_backgroud_bins.R"
    params:
        script = config["repo"] + "/workflow/scripts/call_csaw_peaks.R",
	bam_dir = config["data_dir"] + "/atac/bam",
        bam_pattern = "_regfilt_tn5.bam$",
        lib_str = config["IR48H_V_SHAM"],
    output:
    log:
        config["data_dir"] + "/logs/make_backgroud_bins.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/make_backgroud_bins.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/make_backgroud_bins.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Script to make background bins for csaw TMM normalization   ###
###

# Setup
##
## Snakemake
args = commandArgs(trailingOnly = TRUE)
window_file =  args[1]
bam_dir = args[2]
bam_pattern = args[3]
filt_libs_str = args[4]
rse = args[4]
bk = args[5]

filt_libs = unlist(strsplit(filt_libs_str, " "))

## Libraries
library(csaw)
library(edgeR)
library(tidyverse)

## Script-local variables
surrounds = 2000
standard_chr <- paste0("chr", c(1:19)) # only use standard chromosomes
param = readParam(max.frag=1000, pe="both", restrict=standard_chr)

bam_list = list.files(path = bam_dir,
                  pattern = bam_pattern,
                  full.names = TRUE)

names(bam_list) = gsub(bam_pattern, "", list.files(path = bam_dir,
                                                   pattern = bam_pattern,
                                                   full.names = FALSE))

bam_list = bam_list[names(bam_list) %in% filt_libs]

binned = windowCounts(bam_list, bin=TRUE, width=10000, param=param)

#+end_src
********** d
#+begin_src R
library(csaw)
library(edgeR)
# DIFFERENTIAL ACCESSIBILITY ANALYSIS

working.windows = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/csaw_all_csaw_open_filt_tmm_rse.rds")

# set working windows for the desired analysis
working.windows <- peak.counts.tmm # MACS2 peaks only, standard TMM normalization based on binned counts
# working.windows <- peak.counts.loess # MACS2 peaks only, for trended biases
# working.windows <- counts.local.tmm # csaw de novo peaks by local enrichment, standard TMM normalization based on binned counts
# working.windows <- counts.local.loess # csaw de novo peaks by local enrichment, for trended biases
# SEE THE CSAW MANUAL FOR MORE INFO ON NORMALIZATION METHODS
###########

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(working.windows)
colnames(y$counts) <- colnames(working.windows)
rownames(y$samples) <- colnames(working.windows)

load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

library(tidyverse)

groups =
  data.frame(library_id = rownames(y$samples)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups

y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))


(design <- model.matrix(~0 + group, data=y$samples))

colnames(design) = levels(groups)

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(ir6w-sham, levels=design))
# head(results$table)

# combine GRanges rowdata with DA statistics
rowData(working.windows) <- cbind(rowData(working.windows), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows

write.table(final.merged.peaks, "treat_vs_control_csaw_DA-windows_all.txt", sep="\t", quote=F, col.names=T, row.names=F)
write.table(final.merged.peaks.sig, "treat_vs_control_csaw_DA-windows_significant.txt", sep="\t", quote=F, col.names=T, row.names=F)

###########################################

# Generate MA plot
library(ggplot2)

final.merged.peaks$sig <- "n.s."
final.merged.peaks$sig[final.merged.peaks$FDR < FDR.thresh] <- "significant"

ggplot(data=data.frame(final.merged.peaks),
       aes(x = logCPM, y = logFC, col = factor(sig, levels=c("n.s.", "significant")))) +
  geom_point() + scale_color_manual(values = c("black", "red")) +
  geom_smooth(inherit.aes=F, aes(x = logCPM, y = logFC), method = "loess") + # smoothed loess fit; can add span=0.5 to reduce computation load/time
  geom_hline(yintercept = 0) + labs(col = NULL)


#+end_src

#+begin_src R
# Make logCPM counts of normalized data
make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm_all_csaw_open_filt_tmm = make_logcpm(tmm)
logcpm_all_csaw_open_filt_loess = make_logcpm(loess)

pca = prcomp(t(logcpm_all_csaw_open_filt_tmm))


pca = prcomp(t(test2))

summary(pca)

#+end_src

*********** edgeR:smk_rule:
https://f1000research.com/articles/5-1438/v2

lfcs are normally distributed, skewed way negative
https://support.bioconductor.org/p/57328/
see for batch correction https://www.nature.com/articles/s41598-020-66998-4#Sec9
- Snakemake
#+begin_src snakemake
rule edger:
    input:
        rse = config["data_dir"] + "/atac/counts/{counter}_all_{join}_{chrom_filt}_{width}_{norm}_rse.rds",
    params:
        script = config["repo"] + "/workflow/scripts/edger.R"
    output:
log:
    config["data_dir"] + "/logs/edger.log"
shell:
    """
    Rscript {params.script} \
    >& {log}
    """
#+end_src
- [[file:./workflow/scripts/edger.R][Base script]]
#+begin_src R :noweb yes :tangle ./workflow/scripts/edger.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###   Do differential expression of ATAC-seq peaks through edgeR   ###
###

args = commandArgs(trailingOnly = TRUE)
= args[1]

library(csaw)
library(DESeq2)
library(edgeR)
library(tidyverse)

# Load counts as DGE list
counts = readRDS(input)

counts = readRDS("/mnt/ris/jschwarz/cardiac-radiobiology/atac/norm/macs2_all_union_open_narrow_tmm_rse.rds")
load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) =
rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

plotMDS(y, col = colors, gene.selection = "common", top = 1000000)

test

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004")))
test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018")))
counts = test

# setup design matrix
# see edgeR manual for more information
y <- asDGEList(counts)
colnames(y$counts) = rownames(y$samples) = names(counts$bam.files)
groups =
  data.frame(library_id = names(counts$bam.files)) %>%
  left_join(libraries_full, by = "library_id") %>%
  droplevels() %>%
  pull(cohort_id)
groups = fct_relevel(groups, "sham", "ir48h")
groups
y$samples$group = groups
colors = as.character(factor(y$samples$group, levels = c("sham", "ir48h", "ir6w"), labels = c("darkgreen", "red", "blue")))

pdf("/tmp/pca.pdf")
plotMDS(y, col = colors, gene.selection = "common", top = 80)
dev.off()

plotMDS(y, col = colors, top = 100)

design <- model.matrix(~group, data=y$samples)
colnames(design) = levels(groups)


# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

summary(fit$df.prior)

fit <- glmQLFit(y, design)

class(design)
# testing for differentially-accessible windows
results <- glmQLFTest(fit, contrast=makeContrasts(sham-ir6w, levels=design))
# head(results$table)

topTags(results)

# combine GRanges rowdata with DA statistics
rowData(counts) <- cbind(rowData(counts), results$table)

res = as.data.frame(topTags(results, n = Inf))

ggplot(res, aes(x = logFC)) + geom_density()
summary(as.data.frame(topTags(results, n = Inf))$FDR)

test = as_tibble(as.data.frame(topTags(results, n = Inf)))

max(test$FDR)

summary(results$table$PValue)

head(results$table$PValue)

fit = glmFit(y, design, contrast = makeContrasts(ir48h-sham, levels = design))

fit
lrt = glmLRT(fit, contrast = makeContrasts(ir48h-sham, levels = design))
test=as.data.frame(topTags(lrt, n = 10000))
class(test)
summary(test$FDR)
lrt
head(lrt$table)
et = exactTest(y)
topTags(et)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)
# summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
min(tab.best$PValue)
min(tab.best$FDR)

# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
FDR.thresh <- 0.05 # set as desired
final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
final.merged.peaks.sig # significant differentially-accessible windows




colnames(design) = levels(counts$samples$group)

test = rlog(assays(counts)$counts)
rld = test

class(rld)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

head(counts$counts)
rownames(counts$counts)

class(working.windows)

working.windows

# stabilize dispersion estimates with empirical bayes
y <- estimateDisp(y, design)
fit <- glmQLFit(y, design, robust=TRUE)

# testing for differentially-accessible windows
#results <- glmQLFTest(fit, contrast=makeContrasts(treat-control, levels=design))

results <- glmQLFTest(fit, contrast=makeContrasts(ir48h-sham, levels=design))
# head(results$table)

test = results$table
min(test$PValue)

class(working.windows)

test = working.windows[,8:15]


# combine GRanges rowdata with DA statistics
#rowData(working.windows) <- cbind(rowData(working.windows), results$table)
rowData(test) = cbind(rowData(test), results$table)

test@rowRanges
working.windows = test

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(working.windows), tol=500L, max.width=5000L)
summary(width(merged.peaks$region))
# should merge some peaks; change as desired

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best <- getBestTest(merged.peaks$id, results$table)
head(tab.best)
# combine merged peaks window range with statistics
final.merged.peaks <- merged.peaks$region
final.merged.peaks@elementMetadata <- cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks <- final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR
final.merged.peaks # all windows

# filter by FDR threshold
#FDR.thresh <- 0.05 # set as desired
#final.merged.peaks.sig <- final.merged.peaks[final.merged.peaks@elementMetadata$FDR < FDR.thresh, ]
#final.merged.peaks.sig # significant differentially-accessible windows



#########1#########2#########3#########4#########5#########6#########7#########8

library(DESeq2)

test = subset(counts, select = !(colnames(counts) %in% c("lib001", "lib002","lib007","lib005", "lib006", "lib003", "lib004","lib013","lib018", "lib023", "lib014")))
counts = test


test = rlog(assays(counts)$counts)
rld = test

rld = vst(assays(counts)$counts)
mat = t(rld)
pca = prcomp(mat)

summary(pca)

pca_plot = as.data.frame(pca$x) %>%
  rownames_to_column(var = "library_id") %>%
  left_join(libraries_full, by = "library_id") %>%
  ggplot(., aes(x = PC1, y = PC2, color = cohort_id)) +
  geom_point(size = 4)
pca_plot



#lowdate = as.character(data.frame(library_id = colnames(y)) %>% left_join(libraries_full, by = "library_id") %>% pull(flow_date))

#########1#########2#########3#########4#########5#########6#########7#########8
#+end_src

******** Description                                                 :ignore:
ATAC-seq peaks were counted by /de novo/ enriched local windows using csaw. Peak counts were normalized by the trimmed mean of M values method in EdgeR. Normalized peak counts were used to test differential chromatin accessibility in EdgeR.

Peaks were annotated from the UCSC mm10 ensGene table using ChIPseeker.


***** All count logcpms for QC
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-03-31 Thu 14:24]
:END:

- [X] Functions and test
  #+begin_src R :tangle ./workflow/scripts/counts_to_logcpm.R
args = commandArgs(trailingOnly = TRUE)
counts_rds = args[1]
background_rds = args[2]
logcpm_file = args[3]

background = readRDS(background_rds)
counts = readRDS(counts_rds)

library(csaw)
library(edgeR)
library(tidyverse)

counts = normFactors(background, se.out = counts)

make_logcpm = function(in_norm){
  dge = asDGEList(in_norm)
  colnames(dge) = colnames(in_norm)
  log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
  return(log_cpm)
}

logcpm = make_logcpm(counts)

saveRDS(object = logcpm,
        file = logcpm_file)
#+end_src
  #+begin_src bash
Rscript /home/jeszyman/repos/cardradbio-atac/workflow/scripts/counts_to_logcpm.R \
	/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_counts.rds \
	/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_background_counts.rds \
	/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_logcpm.rds
#+end_src

- All sample PCA
  #+begin_src bash

#+end_src
- Filtered PCA
- Reference
  - PCA of mislabeled samples
    #+begin_src R
  load("/mnt/ris/jschwarz/cardiac-radiobiology/atac/ir48_v_sham_tmp.rdata")

  load("/mnt/ris/jschwarz/cardiac-radiobiology/data_model/data_model.RData")

  participants$cohort_id[which(participants$part_id == "ms015")] = "ir48h"

  libraries_full$cohort_id[which(libraries_full$library_id == "lib009")] = "ir48h"

  libraries_full$cohort_id[which(libraries_full$library_id == "lib016")] = "sham"

  library(csaw)

  make_logcpm = function(in_norm){
    dge = asDGEList(in_norm)
    colnames(dge) = colnames(in_norm)
    log_cpm = cpm(dge, normalized.lib.sizes = TRUE, log = TRUE, prior.count = 2)
    return(log_cpm)
  }

  logcpm = make_logcpm(filtered_counts)

  pca = prcomp(t(logcpm))
  summary(pca)

  library(tidyverse)
  library(ggrepel)

  make_pca_plots = function(in_pca, full_libs){
    pve_pc1=round(100*summary(in_pca)$importance[2,1])
    pve_pc2=round(100*summary(in_pca)$importance[2,2])

    pca_plot = as.data.frame(in_pca$x) %>%
      rownames_to_column(var = "library_id") %>%
      left_join(full_libs, by = "library_id") %>%
      ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
      geom_point(size = 4) +
      geom_text_repel() +
      xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
      ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
      guides(color="none")
    return(pca_plot)
  }



  test =make_pca_plots(pca, libraries_full)


  in_pca = pca
  pve_pc1=round(100*summary(in_pca)$importance[2,1])
  pve_pc2=round(100*summary(in_pca)$importance[2,2])

  pca_plot = as.data.frame(in_pca$x) %>%
    rownames_to_column(var = "library_id") %>%
    left_join(libraries_full, by = "library_id") %>%
    ggplot(., aes(x = PC1, y = PC2, color = cohort_id, label = library_id)) +
    geom_point(size = 4) +
    geom_text_repel(force = 10) +
    xlab(paste("PC1, ", pve_pc1, "% variance explained", sep ="")) +
    ylab(paste("PC2, ", pve_pc2, "% variance explained", sep ="")) +
    guides(color="none")


  ggsave(pca_plot, filename = "/mnt/ris/jschwarz/cardiac-radiobiology/tmp/pca2.pdf")

  ggsave(pca_plot, filename = "~/repos/cardradbio-atac/results/imgs/ir48h_v_sham_full_pca.pdf")
  #+end_src

***** Read processing and alignment
****** Description                                                   :ignore:
Sequencing read adapters were removed and reads were quality trimmed using flexbar.

Processed reads were aligned to mm10 using bowtie2.

PCR duplicate reads were removed using samtools. Reads were then filtered and processed for ATAC-seq analysis as follows. Only paired reads aligning to mm10 autosomes were retained. Read pairs were also removed if they overlapped known problematic regions from the ENCODE blacklist supercite:amemiya2019. Finally, alignments were shifted on the forward strand by +4 bp and on the reverse strand by âˆ’5 bp to account for the 9-bp duplication introduced by Tn5.


****** DONE [[file:workflow/preprocess_align.smk][Snakefile]]           :smk:
CLOSED: [2022-03-11 Fri 12:19]
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/preprocess_align.smk
:CUSTOM_ID: readp
:END:
:LOGBOOK:
- State "DONE"       from "INPROCESS"  [2022-03-11 Fri 12:19]
:END:
******* Smk preamble
#+begin_src snakemake
container: config["container"]
RUNSAMPLES =  ["lib001", "lib002", "lib003", "lib004", "lib005", "lib006", "lib007", "lib008", "lib009", "lib010", "lib011", "lib012", "lib013", "lib014", "lib015", "lib016", "lib017", "lib018", "lib019", "lib020", "lib021", "lib022", "lib023", "lib024", "lib025"]
#+end_src
******* Smk rules
******** All rule
#+begin_src snakemake
rule all:
    input:
        expand(config["data_dir"] + "/atac/bam/{library_id}.bam", library_id=RUNSAMPLES),
        config["data_dir"] + "/ref/keep.bed",
        expand(config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/atac/bam/{library_id}_open.bam", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/atac/bam/{library_id}_regfilt_tn5.bam", library_id=RUNSAMPLES),
        expand(config["data_dir"] + "/atac/bam/{library_id}_open_tn5.bam", library_id=RUNSAMPLES),
#+end_src
******** Read trim                                                 :smk_rule:
- Snakemake
  #+begin_src snakemake
rule read_trim:
    input:
        r1 = config["data_dir"] + "/atac/fastq/{library_id}_R1.fastq.gz",
        r2 = config["data_dir"] + "/atac/fastq/{library_id}_R2.fastq.gz",
    params:
        outdir = config["data_dir"] + "/atac/fastq",
        threads = config["threads"],
    output:
        config["data_dir"] + "/atac/fastq/{library_id}_flex_1.fastq.gz",
        config["data_dir"] + "/atac/fastq/{library_id}_flex_2.fastq.gz",
    resources:
        mem_mb=5000
    shell:
        """
        workflow/scripts/read_trim.sh {input.r1} {input.r2} {params.outdir} {params.threads}
        """
#+end_src
- Script [[file:workflow/scripts/read_trim.sh]]
  #+begin_src bash :noweb yes :tangle ./workflow/scripts/read_trim.sh
#########1#########2#########3#########4#########5#########6#########7#########8
#
# Function for flexbar processing
flexbar_atac() {
    base=$(basename -s _R1.fastq.gz $1)
    flexbar \
        --adapter-pair-overlap ON \
        --adapter-preset Nextera \
        --pre-trim-right 1 \
        --reads "${1}" \
        --reads2 "${2}" \
        --target "${3}/${base}_flex" \
        --threads ${4} \
        --zip-output GZ
}

# Snakemake parameters
input_r1="$1"
input_r2="$2"
params_outdir="$3"
params_threads="$4"

# Run
flexbar_atac "${input_r1}" "${input_r2}" "${params_outdir}" "${params_threads}"
#+end_src
******** Make bowtie index                                         :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_bowtie_index:
    input:
        fa = config["data_dir"] + "/ref/mm10.fa",
    params:
        prefix = config["data_dir"] + "/ref/ucsc_mm10_bt2/ucsc_mm10_bt2",
        threads = config["threads"]
    output:
        config["data_dir"] + "/ref/ucsc_mm10_bt2/ucsc_mm10_bt2.1.bt2",
    shell:
        """
        workflow/scripts/make_bowtie_index.sh {input.fa} {params.prefix} {params.threads}
        """
#+end_src
- [[file:./workflow/scripts/make_bowtie_index.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/make_bowtie_index.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function
make_bt2_index(){
    index_dir=$(dirname $3)
    mkdir -p $index_dir
    bowtie2-build -f \
                  --threads $1 \
                  $2 \
                  $3
}

# Snakemake variables
input_fa="$1"
params_prefix="$2"
params_threads="$3"

# Run
make_bt2_index $params_threads $input_fa $params_prefix
#+end_src
******** Align BT2                                                 :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2021-12-23 Thu 12:41]
:END:
- Snakemake
  #+begin_src snakemake
rule align_bt2:
    input:
        r1 = config["data_dir"] + "/atac/fastq/{library_id}_flex_1.fastq.gz",
        r2 = config["data_dir"] + "/atac/fastq/{library_id}_flex_2.fastq.gz",
    params:
        prefix = config["data_dir"] + "/ref/ucsc_mm10_bt2/ucsc_mm10_bt2",
        threads = config["threads"],
    output:
        bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
    shell:
        """
        workflow/scripts/align_bt2.sh {input.r1} {input.r2} {params.prefix} {params.threads} {output.bam}
        """
#+end_src
- [[file:./workflow/scripts/align_bt2.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/align_bt2.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function
bt2_align(){
    bowtie2 --maxins 2000 --threads $1 --very-sensitive -x $2 -1 $3 -2 $4 | samtools view -bS - > $5
}

# Snakemake variables
input_r1="$1"
input_r2="$2"
params_prefix="$3"
params_threads="$4"
output_bam="$5"

# Run
bt2_align "$params_threads" "$params_prefix" "$input_r1" "$input_r2" "$output_bam"
#+end_src
******** Make keep bed                                             :smk_rule:
- Snakemake
  #+begin_src snakemake
rule make_keep_bed:
    input:
        autosome_bed = config["data_dir"] + "/ref/grcm38_primary_assembly_chr.bed",
        blacklist_bed = config["data_dir"] + "/ref/mm10-blacklist.v2_ENSEMBL_chr.bed",
    output:
        keep_bed = config["data_dir"] + "/ref/keep.bed",
    shell:
        """
        bedtools subtract -a {input.autosome_bed} -b {input.blacklist_bed} > {output.keep_bed}
        """
#+end_src
******** Filter and dedup                                          :smk_rule:
- Snakemake
  #+begin_src snakemake
rule filter_and_dedup:
    input:
        bam = config["data_dir"] + "/atac/bam/{library_id}.bam",
    params:
        keep_bed = config["data_dir"] + "/ref/keep.bed",
        threads = config["threads"],
    output:
        dedup_bam = config["data_dir"] + "/atac/bam/{library_id}_dedup.bam",
        qfilt_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_qfilt.bam"),
        regfilt_bam = config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam",
        regfilt_index = config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam.bai",
    resources:
        mem_mb=5000
    shell:
        """
        workflow/scripts/filter_and_dedup.sh {input.bam} \
	                                     {params.keep_bed} \
	                                     {params.threads} \
	                                     {output.dedup_bam} \
	                                     {output.qfilt_bam} \
	                                     {output.regfilt_bam}
        """
#+end_src
- [[file:./workflow/scripts/filter_and_dedup.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/filter_and_dedup.sh
#########1#########2#########3#########4#########5#########6#########7#########8

# Function

atac_bam_processing(){
    #
    # Dedup
    samtools sort -@ $1 -n -o - $2 |
    samtools fixmate -m - - |
    samtools sort -@ $1 -o - - |
    samtools markdup -@ $1 -r - $3
    #
    # Filter to aligned, properly paired reads
    samtools view -@ $1 -b -f 3 -h -o $4 $3
    #
    # Filter to autosomes and remove blacklisted regions
    samtools view -@ $1 -b -h -L $5 -o - $4 |
    samtools sort -@ $1 -n -o - - |
    samtools fixmate -m - - |
    samtools sort -@ $1 -o $6 -
    samtools index $6
}

# Snakemake variables
input_bam="$1"
params_keep_bed="$2"
params_threads="$3"
output_dedup_bam="$4"
output_qfilt_bam="$5"
output_regfilt_bam="$6"

# Run command
atac_bam_processing "$params_threads" \
                    "$input_bam" \
                    "$output_dedup_bam" \
                    "$output_qfilt_bam" \
                    "$params_keep_bed" \
                    "$output_regfilt_bam"
samtools index "$output_regfilt_bam"
#+end_src
******** Get open chrom                                            :smk_rule:
- Snakemake
  #+begin_src snakemake
rule get_open_chrom:
    input:
        regfilt_bam = config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam",
    output:
        unsort_open_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_unsort_open.bam"),
        open_bam = config["data_dir"] + "/atac/bam/{library_id}_open.bam",
    shell:
        """
        workflow/scripts/get_open_chrom.sh {input.regfilt_bam} \
                                           {config[threads]} \
                                           {output.unsort_open_bam} \
                                           {output.open_bam}
        """
#+end_src
- [[file:./workflow/scripts/get_open_chrom.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/get_open_chrom.sh
#########1#########2#########3#########4#########5#########6#########7#########8
alignmentSieve --bam $1 \
               --maxFragmentLength 150 \
               --numberOfProcessors $2 \
               --outFile $3
samtools sort -@ $2 -o $4 $3
samtools index -@ $2 $4
#+end_src
******** Tn5 shift                                                 :smk_rule:
:LOGBOOK:
- State "DONE"       from "DELEGATED"  [2022-02-11 Fri 16:40]
- State "DONE"       from "CLOSEOUT"   [2022-02-11 Fri 16:40]
- State "DONE"       from "RUN"        [2022-02-11 Fri 16:40]
- State "WAITING"    from "TODO"       [2022-01-06 Thu 09:09] \\
  add to next run
:END:
- Snakemake
  #+begin_src snakemake
rule tn5_shift_and_open:
    input:
        atac_bam =         config["data_dir"] + "/atac/bam/{library_id}_regfilt.bam",
    output:
        tmp_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_regfilt_tmp.bam"),
        tn5_bam =      config["data_dir"] + "/atac/bam/{library_id}_regfilt_tn5.bam",
    log:
        config["data_dir"] + "/logs/tn5_shift_and_open_{library_id}_regfilt.log",
    shell:
        """
        workflow/scripts/tn5_shift.sh {input.atac_bam} \
	                              {config[threads]} \
	                              {output.tmp_bam} \
                                      {output.tn5_bam} > {log} 2>&1
        """
#+end_src
- [[file:./workflow/scripts/todo_tn5_shift.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/tn5_shift.sh
alignmentSieve --ATACshift --bam "$1" --numberOfProcessors $2 --outFile "$3"

samtools sort -@ $2 -o $4 $3

samtools index -@ $2 $4
#+end_src
******** Tn5 open shift                                            :smk_rule:
:LOGBOOK:
- State "WAITING"    from "TODO"       [2022-01-06 Thu 09:09] \\
  add to next run
:END:
- Snakemake
  #+begin_src snakemake
rule tn5_shift_open:
    input:
        atac_bam =         config["data_dir"] + "/atac/bam/{library_id}_open.bam",
    output:
        tmp_bam = temp(config["data_dir"] + "/atac/bam/{library_id}_open_tmp.bam"),
        tn5_bam =      config["data_dir"] + "/atac/bam/{library_id}_open_tn5.bam",
    log:
        config["data_dir"] + "/logs/tn5_shift_and_open_{library_id}_open.log",
    shell:
        """
        workflow/scripts/tn5_shift.sh {input.atac_bam} \
	                              {config[threads]} \
	                              {output.tmp_bam} \
                                      {output.tn5_bam} > {log} 2>&1
        """
#+end_src
- [[file:./workflow/scripts/todo_tn5_shift.sh][Base script]]
  #+begin_src bash :tangle ./workflow/scripts/tn5_shift.sh
alignmentSieve --ATACshift --bam "$1" --numberOfProcessors $2 --outFile "$3"

samtools sort -@ $2 -o $4 $3

samtools index -@ $2 $4
#+end_src

******* Ideas
- redefine samtools tmp dir outside repo




**** Motif analysis
- Get gene list- Takes annotated edger results as table
  #+begin_src R
library(tidyverse)
test = as_tibble(read.csv("/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_de.csv", header = T))

motifs_down_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC < 0) %>%
  pull(geneId)

motifs_up_ensembl = test %>%
  filter(grepl("promoter", annotation, ignore.case = T)) %>%
  filter(FDR < 0.05) %>%
  filter(logFC > 0) %>%
  pull(geneId)

writeLines(as.character(motifs_down_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt")
writeLines(as.character(motifs_up_ensembl), "/mnt/ris/jschwarz/cardiac-radiobiology/atac/test_up.txt")

#+end_src

- Find motifs
  #+begin_src bash
mkdir -p /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/

nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/ -fdr 10 -p 12

# try



Number of CPUs to use ("-p <#>", default 1)
HOMER is now multicore compliant.  It's not perfectly parallelized, however, certain types of analysis can benefit.  In general, the longer the length of the motif, the better the speed-up you'll see.

Number of motifs to find ("-S <#>", default 25)
Specifies the number of motifs of each length to find.  25 is already quite a bit.  If anything, I'd recommend reducing this number, particularly for long motifs to reduce the total execution time.
perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src

- Extract gene names
  #+begin_src bash

#+end_src


***** Snakefile                                                :smk:noexport:
:PROPERTIES:
:header-args:snakemake:  :tangle ./workflow/motifs.smk
:END:
****** Smk preamble
#+begin_src snakemake :noweb yes
<<smk_preamble>>
#+end_src
****** All rule
#+begin_src snakemake
rule all:
    input:
#+end_src
****** Extract gene list                                           :smk_rule:

extract ensembl ID lists from csaw-EdgeR DCA workflow

- Snakemake
  #+begin_src snakemake
rule extract_gene_list:
    input:
    params:
        script = config["repo"] + "/workflow/scripts/extract_gene_list.R"
    output:
    log:
        config["data_dir"] + "/logs/extract_gene_list.log"
    shell:
        """
        Rscript {params.script} \
        >& {log}
        """
#+end_src
- [[file:./workflow/scripts/extract_gene_list.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/extract_gene_list.R
#!/usr/bin/env Rscript
#########1#########2#########3#########4#########5#########6#########7#########8
###
###    SCRIPT TITLE   ###
###

args = commandArgs(trailingOnly = TRUE)
dca_tbl = args[1]

#+end_src
****** Find motifs for gene list promoters
#+begin_src bash
#nohup findMotifs.pl /mnt/ris/jschwarz/cardiac-radiobiology/atac/test_down.txt mouse /mnt/ris/jschwarz/cardiac-radiobiology/atac/homer/ir48h_v_sham_less_access/ -fdr 10 -p 12

findMotifs.pl test/homer/open_48hr-sham_down_genelist.txt \
              mouse \
              test/homer/open_ir48h-sham_less -fdr10 -p 4

#+end_src
- Find motifs by gene list
  #+begin_src bash
# TODO install homer w/ mouse-p promoter set

source ~/repos/cardradbio-atac/config/${HOSTNAME}.sh

# Fake gene list from peak annotation output, is ensembl IDs
#

# Install mouse homer promotor set
perl /home/jeszyman/homer/.//configureHomer.pl -install mouse-p

mkdir -p /tmp/out

findMotifs.pl /tmp/test.txt mouse /tmp/out

perl /opt/miniconda/share/homer/.//configureHomer.pl -list

perl /opt/miniconda/share/homer/.//configureHomer.pl -install mm10 --keepScript

#+end_src
***** Description                                                    :ignore:
**** [[file:workflow/dca_and_annot.smk][Differential chromatin accessibility and annotation]]                :smk:
:PROPERTIES:
:header-args:snakemake: :tangle ./workflow/dca_and_annot.smk
:END:
:LOGBOOK:
- State "WAITING"    from "TEST"       [2022-03-31 Thu 14:33]
:END:
# Latest deepTools on bioconda does not contain alignmentSieve
RUN conda install -c bioconda deeptools=3.4 --force

***** Differential chromatin accessibility
- Snakemake
  #+begin_src snakemake
rule diff_chrom_accessibility:
    input:
        dge = config["data_dir"] + "/csaw/dge_{bam_process}.rds",
        norm_counts_rse = config["data_dir"] + "/csaw/norm_counts_rse_{bam_process}.rds",
    params:
        groups_str = "ir48h ir48h sham sham",
        contrast = "ir48h-sham",
        script = config["atac_scripts_dir"] + "/diff_chrom_accessibility.R",
    output:
        config["data_dir"] + "/dca/dca_granges_{bam_process}.rds"
    log:
        config["log_dir"] + "/diff_chrom_accessibility_{bam_process}.log",
    shell:
        """
        Rscript {params.script} \
        {input.dge} \
        "{params.groups_str}" \
        "{params.contrast}" \
        {input.norm_counts_rse} \
        {output} \
        >& {log}
        """
#+end_src
- [[file:workflow/scripts/diff_chrom_accessibility.R][Base script]]
  #+begin_src R :noweb yes :tangle ./workflow/scripts/diff_chrom_accessibility.R

#########1#########2#########3#########4#########5#########6#########7#########8
###                                                                          ###
###   Script to generate differential accessibility model with EdgeR         ###
###                                                                          ###
#########1#########2#########3#########4#########5#########6#########7#########8

# Setup

## Arguements for testing
dge_rds = "~/repos/atac-seq/test/csaw/dge_regfilt.rds"
groups_str = "ir48h ir48h sham sham"
contrast = "ir48h-sham"
norm_counts_rds = "~/repos/atac-seq/test/csaw/norm_counts_rse_regfilt.rds"
dca_granges_rds = "/tmp/test.rds"

args = commandArgs(trailingOnly = TRUE)
dge_rds = args[1]
groups_str =args [2]
contrast = args[3]
norm_counts_rds = args[4]
dca_granges_rds = args[5]

library(csaw)
library(edgeR)
library(tidyverse)

y = readRDS(dge_rds)
groups = as.factor(unlist(strsplit(groups_str, " ")))

design = model.matrix(~0 + groups, data=y$samples)
colnames(design) = levels(groups)
y = estimateDisp(y, design)
fit = glmQLFit(y, design, robust=TRUE)
results = glmQLFTest(fit, contrast=makeContrasts(contrast, levels=design))

# combine GRanges rowdata with DA statistics
counts = readRDS(norm_counts_rds)
rowData(counts) = cbind(rowData(counts), results$table)

# merge nearby windows
# up to "tol" distance apart: 500 bp in this case
# max merged window width: 5000 bp
merged.peaks <- mergeWindows(rowRanges(counts), tol=500L, max.width=5000L)

# use most significant window as statistical representation for p-value and FDR for merged windows
tab.best = getBestTest(merged.peaks$id, results$table)

# combine merged peaks window range with statistics
final.merged.peaks = merged.peaks$region
final.merged.peaks@elementMetadata = cbind(final.merged.peaks@elementMetadata, tab.best[,-1])
final.merged.peaks = final.merged.peaks[order(final.merged.peaks@elementMetadata$FDR), ] # sort by FDR

saveRDS(object = final.merged.peaks,
        file = dca_granges_rds)

#+end_src
***** Peak annotation                                              :smk_rule:
- Snakemake
  #+begin_src snakemake
rule peak_annotation:
    input:
        config["data_dir"] + "/dca/dca_granges_{bam_process}.rds",
    params:
        script = config["atac_scripts_dir"] + "/peak_annotation.R"
    output:
        csv = config["data_dir"] + "/dca/{bam_process}_dca.csv",
        chipseek = config["data_dir"] + "/dca/{bam_process}_chipseek.rds"
    log:
        config["data_dir"] + "/logs/{bam_process}_peak_annotation.log"
    shell:
        """
        Rscript {params.script} \
        {input} \
        {output.csv} \
        {output.chipseek} \
        >& {log}
        """
#+end_src
- Base script
  #+begin_src R :tangle ./workflow/scripts/peak_annotation.R
# Arguements for testing
## granges_rds = "/home/jeszyman/repos/atac-seq/test/dca/dca_granges_regfilt.rds"
## annotation_csv = "/home/jeszyman/repos/atac-seq/test/dca/regfilt_dca.csv"
## chipseek_file = "/home/jeszyman/repos/atac-seq/test/dca/regfilt_chipseek.rds"

# Arguements for command line input
args = commandArgs(trailingOnly = TRUE)
granges_rds = args[1]
annotation_csv = args[2]
chipseek_file = args[3]

peaks = readRDS(granges_rds)

library(ChIPseeker)
library(csaw)
library(TxDb.Mmusculus.UCSC.mm10.ensGene)
library(tidyverse)

txdb = TxDb.Mmusculus.UCSC.mm10.ensGene

chipseek = annotatePeak(peaks, TxDb = txdb, annoDb = "org.Mm.eg.db")

annotation = as_tibble(as.data.frame(chipseek))

write.csv(annotation, row.names = F, file = annotation_csv)

saveRDS(object = chipseek,
        file = chipseek_file)
#+end_src
- Reference
  - https://bioconductor.org/packages/release/bioc/vignettes/ChIPseeker/inst/doc/ChIPseeker.html#peak-annotation
**** Update via biopipe mod
** README
[[file:resources/int_test.png]]
*** Prerequisites to run repository local integration testing
- Singularity container built from https://github.com/jeszyman/atac-seq/blob/master/config/atac_Dockerfile
- Local snakemake
- Local snakemake configuration YAML
*** Changelog
- [2022-09-06 Tue] Re-written for my biotools repo best practices [2022-09-06 Tue]. Downgraded to alignment and qc only. Need to add back macs2.
- [2022-08-29 Mon] Initial pre-processing, peak calling, and normalization validated.
** Reference
- [[https://static-content.springer.com/esm/art%3A10.1186%2Fs13072-020-00342-y/MediaObjects/13072_2020_342_MOESM6_ESM.txt][reske csaw workflow]]
- [[id:271b4d5f-727e-496e-b835-8fe9f8655655][biopipe module]]
- [[id:22e31d06-f5df-427e-bd70-3a2ccd3f47ec][ATAC-seq]]
